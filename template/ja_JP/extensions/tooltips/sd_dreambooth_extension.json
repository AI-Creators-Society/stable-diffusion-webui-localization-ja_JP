{
  "API Key": {
    "key": "API Key",
    "tooltip": "ウェブAPIのセキュリティ確保に使用します。右の更新ボタンをクリックするとキーが(再)生成され、ゴミ箱アイコンをクリックするとキーが削除されます。"
  },
  "AdamW Weight Decay": {
    "key": "AdamW Weight の減衰",
    "tooltip": "AdamW Optimizerのウェイト減衰量。値が0に近い場合はトレーニングデータセットと密接に一致し、1に近い場合はより一般化しトレーニングデータセットから逸脱します。デフォルトは1e-2で、0.1より低い値を推奨されます。"
  },
  "Amount of time to pause between Epochs (s)": {
    "key": "エポック間で一時停止する時間(秒)",
    "tooltip": "「Nエポック後に一時停止」の値が0より大きい場合、訓練は数秒で一時停止されます。"
  },
  "Apply Horizontal Flip": {
    "key": "水平フリップを適用",
    "tooltip": "画像を水平方向に反転することをランダムに決定します。"
  },
  "Batch Size": {
    "key": "出力枚数",
    "tooltip": "訓練ステップごとに何枚の画像を処理しますか？"
  },
  "Cache Latents": {
    "key": "履歴のキャッシュ",
    "tooltip": "このボックスがチェックされている場合、レイテントはキャッシュされます。レイテントをキャッシュすると、より多くのVRAMを使用しますが、トレーニング速度は向上します。"
  },
  "Cancel": {
    "key": "取消",
    "tooltip": "トレーニングをキャンセル"
  },
  "Class Batch Size": {
    "key": "クラスのバッチサイズ",
    "tooltip": "一度に生成する分類/正規化画像の枚数。"
  },
  "Class Images Per Instance Image": {
    "key": "Class Images Per Instance Image",
    "tooltip": "How many classification images to use per instance image."
  },
  "Class Prompt": {
    "key": "クラスプロンプト",
    "tooltip": "A prompt for generating classification/regularization images. See the readme for more info."
  },
  "Class Token": {
    "key": "クラストークン",
    "tooltip": "When using [filewords], this is the class identifier to use/find in existing prompts. Should be a single word."
  },
  "Classification CFG Scale": {
    "key": "分類CFGスケール",
    "tooltip": "The Classifier-Free Guidance Scale to use for classifier/regularization images."
  },
  "Classification Dataset Directory": {
    "key": "分類データセットディレクトリ",
    "tooltip": "分類/規則化画像を含むディレクトリ。"
  },
  "Classification Image Negative Prompt": {
    "key": "分類イメージのネガティブプロンプト",
    "tooltip": "クラスイメージを生成する際に使用するネガティブプロンプトです。空でも問題ありません。"
  },
  "Classification Steps": {
    "key": "分類のステップ",
    "tooltip": "分類画像/規則画像を生成する際に使用するステップ数。"
  },
  "Clip Skip": {
    "key": "Clip Skip",
    "tooltip": "テキストエンコーダの背面からのn番目のレイヤーの出力を使用 (n>=1)"
  },
  "Concepts List": {
    "key": "コンセプト一覧",
    "tooltip": "コンセプトJSONファイル、またはJSON文字列へのパス。"
  },
  "Constant/Linear Starting Factor": {
    "key": "Constant/Linear Starting Factor",
    "tooltip": "Sets the initial learning rate to the main_lr * this value. If you had a target LR of .000006 and set this to .5, the scheduler would start at .000003 and increase until it reached .000006."
  },
  "Create From Hub": {
    "key": "ハブから作成",
    "tooltip": "ローカルチェックポイントを使用する代わりに、Huggingface.coからモデルをインポートします。ハブモデルには拡散ウエイトが含まれていなければなりません。クローンしたモデルでローカルフォルダを指定することができます。この場合、HFトークンは必要ありません。"
  },
  "Create Model": {
    "key": "モデルを作成",
    "tooltip": "新しいモデルを作成"
  },
  "Create": {
    "key": "作成",
    "tooltip": "Create the danged model already."
  },
  "Custom Model Name": {
    "key": "カスタムモデル名",
    "tooltip": ".ckptおよび.ptファイルを保存するときに使用するカスタム名です。サブディレクトリもこの名前になります。"
  },
  "Dataset Directory": {
    "key": "データセットディレクトリ",
    "tooltip": "学習用画像が格納されているディレクトリ"
  },
  "Debug Buckets": {
    "key": "Debug Buckets",
    "tooltip": "インスタンスとクラス・イメージを調べて、対応するクラス・イメージのないインスタンスイメージを報告します。"
  },
  "Discord Webhook": {
    "key": "DiscordをWebフォーク",
    "tooltip": "生成後にトレーニングサンプルをDiscordチャンネルに送信する"
  },
  "Existing Prompt Contents": {
    "key": "既存のプロンプトの内容",
    "tooltip": "If using [filewords], this tells the string builder how the existing prompts are formatted."
  },
  "Extract EMA Weights": {
    "key": "EMAウェイトを抽出",
    "tooltip": "EMAの重みがモデルに保存されている場合、完全なUnetの代わりに、これらが抽出されます。トレーニングや微調整にはおそらく必要ありません。"
  },
  "Freeze CLIP Normalization Layers": {
    "key": "CLIP正規化レイヤーを固定",
    "tooltip": "Keep the normalization layers of CLIP frozen during training. Advanced usage, may increase model performance and editability."
  },
  "Generate Ckpt": {
    "key": "Ckptを生成",
    "tooltip": "現在のトレーニングレベルでチェックポイントを生成します。"
  },
  "Generate Class Images": {
    "key": "クラス画像の生成",
    "tooltip": "トレーニングなしで、トレーニング設定を用いて分類画像を作成する。"
  },
  "Generate Classification Images Using txt2img": {
    "key": "Generate Classification Images Using txt2img",
    "tooltip": "ソース チェックポイントと TXT2IMG を使用してクラスイメージを生成します。"
  },
  "Generate Classification Images to match Instance Resolutions": {
    "key": "インスタンスの解像度に合わせた分類画像の生成",
    "tooltip": "正方形のクラス画像を生成するのではなく、クラス画像と同じ解像度(複数可) で生成します。"
  },
  "Generate Graph": {
    "key": "グラフを作成する",
    "tooltip": "トレーニングログからグラフを生成し、トレーニング中の学習率と損失平均を示します。"
  },
  "Generate Sample Images": {
    "key": "サンプル画像を生成",
    "tooltip": "Generate sample images using the currently saved diffusers model."
  },
  "Generate Samples": {
    "key": "サンプルを生成",
    "tooltip": "Trigger sample generation after the next training epoch."
  },
  "Generate a .ckpt file when saving during training.": {
    "key": "トレーニング中に保存するときに .ckpt ファイルを生成します。",
    "tooltip": "When enabled, a checkpoint will be generated at the specified epoch intervals while training is active. This also controls manual generation using the 'save weights' button while training is active."
  },
  "Generate a .ckpt file when training completes.": {
    "key": "トレーニングが完了したら.ckptファイルを生成します。",
    "tooltip": "有効にすると、トレーニングが正常に完了したときにチェックポイントが生成されます。"
  },
  "Generate a .ckpt file when training is cancelled.": {
    "key": "トレーニング中止時に.ckptファイルを生成する。",
    "tooltip": "有効にすると、ユーザーによってトレーニングがキャンセルされたときに、チェックポイントが生成されます。"
  },
  "Generate lora weights Generate lora weights for additional networks.": {
    "key": "Generate lora weights Generate lora weights for additional networks.",
    "tooltip": "有効にすると、追加ネットワークに対応したlora .safetensorsファイルがuiローラモデルディレクトリに生成されます。拡張ローラとは互換性がありません。"
  },
  "Generate lora weights when saving during training.": {
    "key": "Generate lora weights when saving during training.",
    "tooltip": "When enabled, lora .pt files will be generated at each specified epoch interval during training. This also affects whether .pt files will be generated when manually clicking the 'Save Weights' button."
  },
  "Generate lora weights when training completes.": {
    "key": "Generate lora weights when training completes.",
    "tooltip": "When enabled, lora .pt files will be generated when training completes."
  },
  "Generate lora weights when training is canceled.": {
    "key": "Generate lora weights when training is canceled.",
    "tooltip": "When enabled, lora .pt files will be generated when training is cancelled by the user."
  },
  "Gradient Accumulation Steps": {
    "key": "Gradient Accumulation Steps",
    "tooltip": "Number of updates steps to accumulate before performing a backward/update pass. You should try to make this the same as your batch size."
  },
  "Gradient Checkpointing": {
    "key": "チェックポイントの傾度",
    "tooltip": "This is a technique to reduce memory usage by clearing activations of certain layers and recomputing them during a backward pass. Effectively, this trades extra computation time for reduced memory usage."
  },
  "Graph Smoothing Steps": {
    "key": "グラフスムージングのステップ",
    "tooltip": "How many timesteps to smooth graph data over. A lower value means a more jagged graph with more information, higher value will make things prettier but slightly less accurate."
  },
  "Half Model": {
    "key": "ハーフモデル",
    "tooltip": "Enable this to generate model with fp16 precision. Results in a smaller checkpoint with minimal loss in quality."
  },
  "HuggingFace Token": {
    "key": "HuggingFace Token",
    "tooltip": "ファイルのクローンに使用するhuggingfaceトークン。"
  },
  "Instance Prompt": {
    "key": "インスタンスプロンプト",
    "tooltip": "A prompt describing the subject. Use [Filewords] to parse image filename/.txt to insert existing prompt here."
  },
  "Instance Token": {
    "key": "インスタンストークン",
    "tooltip": "When using [filewords], this is the instance identifier that is unique to your subject. Should be a single word."
  },
  "Learning Rate Scheduler": {
    "key": "学習率スケジューラー",
    "tooltip": "The learning rate scheduler to use. All schedulers use the provided warmup time except for 'constant'."
  },
  "Learning Rate Warmup Steps": {
    "key": "学習率ウォームアップのステップ",
    "tooltip": "Number of steps for the warmup in the lr scheduler. LR will start at 0 and increase to this value over the specified number of steps."
  },
  "Learning Rate": {
    "key": "学習率",
    "tooltip": "モデルが学習する割合。デフォルトは2e-6です。"
  },
  "Load Settings": {
    "key": "設定の読み込み",
    "tooltip": "最後に保存したモデルのトレーニングパラメータをロードします。"
  },
  "Log Memory": {
    "key": "ログメモリ",
    "tooltip": "現在のGPUメモリ使用量を記録します。"
  },
  "Lora Model": {
    "key": "Lora モデル",
    "tooltip": "The Lora model to load for continued fine-tuning or checkpoint generation."
  },
  "Use Lora Extended": {
    "key": "Lora 拡張を使用",
    "tooltip": "Loraモデルをレネットレイヤーで訓練します。これにより、品質と編集性が常に向上しますが、ファイルが大きくなります。"
  },
  "Lora UNET Rank": {
    "key": "Lora UNET ランク",
    "tooltip": "Lora UNETのランク(デフォルトは4) 。高い値＝ファイルサイズが大きくても品質が良い。低い値 = 低いファイルサイズで品質を犠牲にする。学習率はランクによって異なる働きをします。高精度(fp32) でロラを保存すると、ロラファイルが大きくなります。"
  },
  "Lora Text Encoder Rank": {
    "key": "Loraテキストエンコーダーランク",
    "tooltip": "Loraテキストエンコーダのランクです(デフォルト4) 。高い値＝ファイルサイズが大きくても品質が良い。低い値 = 低いファイルサイズで品質を犠牲にする。学習率は、ランクによって異なる働きをします。高精度(fp32) でLoraを保存すると、Loraファイルが大きくなります。"
  },
  "Lora Text Learning Rate": {
    "key": "Loraテキスト学習率",
    "tooltip": "The learning rate at which to train lora text encoder. Regular learning rate is ignored."
  },
  "Lora Text Weight": {
    "key": "Lora テキスト Weight",
    "tooltip": "チェックポイントを作成する際に、Lora Weightを何％テキストエンコーダーに適用するか。"
  },
  "Lora UNET Learning Rate": {
    "key": "LoraのUNET学習率",
    "tooltip": "Loraユニットを学習させる際の学習速度です。通常の学習速度は無視されます。"
  },
  "Lora Weight": {
    "key": "Lora Weight",
    "tooltip": "チェックポイントを作成する際に、ローラウェイトを何％ユニットに適用するか。"
  },
  "Max Resolution": {
    "key": "最大解像度",
    "tooltip": "The resolution of input images. When using bucketing, this is the maximum size of image buckets."
  },
  "Max Token Length": {
    "key": "最大トークンの長さ",
    "tooltip": "Maximum token length to respect. You probably want to leave this at 75."
  },
  "Memory Attention": {
    "key": "メモリに注意",
    "tooltip": "The type of memory attention to use. 'Xformers' will provide better performance than flash_attention, but requires a separate installation."
  },
  "Min Learning Rate": {
    "key": "最低学習率",
    "tooltip": "時間の経過とともに減少する最小学習率。"
  },
  "Mixed Precision": {
    "key": "Mixed Precision",
    "tooltip": "FP16またはBF16(利用可能な場合) を使用すると、メモリ性能が向上します。\"xformers\"を使用する場合は必須です。"
  },
  "Model Path": {
    "key": "モデルのパス",
    "tooltip": "The URL to the model on huggingface. Should be in the format of 'developer/model_name'."
  },
  "Model": {
    "key": "モデル",
    "tooltip": "トレーニングするモデル"
  },
  "Name": {
    "key": "名前",
    "tooltip": "作成するモデルの名前"
  },
  "Number of Hard Resets": {
    "key": "ハードリセット数",
    "tooltip": "Number of hard resets of the lr in cosine_with_restarts scheduler."
  },
  "Number of Samples to Generate": {
    "key": "生成するサンプル数",
    "tooltip": "テーマごとに生成するサンプル数"
  },
  "Offset Noise": {
    "key": "ノイズをオフセット",
    "tooltip": "Allows the model to learn brightness and contrast with greater detail during training. Value controls the strength of the effect, 0 disables it."
  },
  "Pad Tokens": {
    "key": "パッドトークン",
    "tooltip": "Pad the input images token length to this amount. You probably want to do this."
  },
  "Pause After N Epochs": {
    "key": "N エポック後に一時停止",
    "tooltip": "指定された時間にトレーニングが一時停止された後のエポックの数です。GPUに休憩を与えたい場合に便利です。"
  },
  "Performance Wizard (WIP)": {
    "key": "パフォーマンスウィザード (WIP)",
    "tooltip": "VRAMの総量に応じたトレーニングパラメータの自動設定を試みます。まだ開発中です。"
  },
  "Polynomial Power": {
    "key": "Polynomial Power",
    "tooltip": "Power factor of the polynomial scheduler."
  },
  "Pretrained VAE Name or Path": {
    "key": "事前訓練済みのVAE名またはパス",
    "tooltip": "To use an alternate VAE, you can specify the path to a directory containing a pytorch_model.bin representing your VAE."
  },
  "Preview Prompts": {
    "key": "プロンプトをプレビュー",
    "tooltip": "訓練に使用されるプロンプトデータの JSON 表現を生成する。"
  },
  "Prior Loss Weight": {
    "key": "Prior Loss Weight",
    "tooltip": "Prior loss weight."
  },
  "Sample CFG Scale": {
    "key": "サンプルCFGスケール",
    "tooltip": "The Classifier-Free Guidance Scale to use for preview images."
  },
  "Sample Image Prompt": {
    "key": "サンプル画像プロンプト:",
    "tooltip": "プレビュー画像の生成に使用するプロンプト。"
  },
  "Sample Negative Prompt": {
    "key": "ネガティブプロンプトのサンプル",
    "tooltip": "A negative prompt to use when generating preview images."
  },
  "Sample Prompt Template File": {
    "key": "サンプルプロンプトテンプレートファイル",
    "tooltip": "サンプルプロンプトに使用する txt ファイルへのパス。サンプル プロンプトにクラス トークンを挿入するには、 [filewords] または [name] を使用してください。"
  },
  "Sample Prompt": {
    "key": "サンプルプロンプト:",
    "tooltip": "サンプル イメージを生成するために使用するプロンプト"
  },
  "Sample Seed": {
    "key": "サンプルシード",
    "tooltip": "サンプル生成時に使用するシードです。毎回ランダムなシードを使用する場合は、-1 を設定します。"
  },
  "Sample Steps": {
    "key": "サンプルステップ",
    "tooltip": "分類画像/規則画像を生成する際に使用するステップ数。"
  },
  "Sanity Sample Prompt": {
    "key": "正常性確認用サンプルプロンプト",
    "tooltip": "モデルの忠実度を検証するために他のサンプルと一緒に作成される「ベースライン」イメージの生成に使用されるプロンプト。"
  },
  "Sanity Sample Seed": {
    "key": "正常性確認用サンプルシード値",
    "tooltip": "検証サンプル画像の生成時に使用するシード。-1 はサポートされていません。"
  },
  "Save Checkpoint to Subdirectory": {
    "key": "チェックポイントをサブディレクトリに保存",
    "tooltip": "有効にすると、チェックポイントは、選択したチェックポイントフォルダのサブディレクトリに保存されます。"
  },
  "Save Model Frequency (Epochs)": {
    "key": "モデルの頻度を保存 (エポック)",
    "tooltip": "N個のエポックごとにチェックポイントを保存する。"
  },
  "Save Model Frequency (Step)": {
    "key": "モデルの保存頻度 (ステップ)",
    "tooltip": "Nエポックごとにチェックポイントを保存します。バッチ数で割り切れる必要があります。"
  },
  "Save Preview(s) Frequency (Epochs)": {
    "key": "プレビュー保存頻度 (エポック数)",
    "tooltip": "N エポックごとにプレビュー画像を生成します。"
  },
  "Save Preview(s) Frequency (Step)": {
    "key": "プレビュー保存頻度 (ステップ数)",
    "tooltip": "プレビュー画像をNステップごとに生成します。バッチ数で割り切れる必要があります。"
  },
  "Save Settings": {
    "key": "設定を保存",
    "tooltip": "現在のトレーニングパラメータをモデルの設定ファイルに保存します。"
  },
  "Save Weights": {
    "key": "重みを保存",
    "tooltip": "Save weights/checkpoint/snapshot as specified in the saving section for saving 'during' training."
  },
  "Save and Test Webhook": {
    "key": "Webフォークの保存とテスト",
    "tooltip": "現在入力されているWebhookのURLを保存し、テストメッセージを送信します。"
  },
  "Save separate diffusers snapshots when saving during training.": {
    "key": "トレーニング中、ディフューザの重みのスナップショットを個別に保存する。",
    "tooltip": "有効にすると、指定したエポック間隔ごとにディフューザーの重みのスナップショットが一つ保存されます。これはHDDの容量を(非常に) 多く使いますが、オプティマイザーの状態も含めて学習を再開することができます。"
  },
  "Save separate diffusers snapshots when training completes.": {
    "key": "トレーニング完了時に、ディフューザーのスナップショットを別々に保存する。",
    "tooltip": "有効にすると、トレーニング完了時にディフューザーの重みのスナップショットが一つ保存されます。これはHDDの容量をより多く使いますが、オプティマイザーの状態も含めて学習を再開することができます。"
  },
  "Save separate diffusers snapshots when training is cancelled.": {
    "key": "Save separate diffusers snapshots when training is cancelled.",
    "tooltip": "When enabled, a unique snapshot of the diffusion weights will be saved when training is canceled. This uses more HDD space, but allows resuming from training including the optimizer state."
  },
  "Save EMA Weights to Generated Models": {
    "key": "EMA Weightを生成されたモデルに保存",
    "tooltip": "If a model was extracted or trained with EMA weights, these will be appended separately to the model for use in training later."
  },
  "Scale Position": {
    "key": "スケールの位置",
    "tooltip": "The percent in training where the 'final' learning rate should be achieved. If training at 100 epochs and this is set to 0.25, the final LR will be reached at epoch 25."
  },
  "Scheduler": {
    "key": "スケジューラー",
    "tooltip": "Model scheduler to use. Only applies to models before 2.0."
  },
  "Set Gradients to None When Zeroing": {
    "key": "Set Gradients to None When Zeroing",
    "tooltip": "When performing the backwards pass, gradients will be set to none, instead of creating a new empty tensor. This will slightly improve VRAM."
  },
  "Shuffle After Epoch": {
    "key": "エポック後シャッフル",
    "tooltip": "When enabled, will shuffle the dataset after the first epoch. Will enable text encoder training and latent caching (More VRAM)."
  },
  "Shuffle Tags": {
    "key": "タグをシャッフル",
    "tooltip": "When enabled, tags after the first ',' in a prompt will be randomly ordered, which can potentially improve training."
  },
  "Source Checkpoint": {
    "key": "ソースのチェックポイント",
    "tooltip": "The source checkpoint to extract for training."
  },
  "Step Ratio of Text Encoder Training": {
    "key": "Step Ratio of Text Encoder Training",
    "tooltip": "The number of steps per image (Epoch) to train the text encoder for. Set 0.5 for 50% of the epochs"
  },
  "Strict Tokens": {
    "key": "Strict Tokens",
    "tooltip": "Parses instance prompts separated by the following characters [,;.!?], and prevents breaking up tokens when using the tokenizer. Useful if you have prompts separated by a lot of tags."
  },
  "Total Number of Class/Reg Images": {
    "key": "Total Number of Class/Reg Images",
    "tooltip": "Total number of classification/regularization images to use. If no images exist, they will be generated. Set to 0 to disable prior preservation."
  },
  "Train Imagic Only": {
    "key": "画像のみでトレーニング",
    "tooltip": "Uses Imagic for training instead of full dreambooth, useful for training with a single instance image."
  },
  "Train Text Encoder": {
    "key": "テキストエンコーダを訓練する",
    "tooltip": "これを有効にすると、より良い結果と編集性が得られますが、より多くのVRAMを消費します。"
  },
  "Train": {
    "key": "学習",
    "tooltip": "トレーニングを開始"
  },
  "Training Steps Per Image (Epochs)": {
    "key": "イメージごとのトレーニングステップ (エポック)",
    "tooltip": "これは、各インスタンス画像に対して実行されるトレーニングステップの総数である。"
  },
  "Training Wizard (Object/Style)": {
    "key": "トレーニングウィザード (オブジェクト/スタイル)",
    "tooltip": "Calculate training parameters for a non-human subject based on number of instance images and set larning rate. Disables prior preservation."
  },
  "Training Wizard (Person)": {
    "key": "Training Wizard (Person)",
    "tooltip": "Calculate training parameters for a human subject based on number of instance images and set learning rate. Enables prior preservation."
  },
  "Unfreeze Model": {
    "key": "Unfreeze Model",
    "tooltip": "Unfreezes model layers and allows for potentially better training, but makes increased VRAM usage more likely."
  },
  "Use 8bit Adam": {
    "key": "Use 8bit Adam",
    "tooltip": "Enable this to save VRAM."
  },
  "Use CPU Only (SLOW)": {
    "key": "Use CPU Only (SLOW)",
    "tooltip": "Guess what - this will be incredibly slow, but it will work for < 8GB GPUs."
  },
  "Use Concepts List": {
    "key": "Use Concepts List",
    "tooltip": "Train multiple concepts from a JSON file or string."
  },
  "Use EMA": {
    "key": "EMAを使用",
    "tooltip": "Enabling this will provide better results and editability, but cost more VRAM."
  },
  "Use EMA Weights for Inference": {
    "key": "Use EMA Weights for Inference",
    "tooltip": "Enabling this will save the EMA unet weights as the 'normal' model weights and ignore the regular unet weights."
  },
  "Use Epoch Values for Save Frequency": {
    "key": "Use Epoch Values for Save Frequency",
    "tooltip": "When enabled, save frequencies below are based on number of epochs. When disabled, frequencies are based on number of training steps."
  },
  "Use LORA": {
    "key": "LORAを使用",
    "tooltip": "Uses Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning. Uses less VRAM, saves a .pt file instead of a full checkpoint"
  },
  "Use Lifetime Epochs When Saving": {
    "key": "Use Lifetime Epochs When Saving",
    "tooltip": "When checked, will save preview images and checkpoints using lifetime epochs, versus current training epochs."
  },
  "Use Lifetime Steps When Saving": {
    "key": "Use Lifetime Steps When Saving",
    "tooltip": "When checked, will save preview images and checkpoints using lifetime steps, versus current training steps."
  }
}
