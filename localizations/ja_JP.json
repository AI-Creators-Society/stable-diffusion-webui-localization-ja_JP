{
    "Loading...": "読み込み中...",
    "Use via API": "APIを通して利用する",
    "Built with Gradio": "Gradioでビルドされました。",
    "Stable Diffusion checkpoint": "Stable Diffusionのチェックポイント",
    "txt2img": "txt2img",
    "img2img": "img2img",
    "Extras": "その他",
    "PNG Info": "PNG内の情報を表示",
    "Checkpoint Merger": "チェックポイントのマージ",
    "Train": "学習",
    "Settings": "設定",
    "Extensions": "拡張機能",
    "Prompt": "プロンプト",
    "Negative prompt": "ネガティブプロンプト",
    "Interrupt": "中断",
    "Skip": "スキップ",
    "Generate": "生成",
    "Run": "実行",
    "Styles": "スタイル",
    "Label": "ラベル",
    "File": "ファイル",
    "Drop File Here": "ここにファイルをドロップ",
    "or": "または",
    "Click to Upload": "クリックしてアップロード",
    "Textual Inversion": "Textual Inversion",
    "Hypernetworks": "Hypernetworks",
    "Lora": "Lora",
    "Refresh": "リフレッシュ",
    "Close": "閉じる",
    "Nothing here. Add some content to the following directories:": "ここには何もありません。以下のディレクトリにコンテンツを追加してください。",
    "Textbox": "テキストボックス",
    "Save preview": "プレビューを保存",
    "Sampling method": "サンプリング方法",
    "Euler a": "Euler a",
    "Euler": "Euler",
    "LMS": "LMS",
    "Heun": "Heun",
    "DPM2": "DPM2",
    "DPM2 a": "DPM2 a",
    "DPM++ 2S a": "DPM++ 2S a",
    "DPM++ 2M": "DPM++ 2M",
    "DPM++ SDE": "DPM++ SDE",
    "DPM fast": "DPM fast",
    "DPM adaptive": "DPM adaptive",
    "LMS Karras": "LMS Karras",
    "DPM2 Karras": "DPM2 Karras",
    "DPM2 a Karras": "DPM2 a Karras",
    "DPM++ 2S a Karras": "DPM++ 2S a Karras",
    "DPM++ 2M Karras": "DPM++ 2M Karras",
    "DPM++ SDE Karras": "DPM++ SDE Karras",
    "DDIM": "DDIM",
    "PLMS": "PLMS",
    "Sampling steps": "サンプリングステップ数",
    "Width": "幅",
    "Height": "高さ",
    "Batch count": "バッチ回数",
    "Batch size": "バッチサイズ",
    "CFG Scale": "CFGスケール",
    "Seed": "シード",
    "Extra": "その他",
    "Variation seed": "変化用シード",
    "Variation strength": "変化の強度",
    "Resize seed from width": "画像幅を元にシードをリサイズする",
    "Resize seed from height": "画像の高さを元にシードをリサイズする",
    "Restore faces": "顔の修復",
    "Tiling": "タイル状の画像を生成",
    "Hires. fix": "高解像度補助",
    "Upscaler": "アップスケーラー",
    "Latent": "Latent",
    "Latent (antialiased)": "Latent（アンチエイリアス）",
    "Latent (bicubic)": "Latent（バイキュービック）",
    "Latent (bicubic antialiased)": "Latent（バイキュービック-アンチエイリアス）",
    "Latent (nearest)": "Latent（ニアレスト）",
    "Latent (nearest-exact)": "Latent（ニアレスト-正確）",
    "None": "なし",
    "Lanczos": "Lanczos",
    "Nearest": "Nearest",
    "ESRGAN_4x": "ESRGAN_4x",
    "R-ESRGAN 4x+": "R-ESRGAN 4x+",
    "R-ESRGAN 4x+ Anime6B": "R-ESRGAN 4x+ Anime6B",
    "LDSR": "LDSR",
    "ScuNET GAN": "ScuNET GAN",
    "ScuNET PSNR": "ScuNET PSNR",
    "SwinIR 4x": "SwinIR 4x",
    "Hires steps": "高解像度でのステップ数",
    "Denoising strength": "ノイズ除去強度",
    "Upscale by": "アップスケール倍率",
    "Resize width to": "幅のサイズ変更",
    "Resize height to": "高さのサイズ変更",
    "Script": "スクリプト",
    "Prompt matrix": "プロンプトマトリックス",
    "Prompts from file or textbox": "ファイルまたはテキストボックスからプロンプトを表示",
    "X/Y plot": "X/Yプロット",
    "Put variable parts at start of prompt": "プロンプトの最初に変数部を配置",
    "Use different seed for each picture": "画像ごとに異なるシードを使用する",
    "Iterate seed every line": "毎行シードを変える",
    "Use same random seed for all lines": "すべての行に同じランダムシードを使用",
    "List of prompt inputs": "プロンプトのリスト",
    "Upload prompt inputs": "プロンプトの入力をアップロードする",
    "Nothing": "なし",
    "Var. seed": "Var. seed",
    "Var. strength": "Var. strength",
    "Steps": "ステップ数",
    "Prompt S/R": "Prompt S/R",
    "Prompt order": "Prompt order",
    "Sampler": "サンプラー",
    "Checkpoint name": "Checkpoint名",
    "Sigma Churn": "Sigma Churn",
    "Sigma min": "Sigma min",
    "Sigma max": "Sigma max",
    "Sigma noise": "Sigma noise",
    "Eta": "Eta",
    "Clip skip": "Clip skip",
    "Denoising": "ノイズ除去",
    "Hires upscaler": "高解像度アップスケーラー",
    "VAE": "VAE",
    "X type": "X軸の種類",
    "X values": "X軸の値",
    "Y type": "Y軸の種類",
    "Y values": "Y軸の値",
    "Z type": "Z軸の種類",
    "Z values": "Z軸の値",
    "Draw legend": "凡例を描画",
    "Include Sub Images": "サブ画像を含める",
    "Keep -1 for seeds": "シード値を-1で固定",
    "Include Sub Grids": "サブグリッドを含める",
    "Grid margins (px)": "グリッド間隔(px)",
    "Swap X/Y axes": "X/Y軸を入れ替える",
    "Swap Y/Z axes": "Y/Z軸を入れ替える",
    "Swap X/Z axes": "X/Z軸を入れ替える",
    "Save": "保存",
    "Zip": "Zip",
    "Send to img2img": "img2imgに転送",
    "Send to inpaint": "レタッチに転送",
    "Send to extras": "その他に転送",
    "Interrogate\nCLIP": "CLIPによる解析",
    "Interrogate\nDeepBooru": "DeepBooruによる解析",
    "Sketch": "スケッチ",
    "Inpaint": "レタッチ(Inpaint)",
    "Inpaint sketch": "Inpaintスケッチ",
    "Inpaint upload": "Inpaintアップロード",
    "Batch": "バッチ",
    "Image for img2img": "img2imgで使用する画像",
    "Drop Image Here": "ここに画像をドロップ",
    "Copy image to:": "次の場所へ画像をコピー:",
    "sketch": "スケッチ",
    "inpaint": "inpaint",
    "inpaint sketch": "inpaintスケッチ",
    "Image for inpainting with mask": "Image for inpainting with mask",
    "Color sketch inpainting": "Color sketch inpainting",
    "Mask": "マスク",
    "Process images in a directory on the same machine where the server is running.": "サーバーが稼働しているマシンと同じフォルダにある画像を処理します",
    "Use an empty output directory to save pictures normally instead of writing to the output directory.": "\"出力フォルダ\"を空にすると、通常の画像と同様に保存されます。",
    "Input directory": "入力フォルダ",
    "Output directory": "出力フォルダ",
    "Resize mode": "リサイズモード",
    "Just resize": "リサイズのみ",
    "Crop and resize": "切り取ってからリサイズ",
    "Resize and fill": "リサイズして埋める",
    "Just resize (latent upscale)": "リサイズ(latent アップスケール)",
    "Mask blur": "マスクぼかし",
    "Mask transparency": "マスクの透明度",
    "Mask mode": "マスクモード",
    "Inpaint masked": "マスクされた場所をレタッチ",
    "Inpaint not masked": "マスクされていない場所をレタッチ",
    "Masked content": "マスクされたコンテンツ",
    "fill": "埋める",
    "original": "オリジナル",
    "latent noise": "潜在空間でのノイズ",
    "latent nothing": "潜在空間における無",
    "Inpaint area": "画像を修復する範囲",
    "Whole picture": "全体像",
    "Only masked": "マスクのみ",
    "Only masked padding, pixels": "マスクされたパディングのみ(ピクセル)",
    "img2img alternative test": "img2img alternative test",
    "Loopback": "ループバック",
    "Outpainting mk2": "Outpainting mk2",
    "Poor man's outpainting": "Poor man's outpainting",
    "SD upscale": "SDアップスケール",
    "should be 2 or lower.": "2以下にすること",
    "Override `Sampling method` to Euler?(this method is built for it)": "サンプリングアルゴリズムをEulerに上書き(そうすることを前提に設計されています)",
    "Override `prompt` to the same value as `original prompt`?(and `negative prompt`)": "プロンプトをオリジナルプロンプトと同じ値に上書きする(ネガティブプロンプトも同様)",
    "Original prompt": "オリジナルのプロンプト",
    "Original negative prompt": "オリジナルのネガティブプロンプト",
    "Override `Sampling Steps` to the same value as `Decode steps`?": "サンプリング数をデコードステップ数と同じ値に上書きする",
    "Decode steps": "デコードステップ数",
    "Override `Denoising strength` to 1?": "ノイズ除去強度を1に上書きする",
    "Decode CFG scale": "CFGスケールをデコード",
    "Randomness": "ランダム性",
    "Sigma adjustment for finding noise for image": "画像のノイズを見つけるためのシグマの調整",
    "Loops": "ループ数",
    "Denoising strength change factor": "ノイズ除去強度変化率",
    "Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8": "推奨設定: サンプリング回数: 80-100, サンプリングアルゴリズム: Euler a, ノイズ除去強度: 0.8",
    "Pixels to expand": "拡大するピクセル数",
    "Outpainting direction": "アウトペインティングの方向",
    "left": "左",
    "right": "右",
    "up": "上",
    "down": "下",
    "Fall-off exponent (lower=higher detail)": "フォールオフ指数(低いほど細かい)",
    "Color variation": "カラーバリエーション",
    "Will upscale the image by the selected scale factor; use width and height sliders to set tile size": "選択した倍率で画像を拡大します; 幅と高さのスライダを使ってタイルの大きさを設定します",
    "Tile overlap": "境界の重なり具合",
    "Scale Factor": "倍率",
    "Cond. Image Mask Weight": "Cond. Image Mask Weight",
    "Single Image": "単一画像",
    "Batch Process": "バッチ処理",
    "Batch from Directory": "フォルダからバッチ処理",
    "Source": "入力",
    "Show result images": "出力画像を表示",
    "Scale by": "倍率指定",
    "Scale to": "解像度指定",
    "Resize": "倍率",
    "Crop to fit": "合うように切り抜き",
    "Upscaler 2 visibility": "Upscaler 2 visibility",
    "GFPGAN visibility": "GFPGAN visibility",
    "CodeFormer visibility": "CodeFormer visibility",
    "CodeFormer weight (0 = maximum effect, 1 = minimum effect)": "CodeFormerの重み (注:0で最大、1で最小)",
    "Send to txt2img": "txt2imgに転送",
    "A weighted sum will be used for interpolation. Requires two models; A and B. The result is calculated as A * (1 - M) + B * M": "A weighted sum will be used for interpolation. Requires two models; A and B. The result is calculated as A * (1 - M) + B * M",
    "Primary model (A)": "最初のmodel (A)",
    "Secondary model (B)": "2つ目のmodel (B)",
    "Tertiary model (C)": "3つ目のmodel (C)",
    "Custom Name (Optional)": "名前 (任意)",
    "Multiplier (M) - set to 0 to get model A": "Multiplier (M) 0にすると完全にmodel Aとなります (ツールチップ参照)",
    "Interpolation Method": "混合(Interpolation)方式",
    "No interpolation": "No interpolation",
    "Weighted sum": "加重平均",
    "Add difference": "差を加える",
    "Checkpoint format": "チェックポイントのフォーマット",
    "ckpt": "ckpt",
    "safetensors": "safetensors",
    "Save as float16": "float16で保存",
    "Copy config from": "ここからコンフィグをコピーします",
    "A, B or C": "A、BまたはC",
    "B": "B",
    "C": "C",
    "Don't": "Don't",
    "Bake in VAE": "Bake in VAE",
    "Discard weights with matching name": "Discard weights with matching name",
    "Merge": "マージ",
    "See": "詳細な説明については",
    "wiki": "wiki",
    "for detailed explanation.": "を参照。",
    "Create embedding": "Embeddingを作成",
    "Create hypernetwork": "Hypernetworkを作成",
    "Preprocess images": "画像の前処理",
    "Name": "名称",
    "Initialization text": "初期設定用テキスト",
    "Number of vectors per token": "トークン毎のベクトル数",
    "Overwrite Old Embedding": "古いEmbeddingを上書き",
    "Modules": "モジュール",
    "Enter hypernetwork layer structure": "Hypernetworkのレイヤー構造を入力",
    "Select activation function of hypernetwork. Recommended : Swish / Linear(none)": "Hypernetworkの活性化関数(activation function)を選択。 推奨: Swish / Linear(none)",
    "linear": "linear",
    "relu": "relu",
    "leakyrelu": "leakyrelu",
    "elu": "elu",
    "swish": "swish",
    "tanh": "tanh",
    "sigmoid": "sigmoid",
    "celu": "celu",
    "gelu": "gelu",
    "glu": "glu",
    "hardshrink": "hardshrink",
    "hardsigmoid": "hardsigmoid",
    "hardtanh": "hardtanh",
    "logsigmoid": "logsigmoid",
    "logsoftmax": "logsoftmax",
    "mish": "mish",
    "prelu": "prelu",
    "rrelu": "rrelu",
    "relu6": "relu6",
    "selu": "selu",
    "silu": "silu",
    "softmax": "softmax",
    "softmax2d": "softmax2d",
    "softmin": "softmin",
    "softplus": "softplus",
    "softshrink": "softshrink",
    "softsign": "softsign",
    "tanhshrink": "tanhshrink",
    "threshold": "しきい値",
    "Select Layer weights initialization. Recommended: Kaiming for relu-like, Xavier for sigmoid-like, Normal otherwise": "レイヤーウェイトの初期化を選択します。(推奨): Kaimingはrelu-like、Xavierはsigmoid-like、それ以外はNormalを推奨します。",
    "Normal": "Normal",
    "KaimingUniform": "KaimingUniform",
    "KaimingNormal": "KaimingNormal",
    "XavierUniform": "XavierUniform",
    "XavierNormal": "XavierNormal",
    "Add layer normalization": "レイヤーの正規化を追加",
    "Use dropout": "Dropoutを使う",
    "Enter hypernetwork Dropout structure (or empty). Recommended : 0~0.35 incrementing sequence: 0, 0.05, 0.15": "Enter hypernetwork Dropout structure (or empty). Recommended : 0~0.35 incrementing sequence: 0, 0.05, 0.15",
    "Overwrite Old Hypernetwork": "古いHypernetworkを上書きする",
    "Source directory": "入力フォルダ",
    "Destination directory": "出力フォルダ",
    "Existing Caption txt Action": "既存のキャプションの取り扱い",
    "ignore": "無視する",
    "copy": "コピーする",
    "prepend": "先頭に加える",
    "append": "末尾に加える",
    "Create flipped copies": "反転画像を生成する",
    "Split oversized images": "巨大な画像を分割する",
    "Auto focal point crop": "自動で焦点をクロップ",
    "Auto-sized crop": "Auto-sized crop",
    "Use BLIP for caption": "BLIPで説明をつける",
    "Use deepbooru for caption": "deepbooruで説明をつける",
    "Split image threshold": "分割する大きさのしきい値",
    "Split image overlap ratio": "Split image overlap ratio",
    "Focal point face weight": "焦点面のウェイト",
    "Focal point entropy weight": "焦点エントロピーのウェイト",
    "Focal point edges weight": "焦点辺のウェイト",
    "Create debug image": "デバッグイメージの作成",
    "Each image is center-cropped with an automatically chosen width and height.": "Each image is center-cropped with an automatically chosen width and height.",
    "Dimension lower bound": "Dimension lower bound",
    "Dimension upper bound": "Dimension upper bound",
    "Area lower bound": "Area lower bound",
    "Area upper bound": "Area upper bound",
    "Resizing objective": "Resizing objective",
    "Maximize area": "Maximize area",
    "Minimize error": "Minimize error",
    "Error threshold": "Error threshold",
    "Preprocess": "前処理開始",
    "Train an embedding or Hypernetwork; you must specify a directory with a set of 1:1 ratio images": "EmbeddingまたはHypernetworkを学習します。1:1の比率の画像セットを含むフォルダを指定する必要があります。",
    "[wiki]": "[wiki]",
    "Embedding": "Embedding",
    "Hypernetwork": "Hypernetwork",
    "Embedding Learning rate": "Embeddingの学習率(Learning rate)",
    "Hypernetwork Learning rate": "Hypernetworkの学習率(Learning rate)",
    "Gradient Clipping": "Gradient Clipping",
    "disabled": "無効",
    "value": "値",
    "norm": "norm",
    "Gradient accumulation steps": "Gradient蓄積ステップ",
    "Dataset directory": "データセットフォルダ",
    "Log directory": "ログフォルダ",
    "Prompt template": "Prompt template",
    "Do not resize images": "Do not resize images",
    "Max steps": "最大ステップ数",
    "Save an image to log directory every N steps, 0 to disable": "指定したステップ数ごとに画像を生成し、ログに保存する。0で無効化。",
    "Save a copy of embedding to log directory every N steps, 0 to disable": "指定したステップ数ごとにEmbeddingのコピーをログに保存する。0で無効化。",
    "Use PNG alpha channel as loss weight": "Use PNG alpha channel as loss weight",
    "Save images with embedding in PNG chunks": "保存する画像にembeddingを埋め込む",
    "Read parameters (prompt, etc...) from txt2img tab when making previews": "プレビューの作成にtxt2imgタブから読み込んだパラメータ(プロンプトなど)を使う",
    "Shuffle tags by ',' when creating prompts.": "プロンプト作成時にタグを ',' 区切りでシャッフルする。",
    "Drop out tags when creating prompts.": "プロンプト作成時にタグをドロップアウトする",
    "Choose latent sampling method": "Latentのサンプリングメゾッドを選択",
    "once": "once",
    "deterministic": "deterministic",
    "random": "ランダム",
    "Train Embedding": "Embeddingの学習を開始",
    "Train Hypernetwork": "Hypernetworkの学習を開始",
    "Apply settings": "設定を適用",
    "Reload UI": "UIの再読み込み",
    "Saving images/grids": "画像/グリッドの保存",
    "Paths for saving": "保存する場所",
    "Saving to a directory": "フォルダについて",
    "Upscaling": "アップスケール",
    "Face restoration": "顔の修復",
    "System": "システム設定",
    "Training": "学習",
    "Stable Diffusion": "Stable Diffusion",
    "Compatibility": "Compatibility",
    "Interrogate Options": "Interrogate設定",
    "Extra Networks": "Extra Networks",
    "User interface": "UI設定",
    "Live previews": "Live previews",
    "Sampler parameters": "サンプラーのパラメータ",
    "Postprocessing": "Postprocessing",
    "Actions": "Actions",
    "Licenses": "ライセンス",
    "Always save all generated images": "生成された画像をすべて保存する",
    "File format for images": "画像ファイルの保存形式",
    "Images filename pattern": "ファイル名のパターン",
    "Add number to filename when saving": "保存時にファイル名に番号を付加する",
    "Always save all generated image grids": "グリッド画像を常に保存する",
    "File format for grids": "グリッド画像の保存形式",
    "Add extended info (seed, prompt) to filename when saving grid": "保存するグリッド画像のファイル名に追加情報(シード値、プロンプト)を加える",
    "Do not save grids consisting of one picture": "1画像からなるグリッド画像は保存しない",
    "Prevent empty spots in grid (when set to autodetect)": "(自動設定のとき)グリッドに空隙が生じるのを防ぐ",
    "Grid row count; use -1 for autodetect and 0 for it to be same as batch size": "グリッドの列数; -1で自動設定、0でバッチ生成回数と同じにする",
    "Save text information about generation parameters as chunks to png files": "生成に関するパラメーターをPNG画像に含める",
    "Create a text file next to every image with generation parameters.": "保存する画像とともに生成パラメータをテキストファイルで保存する",
    "Save a copy of image before doing face restoration.": "顔の修復を行う前に元画像のコピーを保存しておく。",
    "Save a copy of image before applying highres fix.": "高解像度補助を行う前に元画像のコピーを保存しておく",
    "Save a copy of image before applying color correction to img2img results": "色補正をする前の画像も保存する",
    "Quality for saved jpeg images": "JPG画像保存時の画質",
    "If the saved image file size is above the limit, or its either width or height are above the limit, save a downscaled copy as JPG": "If the saved image file size is above the limit, or its either width or height are above the limit, save a downscaled copy as JPG",
    "File size limit for the above option, MB": "File size limit for the above option, MB",
    "Width/height limit for the above option, in pixels": "Width/height limit for the above option, in pixels",
    "Use original name for output filename during batch process in extras tab": "その他タブでバッチ処理をする際、元のファイル名を出力ファイル名に使う",
    "Use upscaler name as filename suffix in the extras tab": "Use upscaler name as filename suffix in the extras tab",
    "When using 'Save' button, only save a single selected image": "\"保存\"ボタンを使うとき、単一の選択された画像のみを保存する",
    "Do not add watermark to images": "電子透かしを画像に追加しない",
    "Directory for temporary images; leave empty for default": "Directory for temporary images; leave empty for default",
    "Cleanup non-default temporary directory when starting webui": "Cleanup non-default temporary directory when starting webui",
    "Output directory for images; if empty, defaults to three directories below": "画像の保存先フォルダ(下項目のデフォルト値になります)",
    "Output directory for txt2img images": "txt2imgで作った画像の保存先フォルダ",
    "Output directory for img2img images": "img2imgで作った画像の保存先フォルダ",
    "Output directory for images from extras tab": "その他タブで作った画像の保存先フォルダ",
    "Output directory for grids; if empty, defaults to two directories below": "画像の保存先フォルダ(下項目のデフォルト値になります)",
    "Output directory for txt2img grids": "txt2imgで作ったグリッドの保存先フォルダ",
    "Output directory for img2img grids": "img2imgで作ったグリッドの保存先フォルダ",
    "Directory for saving images using the Save button": "保存ボタンを押したときの画像の保存先フォルダ",
    "Save images to a subdirectory": "画像をサブフォルダに保存する",
    "Save grids to a subdirectory": "グリッドをサブフォルダに保存する",
    "When using \"Save\" button, save images to a subdirectory": "保存ボタンを押した時、画像をサブフォルダに保存する",
    "Directory name pattern": "フォルダ名のパターン",
    "Max prompt words for [prompt_words] pattern": "Max prompt words for [prompt_words] pattern",
    "Tile size for ESRGAN upscalers. 0 = no tiling.": "ESRGANのタイルサイズ。0とするとタイルしない。",
    "Tile overlap, in pixels for ESRGAN upscalers. Low values = visible seam.": "ESRGANのタイルの重複部分のピクセル数。少なくするとつなぎ目が見えやすくなる。",
    "Select which Real-ESRGAN models to show in the web UI. (Requires restart)": "Select which Real-ESRGAN models to show in the web UI. (Requires restart)",
    "Upscaler for img2img": "img2imgで使うアップスケーラー",
    "LDSR processing steps. Lower = faster": "LDSRの処理ステップ(低いほど速い)",
    "Cache LDSR model in memory": "Cache LDSR model in memory",
    "Tile size for all SwinIR.": "SwinIRのタイルサイズ",
    "Tile overlap, in pixels for SwinIR. Low values = visible seam.": "SwinIRのタイルの重複部分のピクセル数。少なくするとつなぎ目が見えやすくなる。",
    "Face restoration model": "Face restoration model",
    "CodeFormer weight parameter; 0 = maximum effect; 1 = minimum effect": "CodeFormerの重みパラメーター;0が最大で1が最小",
    "Move face restoration model from VRAM into RAM after processing": "処理終了後、顔の修復モデルをVRAMからRAMへと移動する",
    "Show warnings in console.": "Show warnings in console.",
    "VRAM usage polls per second during generation. Set to 0 to disable.": "生成中のVRAM使用率の取得間隔。0にすると取得しない。",
    "Always print all generation info to standard output": "常にすべての生成に関する情報を標準出力(stdout)に出力する",
    "Add a second progress bar to the console that shows progress for an entire job.": "ジョブ全体の進捗をコンソールに表示する2つ目のプログレスバーを追加する",
    "Print extra hypernetwork information to console.": "Print extra hypernetwork information to console.",
    "Move VAE and CLIP to RAM when training if possible. Saves VRAM.": "hypernetworkの学習をする際、VAEとCLIPをRAMへ退避。VRAMが節約できます。",
    "Turn on pin_memory for DataLoader. Makes training slightly faster but can increase memory usage.": "Turn on pin_memory for DataLoader. Makes training slightly faster but can increase memory usage.",
    "Saves Optimizer state as separate *.optim file. Training of embedding or HN can be resumed with the matching optim file.": "Optimizerの状態を別の*.optimファイルとして保存します。 埋め込みまたはHNのトレーニングは、一致するoptimファイルで再開できます。",
    "Save textual inversion and hypernet settings to a text file whenever training starts.": "トレーニングの開始時にテキストの反転とハイパーネット設定をテキストファイルに保存します。",
    "Filename word regex": "ファイル名の正規表現(学習用)",
    "Filename join string": "ファイル名の結合子",
    "Number of repeats for a single input image per epoch; used only for displaying epoch number": "Number of repeats for a single input image per epoch; used only for displaying epoch number",
    "Save an csv containing the loss to log directory every N steps, 0 to disable": "指定したステップ数ごとにlossなどのログをcsvに保存する。0で無効化。",
    "Use cross attention optimizations while training": "トレーニング中にクロスアテンションの最適化を使用する",
    "Enable tensorboard logging.": "Enable tensorboard logging.",
    "Save generated images within tensorboard.": "Save generated images within tensorboard.",
    "How often, in seconds, to flush the pending tensorboard events and summaries to disk.": "How often, in seconds, to flush the pending tensorboard events and summaries to disk.",
    "Checkpoints to cache in RAM": "RAMにキャッシュするCheckpoint数",
    "VAE Checkpoints to cache in RAM": "VAE Checkpoints to cache in RAM",
    "SD VAE": "SD VAE",
    "Automatic": "Automatic",
    "Ignore selected VAE for stable diffusion checkpoints that have their own .vae.pt next to them": "チェックポイントに対応するファイル名の.vae.ptがあるなら、選択されたVAEを無視する",
    "Inpainting conditioning mask strength": "Inpainting conditioning mask strength",
    "Noise multiplier for img2img": "Noise multiplier for img2img",
    "Apply color correction to img2img results to match original colors.": "元画像に合わせてimg2imgの結果を色補正する",
    "With img2img, do exactly the amount of steps the slider specifies (normally you'd do less with less denoising).": "img2imgでスライダーで指定されたステップ数を正確に実行する（通常は、ノイズ除去を少なくするためにより少ないステップ数で実行します）。",
    "With img2img, fill image's transparent parts with this color.": "With img2img, fill image's transparent parts with this color.",
    "Enable quantization in K samplers for sharper and cleaner results. This may change existing seeds. Requires restart to apply.": "より良い結果を得るために、Kサンプラーで量子化を有効にします。これにより既存のシードが変更される可能性があります。適用するには再起動が必要です。",
    "Emphasis: use (text) to make model pay more attention to text and [text] to make it pay less attention": "強調: (text)とするとモデルはtextをより強く扱い、[text]とするとモデルはtextをより弱く扱います。",
    "Make K-diffusion samplers produce same images in a batch as when making a single image": "K-diffusionサンプラーによるバッチ生成時に、単一画像生成時と同じ画像を生成する",
    "Increase coherency by padding from the last comma within n tokens when using more than 75 tokens": "75トークン以上を使用する場合、nトークン内の最後のカンマからパディングして一貫性を高める",
    "Upcast cross attention layer to float32": "Upcast cross attention layer to float32",
    "Multiplier for extra networks": "Multiplier for extra networks",
    "Add hypernetwork to prompt": "Add hypernetwork to prompt",
    "Add Lora to prompt": "Add Lora to prompt",
    "Apply Lora to outputs rather than inputs when possible (experimental)": "Apply Lora to outputs rather than inputs when possible (experimental)",
    "Use old emphasis implementation. Can be useful to reproduce old seeds.": "古い強調の実装を使う。古い生成物を再現するのに使えます。",
    "Use old karras scheduler sigmas (0.1 to 10).": "Use old karras scheduler sigmas (0.1 to 10).",
    "Do not make DPM++ SDE deterministic across different batch sizes.": "Do not make DPM++ SDE deterministic across different batch sizes.",
    "For hires fix, use width/height sliders to set final resolution rather than first pass (disables Upscale by, Resize width/height to).": "For hires fix, use width/height sliders to set final resolution rather than first pass (disables Upscale by, Resize width/height to).",
    "Interrogate: keep models in VRAM": "Interrogate: モデルをVRAMに保持する",
    "Interrogate: include ranks of model tags matches in results (Has no effect on caption-based interrogators).": "Interrogate: include ranks of model tags matches in results (Has no effect on caption-based interrogators).",
    "Interrogate: num_beams for BLIP": "Interrogate: num_beams for BLIP",
    "Interrogate: minimum description length (excluding artists, etc..)": "Interrogate: minimum description length (excluding artists, etc..)",
    "Interrogate: maximum description length": "Interrogate: maximum description length",
    "CLIP: maximum number of lines in text file (0 = No limit)": "CLIP: maximum number of lines in text file (0 = No limit)",
    "CLIP: skip inquire categories": "CLIP: skip inquire categories",
    "Interrogate: deepbooru score threshold": "Interrogate: deepbooruで拾う単語のスコアしきい値",
    "Interrogate: deepbooru sort alphabetically": "Interrogate: deepbooruで単語をアルファベット順に並べる",
    "use spaces for tags in deepbooru": "deepbooruのタグでスペースを使う",
    "escape (\\) brackets in deepbooru (so they are used as literal brackets and not for emphasis)": "deepbooruで括弧をエスケープする(\\) (強調を示す()ではなく、文字通りの()であることをモデルに示すため)",
    "filter out those tags from deepbooru output (separated by comma)": "filter out those tags from deepbooru output (separated by comma)",
    "Default view for Extra Networks": "Default view for Extra Networks",
    "cards": "cards",
    "thumbs": "thumbs",
    "Show grid in results for web": "WebUI上でグリッド表示",
    "Do not show any images in results for web": "WebUI上で一切画像を表示しない",
    "Add model hash to generation information": "モデルのハッシュ値を生成情報に追加",
    "Add model name to generation information": "モデルの名称を生成情報に追加",
    "When reading generation parameters from text into UI (from PNG info or pasted text), do not change the selected model/checkpoint.": "テキストからUIに生成パラメータを読み込む場合(PNG情報または貼り付けられたテキストから)、選択されたモデル/チェックポイントは変更しない。",
    "Send seed when sending prompt or image to other interface": "Send seed when sending prompt or image to other interface",
    "Send size when sending prompt or image to another interface": "Send size when sending prompt or image to another interface",
    "Font for image grids that have text": "画像グリッド内のテキストフォント",
    "Enable full page image viewer": "フルページの画像ビューワーを有効化",
    "Show images zoomed in by default in full page image viewer": "フルページ画像ビューアでデフォルトで画像を拡大して表示する",
    "Show generation progress in window title.": "ウィンドウのタイトルで生成の進捗を表示",
    "Use dropdown for sampler selection instead of radio group": "Use dropdown for sampler selection instead of radio group",
    "Show Width/Height and Batch sliders in same row": "Show Width/Height and Batch sliders in same row",
    "Ctrl+up/down precision when editing (attention:1.1)": "Ctrl+up/down precision when editing (attention:1.1)",
    "Ctrl+up/down precision when editing <extra networks:0.9>": "Ctrl+up/down precision when editing <extra networks:0.9>",
    "Quicksettings list": "クイック設定",
    "txt2img/img2img UI item order": "txt2img/img2img UI item order",
    "Extra networks tab order": "Extra networks tab order",
    "Localization (requires restart)": "言語 (プログラムの再起動が必要)",
    "Show progressbar": "プログレスバーを表示",
    "Show live previews of the created image": "Show live previews of the created image",
    "Show previews of all images generated in a batch as a grid": "Show previews of all images generated in a batch as a grid",
    "Show new live preview image every N sampling steps. Set to -1 to show after completion of batch.": "Show new live preview image every N sampling steps. Set to -1 to show after completion of batch.",
    "Image creation progress preview mode": "Image creation progress preview mode",
    "Full": "フル",
    "Approx NN": "Approx NN",
    "Approx cheap": "Approx cheap",
    "Live preview subject": "Live preview subject",
    "Combined": "Combined",
    "Progressbar/preview update period, in milliseconds": "Progressbar/preview update period, in milliseconds",
    "Hide samplers in user interface (requires restart)": "使わないサンプリングアルゴリズムを隠す (再起動が必要)",
    "eta (noise multiplier) for DDIM": "DDIMで用いるeta (noise multiplier)",
    "eta (noise multiplier) for ancestral samplers": "Ancestralサンプラーで用いるeta (noise multiplier)",
    "img2img DDIM discretize": "img2img DDIM discretize",
    "uniform": "uniform",
    "quad": "quad",
    "sigma churn": "sigma churn",
    "sigma tmin": "sigma tmin",
    "sigma noise": "sigma noise",
    "Eta noise seed delta": "Eta noise seed delta",
    "Always discard next-to-last sigma": "Always discard next-to-last sigma",
    "Enable postprocessing operations in txt2img and img2img tabs": "Enable postprocessing operations in txt2img and img2img tabs",
    "Postprocessing operation order": "Postprocessing operation order",
    "Maximum number of images in upscaling cache": "upscalingキャッシュの最大枚数",
    "Request browser notifications": "ブラウザに通知の許可を要求",
    "Download localization template": "ローカライズ用テンプレートをダウンロード",
    "Reload custom script bodies (No ui updates, No restart)": "カスタムスクリプトを再読込 (UIは変更されず、再起動もしません。)",
    "Show all pages": "すべてのページを表示",
    "Installed": "インストール済",
    "Available": "拡張機能リスト",
    "Install from URL": "URLからインストール",
    "Apply and restart UI": "適用してUIを再起動",
    "Check for updates": "アップデートを確認",
    "Extension": "拡張機能",
    "Use checkbox to enable the extension; it will be enabled or disabled when you click apply button": "有効化する拡張機能をチェックボックスで選択してください。。反映ボタンを押すと有効化、または無効化されます。",
    "URL": "URL",
    "Version": "バージョン",
    "Extension version": "拡張機能のバージョン",
    "Update": "アップデート",
    "Use checkbox to mark the extension for update; it will be updated when you click apply button": "アップデートする拡張機能をチェックボックスで選択してください。反映ボタンをクリックするとアップデートされます。",
    "built-in": "ビルトイン",
    "latest": "最新",
    "behind": "behind",
    "Error": "エラー",
    "unknown": "不明",
    "ScuNET": "ScuNET",
    "prompt-bracket-checker": "prompt-bracket-checker",
    "Load from:": "読込",
    "Extension index URL": "拡張機能リストのURL",
    "Hide extensions with tags": "タグで拡張機能を隠す",
    "script": "スクリプト",
    "ads": "広告",
    "localization": "言語",
    "installed": "インストール済",
    "training": "トレーニング",
    "models": "モデル",
    "UI related": "UI関連",
    "prompting": "prompting",
    "editing": "editing",
    "manipulations": "manipulations",
    "online": "オンライン",
    "animation": "アニメーション",
    "query": "クエリ",
    "science": "science",
    "Order": "順序",
    "newest first": "新しい順",
    "oldest first": "古い順",
    "a-z": "a-z",
    "z-a": "z-a",
    "internal order": "内部順序",
    "Description": "説明",
    "URL for extension's git repository": "拡張機能のリポジトリのURL",
    "Local directory name": "ローカルディレクトリ",
    "Install": "インストール",
    "API": "API",
    "Github": "Github",
    "Gradio": "Gradio",
    "python": "python",
    "N/A": "N/A",
    "Prompt (press Ctrl+Enter or Alt+Enter to generate)": "プロンプト (Ctrl+Enter か Alt+Enter を押して生成)",
    "Negative prompt (press Ctrl+Enter or Alt+Enter to generate)": "ネガティブプロンプト (Ctrl+Enter か Alt+Enter を押して生成)",
    "Stop processing images and return any results accumulated so far.": "処理を中断し、それまでに出来た結果を表示",
    "Stop processing current image and continue processing.": "現在行っている処理を中断し、その次以降の処理を継続",
    "Read generation parameters from prompt or last generation if prompt is empty into user interface.": "プロンプトから生成パラメータを読み込むか、プロンプトが空の場合は最後の生成パラメータをUIに読み込む。",
    "Show extra networks": "Show extra networks",
    "Apply selected styles to current prompt": "現在のプロンプトに選択したスタイルを適用",
    "Save style": "スタイルを保存",
    "Remove All": "全て削除",
    "Search...": "検索…",
    "Which algorithm to use to produce the image": "画像を生成するために使用するアルゴリズムを選択します。",
    "Euler Ancestral - very creative, each can get a completely different picture depending on step count, setting steps higher than 30-40 does not help": "Euler Ancestral - very creative, each can get a completely different picture depending on step count, setting steps higher than 30-40 does not help",
    "How many times to improve the generated image iteratively; higher values take longer; very low values can produce bad results": "生成された画像を反復的に改善する回数です。値を高くすると処理に時間がかかり、値を低くしすぎると悪い結果になる可能性があります。",
    "How many batches of images to create": "バッチ処理を何回行うか",
    "How many image to create in a single batch": "1回のバッチ処理で何枚の画像を生成するか",
    "Classifier Free Guidance Scale - how strongly the image should conform to prompt - lower values produce more creative results": "Classifier Free Guidance Scale - 画像がプロンプトに従う度合い。値を低くするほど、より創造的な結果が得られます。",
    "A value that determines the output of random number generator - if you create an image with same parameters and seed as another image, you'll get the same result": "乱数生成器の出力を決定する値。同じパラメーターとシードで画像を生成すると、同じ結果が得られます。",
    "Set seed to -1, which will cause a new random number to be used every time": "シードを-1に設定し、毎回新しい乱数を使用します。",
    "Reuse seed from last generation, mostly useful if it was randomed": "前回の生成時に使用したシードを再利用します。前回がランダムなシードであった場合に有効です。",
    "Seed of a different picture to be mixed into the generation.": "生成時に、別の画像のシードを混ぜ込んで使用します。",
    "How strong of a variation to produce. At 0, there will be no effect. At 1, you will get the complete picture with variation seed (except for ancestral samplers, where you will just get something).": "生成される画像に加える変化の強度を設定します。強度が0の場合は影響なし、強度が1の場合は完全に変化用シードに基づいた画像が生成されます。ただし、Ancestralサンプラーを使用する場合は生成される画像が多少異なる可能性があります。",
    "Make an attempt to produce a picture similar to what would have been produced with same seed at specified resolution": "指定された解像度で同じシードを使用した場合の画像に近いものを生成します。",
    "Produce an image that can be tiled.": "タイル状に敷き詰めることができる画像を生成します。",
    "Use a two step process to partially create an image at smaller resolution, upscale, and then improve details in it without changing composition": "画像生成を二段階のプロセスで行います。最初に低解像度で途中までの画像を作成し、次に拡大して、構図を変えずに細部を改善します。",
    "Number of sampling steps for upscaled picture. If 0, uses same as for original.": "アップスケールした画像のサンプリングステップ数です。0の場合は本来のステップ数と同じになります。",
    "Determines how little respect the algorithm should have for image's content. At 0, nothing will change, and at 1 you'll get an unrelated image. With values below 1.0, processing will take less steps than the Sampling Steps slider specifies.": "アルゴリズムが画像の内容をどの程度無視するかを決定します。0にすると全く変化せず、 1にすると無関係な画像になります。1.0未満の値では、スライダーで指定したサンプリングステップ数よりも少ないステップ数で処理が行われます。",
    "Adjusts the size of the image by multiplying the original width and height by the selected value. Ignored if either Resize width to or Resize height to are non-zero.": "元の幅と高さを指定した値で掛け算して画像のサイズを調整します。幅のサイズ変更または高さのサイズ変更が0以外になっている場合、この値は無視されます。",
    "Resizes image to this width. If 0, width is inferred from either of two nearby sliders.": "Resizes image to this width. If 0, width is inferred from either of two nearby sliders.",
    "Resizes image to this height. If 0, height is inferred from either of two nearby sliders.": "Resizes image to this height. If 0, height is inferred from either of two nearby sliders.",
    "Do not do anything special": "特別なことをなにもしない",
    "Separate values for X axis using commas.": "X軸に用いる値をカンマ(,)で区切って入力してください。",
    "Paste available values into the field": "Paste available values into the field",
    "Separate values for Y axis using commas.": "Y軸に用いる値をカンマ(,)で区切って入力してください。",
    "Open images output directory": "画像の出力フォルダを開く",
    "Write image to a directory (default - log/images) and generation parameters into csv file.": "画像はフォルダ(デフォルト:log/images)に、生成パラメータはcsvファイルに書き出します。",
    "Resize image to target resolution. Unless height and width match, you will get incorrect aspect ratio.": "画像をターゲット解像度にリサイズします。高さと幅が一致しない場合、アスペクト比が正しくなくなります。",
    "Resize the image so that entirety of target resolution is filled with the image. Crop parts that stick out.": "対象の解像度に画像をフィットさせます。はみ出た部分は切り取られます。",
    "Resize the image so that entirety of image is inside target resolution. Fill empty space with image's colors.": "画像をリサイズして、ターゲット解像度の中に収まるようにします。空白部分は画像の色で埋めます。",
    "How much to blur the mask before processing, in pixels.": "処理前にどれだけマスクをぼかすか。px単位。",
    "What to put inside the masked area before processing it with Stable Diffusion.": "Stable Diffusionに処理させる前にマスクされたエリアに何を書き込むか。",
    "fill it with colors of the image": "元画像の色で埋める",
    "keep whatever was there originally": "もともとあったものをそのままにする",
    "fill it with latent space noise": "潜在空間(latent space)におけるノイズで埋める",
    "fill it with latent space zeroes": "潜在空間(latent space)における0で埋める",
    "How many times to repeat processing an image and using it as input for the next iteration": "何回画像処理を繰り返し、次の反復処理の入力として使用するか",
    "In loopback mode, on each loop the denoising strength is multiplied by this value. <1 means decreasing variety so your sequence will converge on a fixed picture. >1 means increasing variety so your sequence will become more and more chaotic.": "ループバックモードにおいて、各ループでのノイズ除去の強度はこの値によって乗算されます。1より小さければ変化が小さくなっていって、生成される画像は1つの画像に収束します。1より大きいとどんどん変化が大きくなるので、生成される画像はよりカオスになります。",
    "For SD upscale, how much overlap in pixels should there be between tiles. Tiles overlap so that when they are merged back into one picture, there is no clearly visible seam.": "SDアップスケールで、どれだけタイル間の重なりを確保するか(px単位)。タイルの一部を重複させることで、1枚の画像にした時明らかな継ぎ目がなくなります。",
    "A directory on the same machine where the server is running.": "サーバーが稼働しているのと同じマシンにあるフォルダ",
    "Leave blank to save images to the default path.": "空欄でデフォルトの場所へ画像を保存",
    "Result = A": "Result = A",
    "Result = A * (1 - M) + B * M": "出力されるモデル = A * (1 - M) + B * M",
    "Result = A + (B - C) * M": "出力されるモデル = A + (B - C) * M",
    "Regular expression; if weights's name matches it, the weights is not written to the resulting checkpoint. Use ^model_ema to discard EMA weights.": "Regular expression; if weights's name matches it, the weights is not written to the resulting checkpoint. Use ^model_ema to discard EMA weights.",
    "If the number of tokens is more than the number of vectors, some may be skipped.\nLeave the textbox empty to start with zeroed out vectors": "If the number of tokens is more than the number of vectors, some may be skipped.\nLeave the textbox empty to start with zeroed out vectors",
    "1st and last digit must be 1. ex:'1, 2, 1'": "最初と最後の数字は1でなければなりません。 例:'1, 2, 1'",
    "1st and last digit must be 0 and values should be between 0 and 1. ex:'0, 0.01, 0'": "1st and last digit must be 0 and values should be between 0 and 1. ex:'0, 0.01, 0'",
    "Gradient clip value": "Gradient clip value",
    "Path to directory with input images": "入力ファイルのあるフォルダの場所",
    "Path to directory where to write outputs": "出力を書き込むフォルダの場所",
    "Use following tags to define how filenames for images are chosen: [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.": "画像のファイル名がどのように生成されるかを定義するのに、以下のタグが使用できます: [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; 空欄でデフォルト設定を使用。",
    "If this option is enabled, watermark will not be added to created images. Warning: if you do not add watermark, you may be behaving in an unethical manner.": "このオプションを有効にすると、作成された画像にウォーターマークが追加されなくなります。警告:ウォーターマークを追加しない場合、非倫理的な行動とみなされる場合があります。",
    "Use following tags to define how subdirectories for images and grids are chosen: [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.": "画像やグリッドのサブディレクトリ名をどのように生成するかを定義するのに、以下のタグが使用できます: [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; 空欄でデフォルト設定を使用。",
    "Restore low quality faces using GFPGAN neural network": "GFPGANニューラルネットワークを使用して、低品質の顔画像を修復します。",
    "This regular expression will be used extract words from filename, and they will be joined using the option below into label text used for training. Leave empty to keep filename text as it is.": "この正規表現を使ってファイル名から単語を抽出し、以下のオプションで結合して学習用のラベルテキストにします。ファイル名のテキストをそのまま使用する場合は空欄。",
    "This string will be used to join split words into a single line if the option above is enabled.": "この文字列は、上記のオプションが有効な場合に、分割された単語を1行に結合するために使用されます。",
    "Only applies to inpainting models. Determines how strongly to mask off the original image for inpainting and img2img. 1.0 means fully masked, which is the default behaviour. 0.0 means a fully unmasked conditioning. Lower values will help preserve the overall composition of the image, but will struggle with large changes.": "inpaintingのモデルにのみ適用される。レタッチ(Inpaint) とimg2imgにおいて、元画像をどの程度マスクするかを決定する。1.0は完全にマスクされる(デフォルト)。0.0は完全にマスクされていない状態。値が低いほど画像全体の構図を保持するのに役に立つが、大きな変化に対しては効率が悪い。",
    "Early stopping parameter for CLIP model; 1 is stop at last layer as usual, 2 is stop at penultimate layer, etc.": "Early stopping parameter for CLIP model; 1 is stop at last layer as usual, 2 is stop at penultimate layer, etc.",
    "When adding extra network such as Hypernetwork or Lora to prompt, use this multiplier for it.": "When adding extra network such as Hypernetwork or Lora to prompt, use this multiplier for it.",
    "List of setting names, separated by commas, for settings that should go to the quick access bar at the top, rather than the usual setting tab. See modules/shared.py for setting names. Requires restarting to apply.": "上部のクイックアクセスバーに置く設定の設定名をカンマで区切って入力。設定名については modules/shared.py を参照してください。適用するには再起動が必要です。",
    "Comma-separated list of tab names; tabs listed here will appear in the extra networks UI first and in order lsited.": "Comma-separated list of tab names; tabs listed here will appear in the extra networks UI first and in order lsited.",
    "Cheap neural network approximation. Very fast compared to VAE, but produces pictures with 4 times smaller horizontal/vertical resolution and lower quality.": "Cheap neural network approximation. Very fast compared to VAE, but produces pictures with 4 times smaller horizontal/vertical resolution and lower quality.",
    "Very cheap approximation. Very fast compared to VAE, but produces pictures with 8 times smaller horizontal/vertical resolution and extremely low quality.": "Very cheap approximation. Very fast compared to VAE, but produces pictures with 8 times smaller horizontal/vertical resolution and extremely low quality.",
    "Ignores step count - uses a number of steps determined by the CFG and resolution": "ステップ数を無視し、CFGと解像度によって決まるステップ数を使用します。",
    "Denoising Diffusion Implicit Models - best at inpainting": "Denoising Diffusion Implicit Models - レタッチに最適",
    "If this values is non-zero, it will be added to seed and used to initialize RNG for noises when using samplers with Eta. You can use this to produce even more variation of images, or you can use this to match images of other software if you know what you are doing.": "この値が0以外の場合、シードに追加され、Etaでサンプラーを使用する際のノイズ用の乱数生成器を初期化するのに使用されます。これを利用して、さらにバリエーション豊かな画像を作成したり、他のソフトの画像に合わせたりすることができます。",
    "Leave empty for auto": "空欄で自動",
    "Upscaler 1": "Upscaler 1",
    "Upscaler 2": "Upscaler 2",
    "3D Openpose Editor": "3D Openpose Editor",
    "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.": "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.",
    "sd-webui-tunnels": "sd-webui-tunnels",
    "Add alternatives to the default tunneling methods. (including cloudflared)": "Add alternatives to the default tunneling methods. (including cloudflared)",
    "db-storage1111": "db-storage1111",
    "Allows to store pictures and their metadata in a database. (supports MongoDB)": "Allows to store pictures and their metadata in a database. (supports MongoDB)",
    "3D Model Loader": "3D Model Loader",
    "Load your 3D model/animation inside webui, then send screenshot to txt2img or img2img to ControlNet.": "Load your 3D model/animation inside webui, then send screenshot to txt2img or img2img to ControlNet.",
    "Corridor Crawler Outpainting": "Corridor Crawler Outpainting",
    "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.": "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.",
    "MultiDiffusion with Tiled VAE": "MultiDiffusion with Tiled VAE",
    "Seamless Image Fusion, along with vram efficient tiled vae script.": "Seamless Image Fusion, along with vram efficient tiled vae script.",
    "VRAM Estimator": "VRAM Estimator",
    "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.": "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.",
    "Dump U-Net": "Dump U-Net",
    "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547": "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547",
    "posex": "posex",
    "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.": "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.",
    "LLuL": "LLuL",
    "Local Latent Upscaler. Target an area to selectively enhance details.": "Local Latent Upscaler. Target an area to selectively enhance details.",
    "CFG-Schedule-for-Automatic1111-SD": "CFG-Schedule-for-Automatic1111-SD",
    "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.": "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.",
    "a1111-sd-webui-locon": "a1111-sd-webui-locon",
    "An extension for loading LoCon networks in webui.": "An extension for loading LoCon networks in webui.",
    "ebsynth_utility": "ebsynth_utility",
    "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.": "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.",
    "LoRA Block Weight": "LoRA Block Weight",
    "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.": "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.",
    "Kitchen Theme": "Kitchen Theme",
    "Custom Theme.": "Custom Theme.",
    "Bilingual Localization": "Bilingual Localization",
    "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.": "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.",
    "Composable LoRA": "Composable LoRA",
    "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.": "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.",
    "Clip Interrogator": "Clip Interrogator",
    "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.": "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.",
    "sd-webui-controlnet": "sd-webui-controlnet",
    "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.": "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.",
    "Latent Couple": "Latent Couple",
    "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts.": "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts.",
    "SuperMerger": "SuperMerger",
    "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more. Some operations are RAM-heavy & diffusers is required.": "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more. Some operations are RAM-heavy & diffusers is required.",
    "OpenPose Editor": "OpenPose Editor",
    "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.": "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.",
    "Video Loopback": "Video Loopback",
    "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.": "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.",
    "text2prompt": "text2prompt",
    "Generates anime tags using databases and models for tokenizing.": "Generates anime tags using databases and models for tokenizing.",
    "Prompt Translator": "Prompt Translator",
    "A integrated translator for translating prompts to English using Deepl or Baidu.": "A integrated translator for translating prompts to English using Deepl or Baidu.",
    "mine-diffusion": "mine-diffusion",
    "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.": "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.",
    "gif2gif": "gif2gif",
    "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif": "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif",
    "Embedding Merge": "Embedding Merge",
    "Merging Textual Inversion embeddings at runtime from string literals.": "Merging Textual Inversion embeddings at runtime from string literals.",
    "anti-burn": "anti-burn",
    "Smoothing generated images by skipping a few very last steps and averaging together some images before them": "Smoothing generated images by skipping a few very last steps and averaging together some images before them",
    "Aspect Ratio selector": "Aspect Ratio selector",
    "Adds image aspect ratio selector buttons.": "Adds image aspect ratio selector buttons.",
    "Catppuccin Theme": "Catppuccin Theme",
    "Adds various custom themes": "Adds various custom themes",
    "Dynamic Thresholding": "Dynamic Thresholding",
    "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.": "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.",
    "Custom Diffusion": "Custom Diffusion",
    "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.": "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.",
    "Fusion": "Fusion",
    "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.": "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.",
    "cafe-aesthetic": "cafe-aesthetic",
    "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.": "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.",
    "Instruct-pix2pix": "Instruct-pix2pix",
    "Adds a tab for doing img2img editing with the instruct-pix2pix model. Note: No longer required. Author has integrated code to webui, use in img2img.": "Adds a tab for doing img2img editing with the instruct-pix2pix model. Note: No longer required. Author has integrated code to webui, use in img2img.",
    "Pixelization": "Pixelization",
    "Using pre-trained models, produce pixel art out of images in the extras tab.": "Using pre-trained models, produce pixel art out of images in the extras tab.",
    "Steps Animation": "Steps Animation",
    "Create animation sequence from denoised intermediate steps.": "Create animation sequence from denoised intermediate steps.",
    "Aesthetic Scorer": "Aesthetic Scorer",
    "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.": "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.",
    "System Info": "System Info",
    "System Info tab for WebUI which shows realtime information of the server.": "System Info tab for WebUI which shows realtime information of the server.",
    "Discord Rich Presence": "Discord Rich Presence",
    "Provides connection to Discord RPC, showing a fancy table in the user profile.": "Provides connection to Discord RPC, showing a fancy table in the user profile.",
    "Promptgen": "Promptgen",
    "Use transformers models to generate prompts.": "Use transformers models to generate prompts.",
    "Depth Image I/O": "Depth Image I/O",
    "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.": "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.",
    "haku-img": "haku-img",
    "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.": "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.",
    "Asymmetric Tiling": "Asymmetric Tiling",
    "An always visible script extension to configure seamless image tiling independently for the X and Y axes.": "An always visible script extension to configure seamless image tiling independently for the X and Y axes.",
    "Batch Face Swap": "Batch Face Swap",
    "Automatically detects faces and replaces them.": "Automatically detects faces and replaces them.",
    "Multiple Hypernetworks": "Multiple Hypernetworks",
    "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.": "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.",
    "Merge Block Weighted": "Merge Block Weighted",
    "Merge models with separate rate for each 25 U-Net block (input, middle, output).": "Merge models with separate rate for each 25 U-Net block (input, middle, output).",
    "Sonar": "Sonar",
    "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.": "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.",
    "Hypernetwork-Monkeypatch-Extension": "Hypernetwork-Monkeypatch-Extension",
    "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.": "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.",
    "Animator": "Animator",
    "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.": "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.",
    "Stable Horde Client": "Stable Horde Client",
    "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.": "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.",
    "Ultimate SD Upscale": "Ultimate SD Upscale",
    "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).": "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).",
    "Stable Horde Worker": "Stable Horde Worker",
    "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.": "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.",
    "Kohya-ss Additional Networks": "Kohya-ss Additional Networks",
    "Allows the Web UI to use networks (LoRA) trained by their scripts to generate images.": "Allows the Web UI to use networks (LoRA) trained by their scripts to generate images.",
    "Model Converter": "Model Converter",
    "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.": "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.",
    "Add image number to grid": "Add image number to grid",
    "Add the image's number to its picture in the grid.": "Add the image's number to its picture in the grid.",
    "Prompt Generator": "Prompt Generator",
    "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.": "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.",
    "quick-css": "quick-css",
    "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.": "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.",
    "th_TH Localization": "th_TH Localization",
    "Thai localization": "Thai localization",
    "model-keyword": "model-keyword",
    "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.": "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.",
    "fi_FI Localization": "fi_FI Localization",
    "Finnish localization": "Finnish localization",
    "ABG_extension": "ABG_extension",
    "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.": "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.",
    "openOutpaint extension": "openOutpaint extension",
    "A tab with the full openOutpaint UI. Run with the --api flag.": "A tab with the full openOutpaint UI. Run with the --api flag.",
    "Save Intermediate Images": "Save Intermediate Images",
    "Save intermediate images during the sampling process. You can also make videos from the intermediate images.": "Save intermediate images during the sampling process. You can also make videos from the intermediate images.",
    "Gelbooru Prompt": "Gelbooru Prompt",
    "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui": "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui",
    "Diffusion Defender": "Diffusion Defender",
    "Prompt blacklist, find and replace, for semi-private and public instances.": "Prompt blacklist, find and replace, for semi-private and public instances.",
    "Preset Utilities": "Preset Utilities",
    "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)": "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)",
    "Riffusion": "Riffusion",
    "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.": "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.",
    "DH Patch": "DH Patch",
    "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.": "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.",
    "Config-Presets": "Config-Presets",
    "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.": "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.",
    "NSFW checker": "NSFW checker",
    "Replaces NSFW images with black.": "Replaces NSFW images with black.",
    "Infinity Grid Generator": "Infinity Grid Generator",
    "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.": "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.",
    "embedding-inspector": "embedding-inspector",
    "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.": "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.",
    "DAAM": "DAAM",
    "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image. Note: new ext. maintainer, uninstall previous ext. if needed.": "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image. Note: new ext. maintainer, uninstall previous ext. if needed.",
    "Prompt Gallery": "Prompt Gallery",
    "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.": "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.",
    "Depth Maps": "Depth Maps",
    "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.": "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.",
    "depthmap2mask": "depthmap2mask",
    "Create masks for img2img based on a depth estimation made by MiDaS.": "Create masks for img2img based on a depth estimation made by MiDaS.",
    "Visualize Cross-Attention": "Visualize Cross-Attention",
    "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.": "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.",
    "StylePile": "StylePile",
    "An easy way to mix and match elements to prompts that affect the style of the result.": "An easy way to mix and match elements to prompts that affect the style of the result.",
    "multi-subject-render": "multi-subject-render",
    "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.": "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.",
    "booru2prompt": "booru2prompt",
    "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.": "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.",
    "Merge Board": "Merge Board",
    "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.": "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.",
    "WD 1.4 Tagger": "WD 1.4 Tagger",
    "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.": "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.",
    "ru_RU Localization": "ru_RU Localization",
    "Russian localization": "Russian localization",
    "no_NO Localization": "no_NO Localization",
    "Norwegian localization": "Norwegian localization",
    "DreamArtist": "DreamArtist",
    "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.": "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.",
    "Auto TLS-HTTPS": "Auto TLS-HTTPS",
    "Allows you to easily, or even completely automatically start using HTTPS.": "Allows you to easily, or even completely automatically start using HTTPS.",
    "Smart Process": "Smart Process",
    "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.": "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.",
    "tr_TR Localization": "tr_TR Localization",
    "Turkish localization": "Turkish localization",
    "Randomize": "Randomize",
    "Allows for random parameters during txt2img generation. This script is processed for all generations, regardless of the script selected, meaning this script will function with others as well, such as AUTOMATIC1111/stable-diffusion-webui-wildcards": "Allows for random parameters during txt2img generation. This script is processed for all generations, regardless of the script selected, meaning this script will function with others as well, such as AUTOMATIC1111/stable-diffusion-webui-wildcards",
    "prompt travel": "prompt travel",
    "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.": "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.",
    "conditioning-highres-fix": "conditioning-highres-fix",
    "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt": "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt",
    "seed travel": "seed travel",
    "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.": "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.",
    "shift-attention": "shift-attention",
    "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.": "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.",
    "Detection Detailer": "Detection Detailer",
    "An object detection and auto-mask extension for Stable Diffusion web UI.": "An object detection and auto-mask extension for Stable Diffusion web UI.",
    "zh_TW Localization": "zh_TW Localization",
    "Traditional Chinese localization": "Traditional Chinese localization",
    "es_ES Localization": "es_ES Localization",
    "Spanish localization": "Spanish localization",
    "pt_BR Localization": "pt_BR Localization",
    "Brazillian portuguese localization": "Brazillian portuguese localization",
    "old localizations": "old localizations",
    "Old unmaintained localizations that used to be a part of main repository": "Old unmaintained localizations that used to be a part of main repository",
    "Dreambooth": "Dreambooth",
    "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.": "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.",
    "it_IT Localization": "it_IT Localization",
    "Italian localization": "Italian localization",
    "de_DE Localization": "de_DE Localization",
    "German localization": "German localization",
    "ja_JP Localization": "ja_JP Localization",
    "Japanese localization": "Japanese localization",
    "training-picker": "training-picker",
    "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.": "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.",
    "Embeddings editor": "Embeddings editor",
    "Allows you to manually edit textual inversion embeddings using sliders.": "Allows you to manually edit textual inversion embeddings using sliders.",
    "Latent Mirroring": "Latent Mirroring",
    "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections": "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections",
    "zh_CN Localization": "zh_CN Localization",
    "Simplified Chinese localization": "Simplified Chinese localization",
    "ko_KR Localization": "ko_KR Localization",
    "Korean localization": "Korean localization",
    "novelai-2-local-prompt": "novelai-2-local-prompt",
    "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.": "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.",
    "tokenizer": "tokenizer",
    "Adds a tab that lets you preview how CLIP model would tokenize your text.": "Adds a tab that lets you preview how CLIP model would tokenize your text.",
    "auto-sd-paint-ext": "auto-sd-paint-ext",
    "Krita Plugin.": "Krita Plugin.",
    "Unprompted": "Unprompted",
    "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.": "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.",
    "Booru tag autocompletion": "Booru tag autocompletion",
    "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.": "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.",
    "Aesthetic Gradients": "Aesthetic Gradients",
    "Create an embedding from one or few pictures and use it to apply their style to generated images.": "Create an embedding from one or few pictures and use it to apply their style to generated images.",
    "Wildcards": "Wildcards",
    "Sample extension. Allows you to use __name__ syntax in your prompt to get a random line from a file named name.txt in the wildcards directory. Also see Dynamic Prompts for similar functionality.": "Sample extension. Allows you to use __name__ syntax in your prompt to get a random line from a file named name.txt in the wildcards directory. Also see Dynamic Prompts for similar functionality.",
    "Dynamic Prompts": "Dynamic Prompts",
    "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.": "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.",
    "Image browser": "Image browser",
    "Provides an interface to browse created images in the web browser. Note: new ext. maintainer, uninstall previous ext. if needed.": "Provides an interface to browse created images in the web browser. Note: new ext. maintainer, uninstall previous ext. if needed.",
    "Inspiration": "Inspiration",
    "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.": "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.",
    "Deforum": "Deforum",
    "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.": "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.",
    "Artists to study": "Artists to study",
    "Shows a gallery of generated pictures by artists separated into categories.": "Shows a gallery of generated pictures by artists separated into categories.",
    "Aesthetic Image Scorer": "Aesthetic Image Scorer",
    "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer": "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer",
    "Dataset Tag Editor": "Dataset Tag Editor",
    "Feature-rich UI tab that allows image viewing, search-filtering and editing.": "Feature-rich UI tab that allows image viewing, search-filtering and editing.",
    "sd-webui-depth-lib": "sd-webui-depth-lib",
    "Depth Library": "Depth Library",
    "Pages:": "Pages:",
    "Selected": "Selected",
    "Send to ControlNet": "Send to ControlNet",
    "https://github.com/jexom/sd-webui-depth-lib.git": "https://github.com/jexom/sd-webui-depth-lib.git",
    "Image Browser": "Image Browser",
    "txt2img-grids": "txt2img-grids",
    "img2img-grids": "img2img-grids",
    "Favorites": "Favorites",
    "Others": "Others",
    "Favorites path from settings: log/images": "Favorites path from settings: log/images",
    "Images directory": "Images directory",
    "Sub directory depth": "Sub directory depth",
    "Add to / replace in saved directories": "Add to / replace in saved directories",
    "Saved directories": "Saved directories",
    "Remove from saved directories": "Remove from saved directories",
    "Sub directories": "Sub directories",
    "Nothing selected": "Nothing selected",
    "Get sub directories": "Get sub directories",
    "Maintenance": "Maintenance",
    "⚠ Caution: You should only use these options if you know what you are doing. ⚠": "⚠ Caution: You should only use these options if you know what you are doing. ⚠",
    "Status:": "Status:",
    "Last message": "Last message",
    "Rebuild exif cache": "Rebuild exif cache",
    "Delete 0-entries from exif cache": "Delete 0-entries from exif cache",
    "Update directory names in database": "Update directory names in database",
    "From (full path)": "From (full path)",
    "to (full path)": "to (full path)",
    "Reapply ranking after moving files": "Reapply ranking after moving files",
    "Dropdown": "Dropdown",
    "First Page": "First Page",
    "Prev Page": "Prev Page",
    "Page Index": "Page Index",
    "Next Page": "Next Page",
    "End Page": "End Page",
    "ranking": "ranking",
    "Next Image After Ranking (To be implemented)": "Next Image After Ranking (To be implemented)",
    "delete next": "delete next",
    "Delete": "Delete",
    "also delete off-screen images": "also delete off-screen images",
    "Additional Generation Info": "Additional Generation Info",
    "sort by": "sort by",
    "Sort by": "Sort by",
    "path name": "path name",
    "date": "date",
    "aesthetic_score": "aesthetic_score",
    "cfg scale": "cfg scale",
    "steps": "steps",
    "seed": "seed",
    "sampler": "sampler",
    "size": "size",
    "model": "model",
    "model hash": "model hash",
    "filename keyword": "filename keyword",
    "Filename keyword search": "Filename keyword search",
    "exif keyword": "exif keyword",
    "EXIF keyword search": "EXIF keyword search",
    "Search negative prompt": "Search negative prompt",
    "No": "No",
    "Yes": "Yes",
    "Only": "Only",
    "case sensitive": "case sensitive",
    "regex - e.g. ^(?!.*Hires).*$": "regex - e.g. ^(?!.*Hires).*$",
    "ranking filter": "ranking filter",
    "Ranking filter": "Ranking filter",
    "All": "All",
    "minimum aesthetic_score": "minimum aesthetic_score",
    "Minimum aesthetic_score": "Minimum aesthetic_score",
    "Maximum aesthetic_score": "Maximum aesthetic_score",
    "Generate Info": "Generate Info",
    "Generation Info": "Generation Info",
    "File Name": "File Name",
    "Move to favorites": "Move to favorites",
    "Send to txt2img ControlNet": "Send to txt2img ControlNet",
    "Send to img2img ControlNet": "Send to img2img ControlNet",
    "ControlNet number": "ControlNet number",
    "Directory path": "Directory path",
    "Move to directory": "Move to directory",
    "Renew Page": "Renew Page",
    "Number": "Number",
    "set_index": "set_index",
    "Image": "Image",
    "load_switch": "load_switch",
    "to_dir_load_switch": "to_dir_load_switch",
    "turn_page_switch": "turn_page_switch",
    "Checkbox": "Checkbox",
    "List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others. Custom folders are also supported by specifying their path.": "List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others. Custom folders are also supported by specifying their path.",
    "Select components to hide": "Select components to hide",
    "Include images in sub directories": "Include images in sub directories",
    "Preload images at startup": "Preload images at startup",
    "Move buttons copy instead of move": "Move buttons copy instead of move",
    "Print image deletion messages to the console": "Print image deletion messages to the console",
    "Move/Copy/Delete matching .txt files": "Move/Copy/Delete matching .txt files",
    "Print warning logs to the console": "Print warning logs to the console",
    "Print debug logs to the console": "Print debug logs to the console",
    "Use recycle bin when deleting images": "Use recycle bin when deleting images",
    "Scan Exif-/.txt-data (initially slower, but required for many features to work)": "Scan Exif-/.txt-data (initially slower, but required for many features to work)",
    "Scan Exif-/.txt-data (slower, but required for exif-keyword-search)": "Scan Exif-/.txt-data (slower, but required for exif-keyword-search)",
    "Change CTRL keybindings to SHIFT": "Change CTRL keybindings to SHIFT",
    "or to CTRL+SHIFT": "or to CTRL+SHIFT",
    "Enable Maintenance tab": "Enable Maintenance tab",
    "Save ranking in image's pnginfo": "Save ranking in image's pnginfo",
    "Number of columns on the page": "Number of columns on the page",
    "Number of rows on the page": "Number of rows on the page",
    "Minimum number of pages per load": "Minimum number of pages per load",
    "stable-diffusion-webui-images-browser": "stable-diffusion-webui-images-browser",
    "https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git": "https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git",
    "Input images directory": "Input images directory",
    "Ultimate SD upscale": "Ultimate SD upscale",
    "Will upscale the image depending on the selected target size type": "Will upscale the image depending on the selected target size type",
    "Target size type": "Target size type",
    "From img2img2 settings": "From img2img2 settings",
    "Custom size": "Custom size",
    "Scale from image size": "Scale from image size",
    "Custom width": "Custom width",
    "Custom height": "Custom height",
    "Scale": "Scale",
    "Redraw options:": "Redraw options:",
    "Type": "Type",
    "Linear": "Linear",
    "Chess": "Chess",
    "Tile width": "Tile width",
    "Tile height": "Tile height",
    "Padding": "Padding",
    "Seams fix:": "Seams fix:",
    "Band pass": "Band pass",
    "Half tile offset pass": "Half tile offset pass",
    "Half tile offset pass + intersections": "Half tile offset pass + intersections",
    "Denoise": "Denoise",
    "Save options:": "Save options:",
    "Upscaled": "Upscaled",
    "Seams fix": "Seams fix",
    "ultimate-upscale-for-automatic1111": "ultimate-upscale-for-automatic1111",
    "https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git": "https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git",
    "stable-diffusion-webui-wd14-tagger": "stable-diffusion-webui-wd14-tagger",
    "url": "https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git",
    "Load Settings": "Load Settings",
    "Save Settings": "Save Settings",
    "Generate Ckpt": "Generate Ckpt",
    "Save Weights": "Save Weights",
    "Generate Samples": "Generate Samples",
    "Cancel": "Cancel",
    "Select or create a model to begin.": "Select or create a model to begin.",
    "Model": "Model",
    "Select": "Select",
    "Create": "Create",
    "Snapshot to Resume": "Snapshot to Resume",
    "Lora Model": "Lora Model",
    "Loaded Model:": "Loaded Model:",
    "Model Revision:": "Model Revision:",
    "Model Epoch:": "Model Epoch:",
    "V2 Model:": "V2 Model:",
    "Has EMA:": "Has EMA:",
    "Source Checkpoint:": "Source Checkpoint:",
    "Create Model": "Create Model",
    "Create From Hub": "Create From Hub",
    "512x Model": "512x Model",
    "Model Path": "Model Path",
    "HuggingFace Token": "HuggingFace Token",
    "Source Checkpoint": "Source Checkpoint",
    "Extract EMA Weights": "Extract EMA Weights",
    "Unfreeze Model": "Unfreeze Model",
    "Input": "Input",
    "Concepts": "Concepts",
    "Saving": "Saving",
    "Testing": "Testing",
    "Performance Wizard (WIP)": "Performance Wizard (WIP)",
    "Basic": "Basic",
    "General": "General",
    "Use LORA": "Use LORA",
    "Use Lora Extended": "Use Lora Extended",
    "Train Imagic Only": "Train Imagic Only",
    "Train Inpainting Model": "Train Inpainting Model",
    "Generate Classification Images Using txt2img": "Generate Classification Images Using txt2img",
    "Intervals": "Intervals",
    "Training Steps Per Image (Epochs)": "Training Steps Per Image (Epochs)",
    "Pause After N Epochs": "Pause After N Epochs",
    "Amount of time to pause between Epochs (s)": "Amount of time to pause between Epochs (s)",
    "Save Model Frequency (Epochs)": "Save Model Frequency (Epochs)",
    "Save Preview(s) Frequency (Epochs)": "Save Preview(s) Frequency (Epochs)",
    "Batching": "Batching",
    "Batch Size": "Batch Size",
    "Gradient Accumulation Steps": "Gradient Accumulation Steps",
    "Class Batch Size": "Class Batch Size",
    "Set Gradients to None When Zeroing": "Set Gradients to None When Zeroing",
    "Gradient Checkpointing": "Gradient Checkpointing",
    "Learning Rate": "Learning Rate",
    "Learning Rate Scheduler": "Learning Rate Scheduler",
    "linear_with_warmup": "linear_with_warmup",
    "cosine": "cosine",
    "cosine_annealing": "cosine_annealing",
    "cosine_annealing_with_restarts": "cosine_annealing_with_restarts",
    "cosine_with_restarts": "cosine_with_restarts",
    "polynomial": "polynomial",
    "constant": "constant",
    "constant_with_warmup": "constant_with_warmup",
    "Min Learning Rate": "Min Learning Rate",
    "Number of Hard Resets": "Number of Hard Resets",
    "Constant/Linear Starting Factor": "Constant/Linear Starting Factor",
    "Polynomial Power": "Polynomial Power",
    "Scale Position": "Scale Position",
    "Lora UNET Learning Rate": "Lora UNET Learning Rate",
    "Lora Text Encoder Learning Rate": "Lora Text Encoder Learning Rate",
    "Learning Rate Warmup Steps": "Learning Rate Warmup Steps",
    "Image Processing": "Image Processing",
    "Max Resolution": "Max Resolution",
    "Apply Horizontal Flip": "Apply Horizontal Flip",
    "Sanity Sample Prompt": "Sanity Sample Prompt",
    "Sanity Sample Negative Prompt": "Sanity Sample Negative Prompt",
    "Sanity Sample Seed": "Sanity Sample Seed",
    "Miscellaneous": "Miscellaneous",
    "Pretrained VAE Name or Path": "Pretrained VAE Name or Path",
    "Use Concepts List": "Use Concepts List",
    "Concepts List": "Concepts List",
    "API Key": "API Key",
    "Discord Webhook": "Discord Webhook",
    "Save and Test Webhook": "Save and Test Webhook",
    "Advanced": "Advanced",
    "Tuning": "Tuning",
    "Use EMA": "Use EMA",
    "Optimizer": "Optimizer",
    "8Bit Adam": "8Bit Adam",
    "Lion": "Lion",
    "Mixed Precision": "Mixed Precision",
    "no": "no",
    "fp16": "fp16",
    "Memory Attention": "Memory Attention",
    "default": "default",
    "xformers": "xformers",
    "Cache Latents": "Cache Latents",
    "Train UNET": "Train UNET",
    "Step Ratio of Text Encoder Training": "Step Ratio of Text Encoder Training",
    "Offset Noise": "Offset Noise",
    "Freeze CLIP Normalization Layers": "Freeze CLIP Normalization Layers",
    "Clip Skip": "Clip Skip",
    "AdamW Weight Decay": "AdamW Weight Decay",
    "Pad Tokens": "Pad Tokens",
    "Strict Tokens": "Strict Tokens",
    "Shuffle Tags": "Shuffle Tags",
    "Max Token Length": "Max Token Length",
    "Prior Loss": "Prior Loss",
    "Scale Prior Loss": "Scale Prior Loss",
    "Prior Loss Weight": "Prior Loss Weight",
    "Prior Loss Target": "Prior Loss Target",
    "Minimum Prior Loss Weight": "Minimum Prior Loss Weight",
    "Training Wizard (Person)": "Training Wizard (Person)",
    "Training Wizard (Object/Style)": "Training Wizard (Object/Style)",
    "Concept 1": "Concept 1",
    "Concept 2": "Concept 2",
    "Concept 3": "Concept 3",
    "Concept 4": "Concept 4",
    "Directories": "Directories",
    "Dataset Directory": "Dataset Directory",
    "Classification Dataset Directory": "Classification Dataset Directory",
    "Filewords": "Filewords",
    "Instance Token": "Instance Token",
    "Class Token": "Class Token",
    "Prompts": "Prompts",
    "Instance Prompt": "Instance Prompt",
    "Class Prompt": "Class Prompt",
    "Sample Image Prompt": "Sample Image Prompt",
    "Classification Image Negative Prompt": "Classification Image Negative Prompt",
    "Sample Prompt Template File": "Sample Prompt Template File",
    "Sample Negative Prompt": "Sample Negative Prompt",
    "Image Generation": "Image Generation",
    "Class Images Per Instance Image": "Class Images Per Instance Image",
    "Classification CFG Scale": "Classification CFG Scale",
    "Classification Steps": "Classification Steps",
    "Number of Samples to Generate": "Number of Samples to Generate",
    "Sample Seed": "Sample Seed",
    "Sample CFG Scale": "Sample CFG Scale",
    "Sample Steps": "Sample Steps",
    "Custom Model Name": "Custom Model Name",
    "Save in .safetensors format": "Save in .safetensors format",
    "Save EMA Weights to Generated Models": "Save EMA Weights to Generated Models",
    "Use EMA Weights for Inference": "Use EMA Weights for Inference",
    "Checkpoints": "Checkpoints",
    "Half Model": "Half Model",
    "Save Checkpoint to Subdirectory": "Save Checkpoint to Subdirectory",
    "Generate a .ckpt file when saving during training.": "Generate a .ckpt file when saving during training.",
    "Generate a .ckpt file when training completes.": "Generate a .ckpt file when training completes.",
    "Generate a .ckpt file when training is canceled.": "Generate a .ckpt file when training is canceled.",
    "Lora UNET Rank": "Lora UNET Rank",
    "Lora Text Encoder Rank": "Lora Text Encoder Rank",
    "Lora Weight": "Lora Weight",
    "Lora Text Weight": "Lora Text Weight",
    "Generate lora weights when saving during training.": "Generate lora weights when saving during training.",
    "Generate lora weights when training completes.": "Generate lora weights when training completes.",
    "Generate lora weights when training is canceled.": "Generate lora weights when training is canceled.",
    "Generate lora weights for extra networks.": "Generate lora weights for extra networks.",
    "Diffusion Weights": "Diffusion Weights",
    "Save separate diffusers snapshots when saving during training.": "Save separate diffusers snapshots when saving during training.",
    "Save separate diffusers snapshots when training completes.": "Save separate diffusers snapshots when training completes.",
    "Save separate diffusers snapshots when training is canceled.": "Save separate diffusers snapshots when training is canceled.",
    "Generate Class Images": "Generate Class Images",
    "Generate Graph": "Generate Graph",
    "Graph Smoothing Steps": "Graph Smoothing Steps",
    "Debug Buckets": "Debug Buckets",
    "Epochs to Simulate": "Epochs to Simulate",
    "Batch Size to Simulate": "Batch Size to Simulate",
    "Generate Sample Images": "Generate Sample Images",
    "Sample Prompt": "Sample Prompt",
    "Sample Prompt File": "Sample Prompt File",
    "Sample Width": "Sample Width",
    "Sample Height": "Sample Height",
    "Sample Batch Size": "Sample Batch Size",
    "Scheduler": "Scheduler",
    "DDPM": "DDPM",
    "PNDM": "PNDM",
    "LMSDiscrete": "LMSDiscrete",
    "EulerDiscrete": "EulerDiscrete",
    "HeunDiscrete": "HeunDiscrete",
    "EulerAncestralDiscrete": "EulerAncestralDiscrete",
    "DPMSolverMultistep": "DPMSolverMultistep",
    "DPMSolverSinglestep": "DPMSolverSinglestep",
    "KDPM2Discrete": "KDPM2Discrete",
    "KDPM2AncestralDiscrete": "KDPM2AncestralDiscrete",
    "DEISMultistep": "DEISMultistep",
    "UniPCMultistep": "UniPCMultistep",
    "Swap Sample Faces": "Swap Sample Faces",
    "Swap Prompt": "Swap Prompt",
    "Swap Negative Prompt": "Swap Negative Prompt",
    "Swap Steps": "Swap Steps",
    "Swap Batch": "Swap Batch",
    "Use txt2img": "Use txt2img",
    "Deterministic": "Deterministic",
    "Use EMA for prediction.": "Use EMA for prediction.",
    "Calculate Split Loss": "Calculate Split Loss",
    "Use TensorFloat 32": "Use TensorFloat 32",
    "Use DEIS for noise scheduler": "Use DEIS for noise scheduler",
    "Update Extension and Restart": "Update Extension and Restart",
    "Bucket Cropping": "Bucket Cropping",
    "Source Path": "Source Path",
    "Dest Path": "Dest Path",
    "Max Res": "Max Res",
    "Bucket Steps": "Bucket Steps",
    "Dry Run": "Dry Run",
    "Start Cropping": "Start Cropping",
    "Output": "Output",
    "Check Progress": "Check Progress",
    "Update Parameters": "Update Parameters",
    "Changelog": "Changelog",
    "X": "X",
    "Release notes": "Release notes",
    "sd_dreambooth_extension": "sd_dreambooth_extension",
    "https://github.com/d8ahazard/sd_dreambooth_extension.git": "https://github.com/d8ahazard/sd_dreambooth_extension.git",
    "A generic prompt used to generate a sample image to verify model fidelity.": "A generic prompt used to generate a sample image to verify model fidelity.",
    "A negative prompt for the generic sample image.": "A negative prompt for the generic sample image.",
    "Leave blank to use base model VAE.": "Leave blank to use base model VAE.",
    "Path to JSON file with concepts to train.": "Path to JSON file with concepts to train.",
    "https://discord.com/api/webhooks/XXX/XXXX": "https://discord.com/api/webhooks/XXX/XXXX",
    "(Optional) Path to directory with classification/regularization images": "(Optional) Path to directory with classification/regularization images",
    "When using [filewords], this is the subject to use when building prompts.": "When using [filewords], this is the subject to use when building prompts.",
    "When using [filewords], this is the class to use when building prompts.": "When using [filewords], this is the class to use when building prompts.",
    "Optionally use [filewords] to read image captions from files.": "Optionally use [filewords] to read image captions from files.",
    "Leave blank to use instance prompt. Optionally use [filewords] to base sample captions on instance images.": "Leave blank to use instance prompt. Optionally use [filewords] to base sample captions on instance images.",
    "Enter the path to a txt file containing sample prompts.": "Enter the path to a txt file containing sample prompts.",
    "Enter a model name for saving checkpoints and lora models.": "Enter a model name for saving checkpoints and lora models.",
    "DreamArtist Create embedding": "DreamArtist Create embedding",
    "DreamArtist Train": "DreamArtist Train",
    "Process Att-Map": "Process Att-Map",
    "Initialization text (negative)": "Initialization text (negative)",
    "Number of negative vectors per token": "Number of negative vectors per token",
    "Unet Learning rate": "Unet Learning rate",
    "Train with DreamArtist": "Train with DreamArtist",
    "Train with reconstruction": "Train with reconstruction",
    "Attention Map": "Attention Map",
    "Train U-Net": "Train U-Net",
    "CFG scale (dynamic cfg: low,high:type e.g. 1.0-3.5:cos)": "CFG scale (dynamic cfg: low,high:type e.g. 1.0-3.5:cos)",
    "Reconstruction loss weight": "Reconstruction loss weight",
    "Negative lr weight": "Negative lr weight",
    "Classifier path": "Classifier path",
    "Accumulation steps": "Accumulation steps",
    "Prompt template file": "Prompt template file",
    "Positive \"filewords\" only": "Positive \"filewords\" only",
    "Experimental features (May be solve the problem of erratic training and difficult to reproduce [set EMA to 0.97])": "Experimental features (May be solve the problem of erratic training and difficult to reproduce [set EMA to 0.97])",
    "EMA (positive)": "EMA (positive)",
    "EMA replace steps (positive)": "EMA replace steps (positive)",
    "EMA (nagetive)": "EMA (nagetive)",
    "EMA replace steps (nagative)": "EMA replace steps (nagative)",
    "beta1": "beta1",
    "beta2": "beta2",
    "Since there is a self-attention operation in VAE, it may change the distribution of features. This processing will superimpose the attention map of self-attention on the original Att-Map.": "Since there is a self-attention operation in VAE, it may change the distribution of features. This processing will superimpose the attention map of self-attention on the original Att-Map.",
    "Data directory": "Data directory",
    "Process": "Process",
    "DreamArtist-sd-webui-extension": "DreamArtist-sd-webui-extension",
    "Path to classifier ckpt, can be empty": "Path to classifier ckpt, can be empty",
    "https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git": "https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git",
    "Embedding Editor": "Embedding Editor",
    "Vector": "Vector",
    "Refresh Embeddings": "Refresh Embeddings",
    "Save Embedding": "Save Embedding",
    "Enter words and color hexes to mark weights on the sliders for guidance. Hint: Use the txt2img prompt token counter or": "Enter words and color hexes to mark weights on the sliders for guidance. Hint: Use the txt2img prompt token counter or",
    "webui-tokenizer": "webui-tokenizer",
    "to see which words are constructed using multiple sub-words, e.g. 'computer' doesn't exist in stable diffusion's CLIP dictionary and instead 'compu' and 'ter' are used (1 word but 2 embedding vectors). Currently buggy and needs a moment to process before pressing the button. If it doesn't work after a moment, try adding a random space to refresh it.": "to see which words are constructed using multiple sub-words, e.g. 'computer' doesn't exist in stable diffusion's CLIP dictionary and instead 'compu' and 'ter' are used (1 word but 2 embedding vectors). Currently buggy and needs a moment to process before pressing the button. If it doesn't work after a moment, try adding a random space to refresh it.",
    "Sampling Steps": "Sampling Steps",
    "Generate Preview": "Generate Preview",
    "stable-diffusion-webui-embedding-editor": "stable-diffusion-webui-embedding-editor",
    "https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git": "https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git",
    "symbol:color-hex, symbol:color-hex, ...": "symbol:color-hex, symbol:color-hex, ...",
    "e.g. A portrait photo of embedding_name": "e.g. A portrait photo of embedding_name",
    "https://github.com/Bing-su/sd-webui-tunnels.git": "https://github.com/Bing-su/sd-webui-tunnels.git",
    "Attention Heatmap": "Attention Heatmap",
    "Attention texts for visualization. (comma separated)": "Attention texts for visualization. (comma separated)",
    "Hide heatmap images": "Hide heatmap images",
    "Do not save heatmap images": "Do not save heatmap images",
    "Hide caption": "Hide caption",
    "Use grid (output to grid dir)": "Use grid (output to grid dir)",
    "Grid layout": "Grid layout",
    "Auto": "Auto",
    "Prevent Empty Spot": "Prevent Empty Spot",
    "Batch Length As Row": "Batch Length As Row",
    "Heatmap blend alpha": "Heatmap blend alpha",
    "Heatmap image scale": "Heatmap image scale",
    "Trace each layers": "Trace each layers",
    "Use layers as row instead of Batch Length": "Use layers as row instead of Batch Length",
    "stable-diffusion-webui-daam": "stable-diffusion-webui-daam",
    "width": "width",
    "height": "height",
    "Add": "Add",
    "Reset": "Reset",
    "Load from JSON": "Load from JSON",
    "Detect from image": "Detect from image",
    "Add Background image": "Add Background image",
    "json": "json",
    "Save JSON": "Save JSON",
    "Save PNG": "Save PNG",
    "Send to": "Send to",
    "openpose-editor": "openpose-editor",
    "Save score as EXIF or PNG Info Chunk": "Save score as EXIF or PNG Info Chunk",
    "cfg_scale": "cfg_scale",
    "sd_model_hash": "sd_model_hash",
    "hash": "hash",
    "Save tags (Windows only)": "Save tags (Windows only)",
    "Save category (Windows only)": "Save category (Windows only)",
    "Save generation params text": "Save generation params text",
    "Force CPU (Requires Custom Script Reload)": "Force CPU (Requires Custom Script Reload)",
    "stable-diffusion-webui-aesthetic-image-scorer": "stable-diffusion-webui-aesthetic-image-scorer",
    "Tokenizer": "Tokenizer",
    "Before your text is sent to the neural network, it gets turned into numbers in a process called tokenization. These tokens are how the neural network reads and interprets text. Thanks to our great friends at Shousetsu愛 for inspiration for this feature.": "Before your text is sent to the neural network, it gets turned into numbers in a process called tokenization. These tokens are how the neural network reads and interprets text. Thanks to our great friends at Shousetsu愛 for inspiration for this feature.",
    "Text input": "Text input",
    "ID input": "ID input",
    "Tokenize": "Tokenize",
    "Text": "Text",
    "Tokens": "Tokens",
    "stable-diffusion-webui-tokenizer": "stable-diffusion-webui-tokenizer",
    "Prompt for tokenization": "Prompt for tokenization",
    "Ids for tokenization (example: 9061, 631, 736)": "Ids for tokenization (example: 9061, 631, 736)",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git",
    "auto-sd-paint-ext Guide/Panel": "auto-sd-paint-ext Guide/Panel",
    "Generate Krita Plugin Symlink Command": "Generate Krita Plugin Symlink Command",
    "Launch Krita.": "Launch Krita.",
    "On the menubar, go to": "On the menubar, go to",
    "Settings > Manage Resources...": "Settings > Manage Resources...",
    "In the window that appears, click": "In the window that appears, click",
    "Open Resource Folder": "Open Resource Folder",
    "In the file explorer that appears, look for a folder called": "In the file explorer that appears, look for a folder called",
    "pykrita": "pykrita",
    "or create it.": "or create it.",
    "Enter the": "Enter the",
    "folder and copy the folder location from the address bar.": "folder and copy the folder location from the address bar.",
    "Paste the folder location below.": "Paste the folder location below.",
    "Pykrita Folder Location": "Pykrita Folder Location",
    "Search for \"Command Prompt\" in the Start Menu, right-click and click \"Run as Administrator...\", paste the follow commands and hit Enter:": "Search for \"Command Prompt\" in the Start Menu, right-click and click \"Run as Administrator...\", paste the follow commands and hit Enter:",
    "mklink /j \"<path_to_pykrita>\\krita_diff\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\"\nmklink \"<path_to_pykrita>\\krita_diff.desktop\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\"": "mklink /j \"<path_to_pykrita>\\krita_diff\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\"\nmklink \"<path_to_pykrita>\\krita_diff.desktop\" \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\"",
    "Linux command:": "Linux command:",
    "ln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\" \"<path_to_pykrita>/krita_diff\"\nln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\" \"<path_to_pykrita>/krita_diff.desktop\"": "ln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff\" \"<path_to_pykrita>/krita_diff\"\nln -s \"D:\\StableDiffusion\\clean install\\webui\\extensions\\auto-sd-paint-ext\\frontends\\krita\\krita_diff.desktop\" \"<path_to_pykrita>/krita_diff.desktop\"",
    "NOTE": "NOTE",
    ": Symlinks will break if you move or rename the repository or any\nof its parent folders or otherwise change the path such that the symlink\nbecomes invalid. In which case, repeat the above steps with the new": ": Symlinks will break if you move or rename the repository or any\nof its parent folders or otherwise change the path such that the symlink\nbecomes invalid. In which case, repeat the above steps with the new",
    "folder location and (auto-detected) repository location.": "folder location and (auto-detected) repository location.",
    ": Ensure": ": Ensure",
    "webui-user.bat": "webui-user.bat",
    "/": "/",
    "webui-user.sh": "webui-user.sh",
    "contains": "contains",
    "--api": "--api",
    "in": "in",
    "COMMANDLINE_ARGS": "COMMANDLINE_ARGS",
    "!": "!",
    "Enabling the Krita Plugin": "Enabling the Krita Plugin",
    "Restart Krita.": "Restart Krita.",
    "Settings > Configure Krita...": "Settings > Configure Krita...",
    "On the left sidebar, go to": "On the left sidebar, go to",
    "Python Plugin Manager": "Python Plugin Manager",
    "Look for": "Look for",
    "Stable Diffusion Plugin": "Stable Diffusion Plugin",
    "and tick the checkbox.": "and tick the checkbox.",
    "Restart Krita again for changes to take effect.": "Restart Krita again for changes to take effect.",
    "The": "The",
    "SD Plugin": "SD Plugin",
    "docked window should appear on the left of the Krita window. If it does not, look on the menubar under": "docked window should appear on the left of the Krita window. If it does not, look on the menubar under",
    "Settings > Dockers": "Settings > Dockers",
    "for": "for",
    "Next Steps": "Next Steps",
    "Troubleshooting": "Troubleshooting",
    "Update Guide": "Update Guide",
    "Usage Guide": "Usage Guide",
    "TODO: Control/status panel": "TODO: Control/status panel",
    "https://github.com/Interpause/auto-sd-paint-ext.git": "https://github.com/Interpause/auto-sd-paint-ext.git",
    "Enable pixelization": "Enable pixelization",
    "Keep resolution": "Keep resolution",
    "Pixel size": "Pixel size",
    "stable-diffusion-webui-pixelization": "stable-diffusion-webui-pixelization",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git",
    "Training Picker": "Training Picker",
    "Video to extract frames from:": "Video to extract frames from:",
    "Only extract keyframes (recommended)": "Only extract keyframes (recommended)",
    "Extract every nth frame": "Extract every nth frame",
    "Extract Frames": "Extract Frames",
    "Extracted Frame Set": "Extracted Frame Set",
    "Resize crops to 512x512": "Resize crops to 512x512",
    "Outfill method:": "Outfill method:",
    "Don't outfill": "Don't outfill",
    "Stretch image": "Stretch image",
    "Transparent": "Transparent",
    "Solid color": "Solid color",
    "Average image color": "Average image color",
    "Dominant image color": "Dominant image color",
    "Stretch pixels at border": "Stretch pixels at border",
    "Reflect image around border": "Reflect image around border",
    "Blurred & stretched overlay": "Blurred & stretched overlay",
    "Reuse original image": "Reuse original image",
    "Reset Aspect Ratio": "Reset Aspect Ratio",
    "Image border outfill method:": "Image border outfill method:",
    "Black outfill": "Black outfill",
    "Outfill border color:": "Outfill border color:",
    "Blur amount:": "Blur amount:",
    "Number of clusters:": "Number of clusters:",
    "Save crops to:": "Save crops to:",
    "Fixed size to resize images to": "Fixed size to resize images to",
    "Path to read videos from": "Path to read videos from",
    "Path to store extracted frame sets in": "Path to store extracted frame sets in",
    "Default cropped image output directory": "Default cropped image output directory",
    "https://github.com/Maurdekye/training-picker.git": "https://github.com/Maurdekye/training-picker.git",
    "stable-diffusion-webui-two-shot": "stable-diffusion-webui-two-shot",
    "Enabled": "Enabled",
    "Divisions": "Divisions",
    "Positions": "Positions",
    "Weights": "Weights",
    "end at this step": "end at this step",
    "Visualize": "Visualize",
    "Regions": "Regions",
    "Extra generation params": "Extra generation params",
    "Apply": "Apply",
    "https://github.com/opparco/stable-diffusion-webui-two-shot.git": "https://github.com/opparco/stable-diffusion-webui-two-shot.git",
    "Seed travel": "Seed travel",
    "Destination seed(s) (Comma separated)": "Destination seed(s) (Comma separated)",
    "Only use Random seeds (Unless comparing paths)": "Only use Random seeds (Unless comparing paths)",
    "Number of random seed(s)": "Number of random seed(s)",
    "Compare paths (Separate travels from 1st seed to each destination)": "Compare paths (Separate travels from 1st seed to each destination)",
    "Steps (Number of images between each seed)": "Steps (Number of images between each seed)",
    "Loop back to initial seed": "Loop back to initial seed",
    "Save results as video": "Save results as video",
    "Frames per second": "Frames per second",
    "Number of frames for lead in/out": "Number of frames for lead in/out",
    "Upscale ratio": "Upscale ratio",
    "Bump seed (If > 0 do a Compare Paths but only one image. No video will be generated.)": "Bump seed (If > 0 do a Compare Paths but only one image. No video will be generated.)",
    "Use cache": "Use cache",
    "Show generated images in ui": "Show generated images in ui",
    "Interpolation rate": "Interpolation rate",
    "Hug-the-middle": "Hug-the-middle",
    "Slow start": "Slow start",
    "Quick start": "Quick start",
    "Rate strength": "Rate strength",
    "Allow the default Euler a Sampling method. (Does not produce good results)": "Allow the default Euler a Sampling method. (Does not produce good results)",
    "seed_travel": "seed_travel",
    "Multiplication (2^N)": "Multiplication (2^N)",
    "Weight": "Weight",
    "Force convert half to float on interpolation (for some platforms)": "Force convert half to float on interpolation (for some platforms)",
    "I know what I am doing.": "上級者向けオプション",
    "Layers": "Layers",
    "Apply to": "Apply to",
    "Resblock": "Resblock",
    "Transformer": "Transformer",
    "S. Attn.": "S. Attn.",
    "X. Attn.": "X. Attn.",
    "OUT": "OUT",
    "Start steps": "Start steps",
    "Bilinear": "Bilinear",
    "Bicubic": "Bicubic",
    "Enable AA for Upscaling.": "Enable AA for Upscaling.",
    "Downscaling": "Downscaling",
    "Area": "Area",
    "Pooling Max": "Pooling Max",
    "Pooling Avg": "Pooling Avg",
    "Enable AA for Downscaling.": "Enable AA for Downscaling.",
    "interpolation method": "interpolation method",
    "Lerp": "線形補間",
    "SLerp": "球面線形補間",
    "LLuL Enabled": "LLuL Enabled",
    "LLuL Multiply": "LLuL Multiply",
    "LLuL Weight": "LLuL Weight",
    "LLuL Layers": "LLuL Layers",
    "LLuL Apply to": "LLuL Apply to",
    "LLuL Start steps": "LLuL Start steps",
    "LLuL Max steps": "LLuL Max steps",
    "LLuL Upscaler": "LLuL Upscaler",
    "LLuL Upscaler AA": "LLuL Upscaler AA",
    "LLuL Downscaler": "LLuL Downscaler",
    "LLuL Downscaler AA": "LLuL Downscaler AA",
    "LLuL Interpolation method": "LLuL Interpolation method",
    "sd-webui-llul": "sd-webui-llul",
    "https://github.com/hnmr293/sd-webui-llul.git": "https://github.com/hnmr293/sd-webui-llul.git",
    "Unprompted Seed": "Unprompted Seed",
    "Learn More ➜": "Learn More ➜",
    "Functions": "Functions",
    "Shortcodes": "Shortcodes",
    "Select function:": "Select function:",
    "Example Function": "Example Function",
    "txt2img2img": "txt2img2img",
    "Options": "Options",
    "This template demonstrates the structure of a basic Wizard function. You can find this file in your": "This template demonstrates the structure of a basic Wizard function. You can find this file in your",
    "Unprompted/templates/examples": "Unprompted/templates/examples",
    "folder.": "folder.",
    "The content of the": "The content of the",
    "template": "template",
    "block is parsed as": "block is parsed as",
    "Markdown format": "Markdown format",
    ". This means that you can include rich content like links and pictures here. Cool, huh?": ". This means that you can include rich content like links and pictures here. Cool, huh?",
    "The following UI fields are generated automatically by detecting": "The following UI fields are generated automatically by detecting",
    "<set>": "<set>",
    "blocks with the": "blocks with the",
    "_new": "_new",
    "flag.": "flag.",
    "Enter a subject 🡢 subject": "Enter a subject 🡢 subject",
    "Add fluff terms? 🡢 use_fluff": "Add fluff terms? 🡢 use_fluff",
    "Auto-include this in prompt": "Auto-include this in prompt",
    "This template demonstrates the power of the \"after\" block.": "This template demonstrates the power of the \"after\" block.",
    "First, it processes": "First, it processes",
    "Subject A": "Subject A",
    "via txt2img.": "via txt2img.",
    "It then uses the result as the initial image for img2img, setting": "It then uses the result as the initial image for img2img, setting",
    "Subject B": "Subject B",
    "as the prompt.": "as the prompt.",
    "Subject A 🡢 subject_a": "Subject A 🡢 subject_a",
    "Subject B 🡢 subject_b": "Subject B 🡢 subject_b",
    "Generate Shortcode": "Generate Shortcode",
    "Select shortcode:": "Select shortcode:",
    "##: Houses a multiline comment that will not affect the final output.": "##: Houses a multiline comment that will not affect the final output.",
    "Content": "Content",
    "#: Houses a comment that does not affect your final prompt.": "#: Houses a comment that does not affect your final prompt.",
    "Comment 🡢 str": "Comment 🡢 str",
    "after: Processes arbitrary text following the main output.": "after: Processes arbitrary text following the main output.",
    "Order compared to other [after] blocks 🡢 int": "Order compared to other [after] blocks 🡢 int",
    "antonyms: Replaces the content with one or more antonyms.": "antonyms: Replaces the content with one or more antonyms.",
    "array: Manages a group or list of values.": "array: Manages a group or list of values.",
    "Name of array variable 🡢 str": "Name of array variable 🡢 str",
    "Get or set index statements 🡢 verbatim": "Get or set index statements 🡢 verbatim",
    "Custom delimiter string 🡢 _delimiter": "Custom delimiter string 🡢 _delimiter",
    "Shuffle the array 🡢 _shuffle": "Shuffle the array 🡢 _shuffle",
    "Prepend value(s) to the array 🡢 _prepend": "Prepend value(s) to the array 🡢 _prepend",
    "Append value(s) to the array 🡢 _append": "Append value(s) to the array 🡢 _append",
    "Delete value(s) from the array by index 🡢 _del": "Delete value(s) from the array by index 🡢 _del",
    "Removed specified value(s) from the array 🡢 _remove": "Removed specified value(s) from the array 🡢 _remove",
    "Find the first index of the following value(s) 🡢 _find": "Find the first index of the following value(s) 🡢 _find",
    "article: Returns the content with prefixed with a definite or indefinite article.": "article: Returns the content with prefixed with a definite or indefinite article.",
    "autocorrect: Attempts to correct the spelling of content.": "autocorrect: Attempts to correct the spelling of content.",
    "case: Use within [switch] to run different logic blocks depending on the value of a var.": "case: Use within [switch] to run different logic blocks depending on the value of a var.",
    "Matching value 🡢 str": "Matching value 🡢 str",
    "casing: Converts the casing of content.": "casing: Converts the casing of content.",
    "Casing method 🡢 str": "Casing method 🡢 str",
    "camelcase": "camelcase",
    "uppercase": "uppercase",
    "lowercase": "lowercase",
    "pascalcase": "pascalcase",
    "snakecase": "snakecase",
    "constcase": "constcase",
    "kebabcase": "kebabcase",
    "upperkebabcase": "upperkebabcase",
    "separatorcase": "separatorcase",
    "sentencecase": "sentencecase",
    "titlecase": "titlecase",
    "alphanumcase": "alphanumcase",
    "chance: Returns the content if the number you passed is greater than or equal to a random number between 1 and 100.": "chance: Returns the content if the number you passed is greater than or equal to a random number between 1 and 100.",
    "Highest possible roll 🡢 _sides": "Highest possible roll 🡢 _sides",
    "choose: Returns one of multiple options, delimited by newline or vertical pipe": "choose: Returns one of multiple options, delimited by newline or vertical pipe",
    "Number of times to choose 🡢 int": "Number of times to choose 🡢 int",
    "String delimiter when returning more than one choice 🡢 _sep": "String delimiter when returning more than one choice 🡢 _sep",
    "Custom weight per option 🡢 _weighted": "Custom weight per option 🡢 _weighted",
    "Override random nature of shortcode with predetermined outcome 🡢 _case": "Override random nature of shortcode with predetermined outcome 🡢 _case",
    "config: Updates your settings with the content for the duration of a run.": "config: Updates your settings with the content for the duration of a run.",
    "conjugate: Converts the content verb into another conjugated form.": "conjugate: Converts the content verb into another conjugated form.",
    "do: It's a do-until loop.": "do: It's a do-until loop.",
    "Until condition 🡢 until": "Until condition 🡢 until",
    "elif: Shorthand 'else-if.'": "elif: Shorthand 'else-if.'",
    "else: Returns content if a previous conditional shortcode failed its check, otherwise discards content.": "else: Returns content if a previous conditional shortcode failed its check, otherwise discards content.",
    "eval: Parses the content using the simpleeval library, returning the result. Particularly useful for arithmetic.": "eval: Parses the content using the simpleeval library, returning the result. Particularly useful for arithmetic.",
    "file: Processes the file content of 'path.'": "file: Processes the file content of 'path.'",
    "Filepath 🡢 str": "Filepath 🡢 str",
    "Expected encoding 🡢 _encoding": "Expected encoding 🡢 _encoding",
    "filelist: Returns a list of files at a given location using glob.": "filelist: Returns a list of files at a given location using glob.",
    "Result delimiter 🡢 _delimiter": "Result delimiter 🡢 _delimiter",
    "for: It's a for loop.": "for: It's a for loop.",
    "Set a variable 🡢 my_var": "Set a variable 🡢 my_var",
    "Conditional check 🡢 str": "Conditional check 🡢 str",
    "Operation to perform at the end step 🡢 str": "Operation to perform at the end step 🡢 str",
    "get: Returns the value of a variable.": "get: Returns the value of a variable.",
    "Variable to get 🡢 str": "Variable to get 🡢 str",
    "Default value if the variable doesn't exist 🡢 _default": "Default value if the variable doesn't exist 🡢 _default",
    "Separator string when returning multiple variables 🡢 _sep": "Separator string when returning multiple variables 🡢 _sep",
    "String to prepend to the variable 🡢 _before": "String to prepend to the variable 🡢 _before",
    "String to append to the variable 🡢 _after": "String to append to the variable 🡢 _after",
    "hypernyms: Replaces the content with one or more hypernyms.": "hypernyms: Replaces the content with one or more hypernyms.",
    "hyponyms: Replaces the content with one or more synonyms.": "hyponyms: Replaces the content with one or more synonyms.",
    "if: Checks whether a variable is equal to a given value.": "if: Checks whether a variable is equal to a given value.",
    "Conditional statement 🡢 my_var": "Conditional statement 🡢 my_var",
    "Evaluation method 🡢 _is": "Evaluation method 🡢 _is",
    "==": "==",
    "!=": "!=",
    "<": "<",
    "<=": "<=",
    ">": ">",
    ">=": ">=",
    "Invert evaluation such that a true statement will return false 🡢 _not": "Invert evaluation such that a true statement will return false 🡢 _not",
    "Return true if any one of multiple conditions are true 🡢 _any": "Return true if any one of multiple conditions are true 🡢 _any",
    "info: Returns various types of metadata about the content.": "info: Returns various types of metadata about the content.",
    "Return the character count 🡢 character_count": "Return the character count 🡢 character_count",
    "Return the word count 🡢 word_count": "Return the word count 🡢 word_count",
    "Return the CLIP token count (prompt complexity) 🡢 clip_count": "Return the CLIP token count (prompt complexity) 🡢 clip_count",
    "Return the count of a custom substring 🡢 string_count": "Return the count of a custom substring 🡢 string_count",
    "length: Returns the number of items in a delimited string.": "length: Returns the number of items in a delimited string.",
    "The string to evaluate 🡢 str": "The string to evaluate 🡢 str",
    "Delimiter to check for 🡢 _delimiter": "Delimiter to check for 🡢 _delimiter",
    "Maximum number to be returned 🡢 _max": "Maximum number to be returned 🡢 _max",
    "max: Returns the maximum value among the given arguments.": "max: Returns the maximum value among the given arguments.",
    "min: Returns the minimum value among the given arguments.": "min: Returns the minimum value among the given arguments.",
    "override: Force variable(s) to hold a pre-determined value the rest of the run.": "override: Force variable(s) to hold a pre-determined value the rest of the run.",
    "Arguments in variable=value format 🡢 verbatim": "Arguments in variable=value format 🡢 verbatim",
    "pluralize: Converts the content into plural form.": "pluralize: Converts the content into plural form.",
    "random: Returns a random number between 0 and a given max value (inclusive)": "random: Returns a random number between 0 and a given max value (inclusive)",
    "Minimum number 🡢 _min": "Minimum number 🡢 _min",
    "Maximum number 🡢 _max": "Maximum number 🡢 _max",
    "Evaluate as floats instead of integers 🡢 _float": "Evaluate as floats instead of integers 🡢 _float",
    "repeat: Returns the content an arbitrary number of times.": "repeat: Returns the content an arbitrary number of times.",
    "Number of times to repeat the content 🡢 int": "Number of times to repeat the content 🡢 int",
    "Delimiter string between outputs 🡢 _sep": "Delimiter string between outputs 🡢 _sep",
    "replace: Updates a string using the arguments for replacement logic.": "replace: Updates a string using the arguments for replacement logic.",
    "Arbitrary replacement arguments in old=new format 🡢 verbatim": "Arbitrary replacement arguments in old=new format 🡢 verbatim",
    "Original value, with advanced expression support 🡢 _from": "Original value, with advanced expression support 🡢 _from",
    "New value, with advanced expression support 🡢 _to": "New value, with advanced expression support 🡢 _to",
    "Maximum number of times the replacement may occur 🡢 _count": "Maximum number of times the replacement may occur 🡢 _count",
    "set: Stores a value into a given variable.": "set: Stores a value into a given variable.",
    "Variable name 🡢 verbatim": "Variable name 🡢 verbatim",
    "Only set this variable if it doesn't already exist 🡢 _new": "Only set this variable if it doesn't already exist 🡢 _new",
    "Array of valid values (used in conjunction with _new) 🡢 _choices": "Array of valid values (used in conjunction with _new) 🡢 _choices",
    "Append the content to the variable's current value 🡢 _append": "Append the content to the variable's current value 🡢 _append",
    "Prepend the content to the variable's current value 🡢 _prepend": "Prepend the content to the variable's current value 🡢 _prepend",
    "Print the variable's value 🡢 _out": "Print the variable's value 🡢 _out",
    "sets: The atomic version of [set] that lets you set multiple variables at once.": "sets: The atomic version of [set] that lets you set multiple variables at once.",
    "Arbitrary arguments in variable=value format 🡢 verbatim": "Arbitrary arguments in variable=value format 🡢 verbatim",
    "singularize: Converts the content into singular form.": "singularize: Converts the content into singular form.",
    "substring: Slices up the content.": "substring: Slices up the content.",
    "Beginning index of the substring 🡢 start": "Beginning index of the substring 🡢 start",
    "Ending index of the substring 🡢 end": "Ending index of the substring 🡢 end",
    "Step size 🡢 step": "Step size 🡢 step",
    "Unit type 🡢 unit": "Unit type 🡢 unit",
    "characters": "characters",
    "words": "words",
    "switch: Use in conjunction with [case] to run different logic blocks depending on the value of a var.": "switch: Use in conjunction with [case] to run different logic blocks depending on the value of a var.",
    "Variable to test against 🡢 verbatim": "Variable to test against 🡢 verbatim",
    "synonyms: Replaces the content with one or more synonyms.": "synonyms: Replaces the content with one or more synonyms.",
    "template: This is used by the Wizard to instantiate a custom template UI. It is bypassed by the normal shortcode parser.": "template: This is used by the Wizard to instantiate a custom template UI. It is bypassed by the normal shortcode parser.",
    "unset: Removes one or more variables from memory. Generally not needed.": "unset: Removes one or more variables from memory. Generally not needed.",
    "Arbitrary variable names to free from memory 🡢 verbatim": "Arbitrary variable names to free from memory 🡢 verbatim",
    "while: Loops content until the condition returns false.": "while: Loops content until the condition returns false.",
    "Arbitrary conditional statement(s) to test against 🡢 verbatim": "Arbitrary conditional statement(s) to test against 🡢 verbatim",
    "Invert evaluation such that a false condition will end the loop 🡢 _not": "Invert evaluation such that a false condition will end the loop 🡢 _not",
    "controlnet: A neural network structure to control diffusion models by adding extra conditions. Check manual for setup info.": "controlnet: A neural network structure to control diffusion models by adding extra conditions. Check manual for setup info.",
    "Model name (do not include extension) 🡢 model": "Model name (do not include extension) 🡢 model",
    "Resolution of the detection map 🡢 detect_resolution": "Resolution of the detection map 🡢 detect_resolution",
    "Use low VRAM mode? 🡢 save_memory": "Use low VRAM mode? 🡢 save_memory",
    "DDIM ETA 🡢 eta": "DDIM ETA 🡢 eta",
    "Value Threshold 🡢 value_threhsold": "Value Threshold 🡢 value_threhsold",
    "Distance Threshold 🡢 distance_threhsold": "Distance Threshold 🡢 distance_threhsold",
    "Background Threshold 🡢 bg_threhsold": "Background Threshold 🡢 bg_threhsold",
    "Canny low threshold 🡢 low_threshold": "Canny low threshold 🡢 low_threshold",
    "Canny high threshold 🡢 high_threshold": "Canny high threshold 🡢 high_threshold",
    "Render hands with Openpose? 🡢 openpose_hands": "Render hands with Openpose? 🡢 openpose_hands",
    "enable_multi_images: Allows to use multiple init_images or multiple masks": "enable_multi_images: Allows to use multiple init_images or multiple masks",
    "file2mask: Modify or replace your img2img mask with arbitrary files.": "file2mask: Modify or replace your img2img mask with arbitrary files.",
    "Path to image file 🡢 str": "Path to image file 🡢 str",
    "Mask blend mode 🡢 mode": "Mask blend mode 🡢 mode",
    "add": "add",
    "subtract": "subtract",
    "discard": "discard",
    "Show mask in output 🡢 show": "Show mask in output 🡢 show",
    "img2img: Runs an img2img task inside of an [after] block.": "img2img: Runs an img2img task inside of an [after] block.",
    "img2img_autosize: Automatically adjusts the width and height parameters in img2img mode based on the proportions of the input image.": "img2img_autosize: Automatically adjusts the width and height parameters in img2img mode based on the proportions of the input image.",
    "Minimum pixels of at least one dimension 🡢 target": "Minimum pixels of at least one dimension 🡢 target",
    "Only run this shortcode if using full resolution inpainting mode 🡢 only_full_res": "Only run this shortcode if using full resolution inpainting mode 🡢 only_full_res",
    "img2pez: Optimize a hard prompt using the PEZ algorithm and CLIP encoders, AKA Hard Prompts Made Easy.": "img2pez: Optimize a hard prompt using the PEZ algorithm and CLIP encoders, AKA Hard Prompts Made Easy.",
    "Image path 🡢 image_path": "Image path 🡢 image_path",
    "Prompt length 🡢 prompt_length": "Prompt length 🡢 prompt_length",
    "Iterations 🡢 iterations": "Iterations 🡢 iterations",
    "Learning rate 🡢 learning_rate": "Learning rate 🡢 learning_rate",
    "Weight decay 🡢 weight_decay": "Weight decay 🡢 weight_decay",
    "Prompt bs (well, that's what they call it) 🡢 prompt_bs": "Prompt bs (well, that's what they call it) 🡢 prompt_bs",
    "CLIP model 🡢 clip_model": "CLIP model 🡢 clip_model",
    "ViT-L-14": "ViT-L-14",
    "ViT-H-14": "ViT-H-14",
    "CLIP pretrain 🡢 clip_pretrain": "CLIP pretrain 🡢 clip_pretrain",
    "openai": "openai",
    "laion2b_s32b_b79k": "laion2b_s32b_b79k",
    "Try freeing CLIP model from memory? 🡢 free_memory": "Try freeing CLIP model from memory? 🡢 free_memory",
    "init_image: Loads an image from the given path and sets it as the initial image for use with img2img.": "init_image: Loads an image from the given path and sets it as the initial image for use with img2img.",
    "Image path": "Image path",
    "instance2mask: Creates an image mask from instances of types specified by the content for use with inpainting.": "instance2mask: Creates an image mask from instances of types specified by the content for use with inpainting.",
    "refine": "refine",
    "Run inpaint per instance found 🡢 per_instance": "Run inpaint per instance found 🡢 per_instance",
    "Precision of selected area 🡢 mask_precision": "Precision of selected area 🡢 mask_precision",
    "Padding radius in pixels 🡢 padding": "Padding radius in pixels 🡢 padding",
    "Smoothing radius in pixels 🡢 smoothing": "Smoothing radius in pixels 🡢 smoothing",
    "Precision of instance selection 🡢 instance_precision": "Precision of instance selection 🡢 instance_precision",
    "Number of instance to select 🡢 select": "Number of instance to select 🡢 select",
    "Instance selection mode 🡢 select_mode": "Instance selection mode 🡢 select_mode",
    "overlap": "overlap",
    "relative overlap": "relative overlap",
    "greatest area": "greatest area",
    "invert_mask: Inverts the mask (great in combination with multiple txt2masks)": "invert_mask: Inverts the mask (great in combination with multiple txt2masks)",
    "pix2pix_zero: A diffusion-based image-to-image approach that allows users to specify the edit direction on-the-fly.": "pix2pix_zero: A diffusion-based image-to-image approach that allows users to specify the edit direction on-the-fly.",
    "txt2mask: Creates an image mask from the content for use with inpainting.": "txt2mask: Creates an image mask from the content for use with inpainting.",
    "Use legacy weights 🡢 legacy_weights": "Use legacy weights 🡢 legacy_weights",
    "Precision of selected area 🡢 precision": "Precision of selected area 🡢 precision",
    "Negative mask prompt 🡢 negative_mask": "Negative mask prompt 🡢 negative_mask",
    "Negative mask precision of selected area 🡢 neg_precision": "Negative mask precision of selected area 🡢 neg_precision",
    "Negative mask padding radius in pixels 🡢 neg_padding": "Negative mask padding radius in pixels 🡢 neg_padding",
    "Negative mask smoothing radius in pixels 🡢 neg_smoothing": "Negative mask smoothing radius in pixels 🡢 neg_smoothing",
    "Mask color, enables Inpaint Sketch mode 🡢 sketch_color": "Mask color, enables Inpaint Sketch mode 🡢 sketch_color",
    "Mask alpha, must be used in conjunction with mask color 🡢 sketch_alpha": "Mask alpha, must be used in conjunction with mask color 🡢 sketch_alpha",
    "Save the mask size to the following variable 🡢 size_var": "Save the mask size to the following variable 🡢 size_var",
    "Process Text": "Process Text",
    "Re-process extra networks after Unprompted is finished (WIP - this is not yet functional!)": "Re-process extra networks after Unprompted is finished (WIP - this is not yet functional!)",
    "unprompted": "unprompted",
    "Photo of a cat": "Photo of a cat",
    "Walter White": "Walter White",
    "my_array": "my_array",
    "my_var < 10": "my_var < 10",
    "my_var + 1": "my_var + 1",
    "my_var=6 another_var=\"300\"": "my_var=6 another_var=\"300\"",
    "hello=\"goodbye\" red=\"blue\"": "hello=\"goodbye\" red=\"blue\"",
    "my_var=\"something\" another_var=56": "my_var=\"something\" another_var=56",
    "my_var another_var": "my_var another_var",
    "Leave blank to use the initial img2img image. Supports multiple paths.": "Leave blank to use the initial img2img image. Supports multiple paths.",
    "e.g. tan or 127,127,127": "e.g. tan or 127,127,127",
    "Test prompt": "Test prompt",
    "Posex": "Posex",
    "Send this image to ControlNet.": "Send this image to ControlNet.",
    "Target ControlNet number": "Target ControlNet number",
    "https://github.com/hnmr293/posex.git": "https://github.com/hnmr293/posex.git",
    "Artists To Study": "Artists To Study",
    "dog": "dog",
    "house": "house",
    "portrait": "portrait",
    "spaceship": "spaceship",
    "anime": "anime",
    "cartoon": "cartoon",
    "digipa-high-impact": "digipa-high-impact",
    "digipa-med-impact": "digipa-med-impact",
    "digipa-low-impact": "digipa-low-impact",
    "fareast": "fareast",
    "fineart": "fineart",
    "scribbles": "scribbles",
    "special": "special",
    "ukioe": "ukioe",
    "weird": "weird",
    "black-white": "black-white",
    "nudity": "nudity",
    "c": "c",
    "n": "n",
    "Get Images": "Get Images",
    "dog-anime": "dog-anime",
    "dog-cartoon": "dog-cartoon",
    "dog-digipa-high-impact": "dog-digipa-high-impact",
    "dog-digipa-med-impact": "dog-digipa-med-impact",
    "dog-digipa-low-impact": "dog-digipa-low-impact",
    "dog-fareast": "dog-fareast",
    "dog-fineart": "dog-fineart",
    "dog-scribbles": "dog-scribbles",
    "dog-special": "dog-special",
    "dog-ukioe": "dog-ukioe",
    "dog-weird": "dog-weird",
    "dog-black-white": "dog-black-white",
    "dog-nudity": "dog-nudity",
    "dog-c": "dog-c",
    "dog-n": "dog-n",
    "house-anime": "house-anime",
    "house-cartoon": "house-cartoon",
    "house-digipa-high-impact": "house-digipa-high-impact",
    "house-digipa-med-impact": "house-digipa-med-impact",
    "house-digipa-low-impact": "house-digipa-low-impact",
    "house-fareast": "house-fareast",
    "house-fineart": "house-fineart",
    "house-scribbles": "house-scribbles",
    "house-special": "house-special",
    "house-ukioe": "house-ukioe",
    "house-weird": "house-weird",
    "house-black-white": "house-black-white",
    "house-nudity": "house-nudity",
    "house-c": "house-c",
    "house-n": "house-n",
    "portrait-anime": "portrait-anime",
    "portrait-cartoon": "portrait-cartoon",
    "portrait-digipa-high-impact": "portrait-digipa-high-impact",
    "portrait-digipa-med-impact": "portrait-digipa-med-impact",
    "portrait-digipa-low-impact": "portrait-digipa-low-impact",
    "portrait-fareast": "portrait-fareast",
    "portrait-fineart": "portrait-fineart",
    "portrait-scribbles": "portrait-scribbles",
    "portrait-special": "portrait-special",
    "portrait-ukioe": "portrait-ukioe",
    "portrait-weird": "portrait-weird",
    "portrait-black-white": "portrait-black-white",
    "portrait-nudity": "portrait-nudity",
    "portrait-c": "portrait-c",
    "portrait-n": "portrait-n",
    "spaceship-anime": "spaceship-anime",
    "spaceship-cartoon": "spaceship-cartoon",
    "spaceship-digipa-high-impact": "spaceship-digipa-high-impact",
    "spaceship-digipa-med-impact": "spaceship-digipa-med-impact",
    "spaceship-digipa-low-impact": "spaceship-digipa-low-impact",
    "spaceship-fareast": "spaceship-fareast",
    "spaceship-fineart": "spaceship-fineart",
    "spaceship-scribbles": "spaceship-scribbles",
    "spaceship-special": "spaceship-special",
    "spaceship-ukioe": "spaceship-ukioe",
    "spaceship-weird": "spaceship-weird",
    "spaceship-black-white": "spaceship-black-white",
    "spaceship-nudity": "spaceship-nudity",
    "spaceship-c": "spaceship-c",
    "spaceship-n": "spaceship-n",
    "artists to study extension by camenduru |": "artists to study extension by camenduru |",
    "github": "github",
    "|": "|",
    "twitter": "twitter",
    "youtube": "youtube",
    "hi-res images": "hi-res images",
    "All images generated with CompVis/stable-diffusion-v1-4 +": "All images generated with CompVis/stable-diffusion-v1-4 +",
    "artists.csv": "artists.csv",
    "| License: Attribution 4.0 International (CC BY 4.0)": "| License: Attribution 4.0 International (CC BY 4.0)",
    "stable-diffusion-webui-artists-to-study": "stable-diffusion-webui-artists-to-study",
    "https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git": "https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git",
    "ddetailer": "ddetailer",
    "NAIConvert": "NAIConvert",
    "History": "History",
    "https://github.com/animerl/novelai-2-local-prompt.git": "https://github.com/animerl/novelai-2-local-prompt.git",
    "stable-diffusion-webui-auto-tls-https": "stable-diffusion-webui-auto-tls-https",
    "Text2Prompt": "Text2Prompt",
    "Input Theme": "Input Theme",
    "Input Negative Theme": "Input Negative Theme",
    "Negative strength": "Negative strength",
    "Replace underscore in tag with whitespace": "Replace underscore in tag with whitespace",
    "Escape brackets in tag": "Escape brackets in tag",
    "Generation Settings": "Generation Settings",
    "Database": "Database",
    "Tag count filter": "Tag count filter",
    "Tag range:": "Tag range:",
    "≥ 0 tagged": "≥ 0 tagged",
    "(14589 tags total)": "(14589 tags total)",
    "Method to convert similarity into probability": "Method to convert similarity into probability",
    "Cutoff and Power": "Cutoff and Power",
    "Softmax": "Softmax",
    "Power": "Power",
    "NONE": "NONE",
    "Top-k": "Top-k",
    "Top-p (Nucleus)": "Top-p (Nucleus)",
    "Max number of tags": "Max number of tags",
    "k value": "k value",
    "p value": "p value",
    "Use weighted choice": "Use weighted choice",
    "stable-diffusion-webui-text2prompt": "stable-diffusion-webui-text2prompt",
    "https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git": "https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git",
    "Enable": "Enable",
    "Highres. percentage chance": "Highres. percentage chance",
    "Highres. Denoising Strength": "Highres. Denoising Strength",
    "Highres. Width": "Highres. Width",
    "Highres. Height": "Highres. Height",
    "Stop at CLIP layers": "Stop at CLIP layers",
    "stable-diffusion-webui-randomize": "stable-diffusion-webui-randomize",
    "Comma separated list OR * for all": "Comma separated list OR * for all",
    "Range of stepped values (min, max, step)": "Range of stepped values (min, max, step)",
    "Float value from 0 to 1": "Float value from 0 to 1",
    "Loads weights from checkpoint before making images. You can either use hash or a part of filename (as seen in settings) for checkpoint name. Recommended to use with Y axis for less switching.": "Loads weights from checkpoint before making images. You can either use hash or a part of filename (as seen in settings) for checkpoint name. Recommended to use with Y axis for less switching.",
    "Create inspiration images": "Create inspiration images",
    "Artist or styles name list. '.txt' files with one name per line": "Artist or styles name list. '.txt' files with one name per line",
    "Prompt Placeholder, which can be used at the top of prompt input": "Prompt Placeholder, which can be used at the top of prompt input",
    "To activate inspiration function, you need get \"inspiration\" images first.": "To activate inspiration function, you need get \"inspiration\" images first.",
    "You can create these images by run \"Create inspiration images\" script in txt2img page,": "You can create these images by run \"Create inspiration images\" script in txt2img page,",
    "you can get the artists or art styles list from here": "you can get the artists or art styles list from here",
    "download these files, and select these files in the \"Create inspiration images\" script UI": "download these files, and select these files in the \"Create inspiration images\" script UI",
    "There about 6000 artists and art styles in these files.": "There about 6000 artists and art styles in these files.",
    "This takes server hours depending on your GPU type and how many pictures  you generate for each artist/style": "This takes server hours depending on your GPU type and how many pictures  you generate for each artist/style",
    "I suggest at least four images for each": "I suggest at least four images for each",
    "You can also download generated pictures from here:": "You can also download generated pictures from here:",
    "unzip the file to": "unzip the file to",
    "/extections/stable-diffusion-webui-inspiration": "/extections/stable-diffusion-webui-inspiration",
    "and restart webui, and enjoy the joy of creation!": "and restart webui, and enjoy the joy of creation!",
    "Maximum number of samples, used to determine which folders to skip when continue running the create script": "Maximum number of samples, used to determine which folders to skip when continue running the create script",
    "stable-diffusion-webui-inspiration": "stable-diffusion-webui-inspiration",
    "https://github.com/toriato/stable-diffusion-webui-daam.git": "https://github.com/toriato/stable-diffusion-webui-daam.git",
    "Checkbox Group": "Checkbox Group",
    "artists": "artists",
    "flavors": "flavors",
    "mediums": "mediums",
    "movements": "movements",
    "Exclude abandoned": "Exclude abandoned",
    "Abandoned": "Abandoned",
    "Key word": "Key word",
    "Get inspiration": "Get inspiration",
    "to txt2img": "to txt2img",
    "to img2img": "to img2img",
    "Collect": "Collect",
    "Don't show again": "Don't show again",
    "https://github.com/yfszzx/stable-diffusion-webui-inspiration.git": "https://github.com/yfszzx/stable-diffusion-webui-inspiration.git",
    "Enable Bilingual Localization": "バイリンガルを有効にする",
    "Localization file (Please leave `User interface` - `Localization` as None)": "言語ファイル(`User Interface` - `Localization` をNoneに変更してください)",
    "Translation display order": "表示順",
    "Translation First": "ローカライズを優先",
    "Original First": "オリジナルを優先",
    "Localization dirs": "言語ファイルのディレクトリ",
    "sd-webui-bilingual-localization": "sd-webui-bilingual-localization",
    "https://github.com/journey-ad/sd-webui-bilingual-localization.git": "https://github.com/journey-ad/sd-webui-bilingual-localization.git",
    "Use same seed for all images": "全ての画像で同じシードを使用する",
    "stable-diffusion-webui-wildcards": "stable-diffusion-webui-wildcards",
    "Tag Autocomplete": "Tag Autocomplete",
    "Tag filename": "Tag filename",
    "Enable Tag Autocompletion": "Enable Tag Autocompletion",
    "Active in txt2img (Requires restart)": "Active in txt2img (Requires restart)",
    "Active in img2img (Requires restart)": "Active in img2img (Requires restart)",
    "Active in negative prompts (Requires restart)": "Active in negative prompts (Requires restart)",
    "Active in third party textboxes [Dataset Tag Editor] (Requires restart)": "Active in third party textboxes [Dataset Tag Editor] (Requires restart)",
    "List of model names (with file extension) or their hashes to use as black/whitelist, separated by commas.": "List of model names (with file extension) or their hashes to use as black/whitelist, separated by commas.",
    "Mode to use for model list": "Mode to use for model list",
    "Blacklist": "Blacklist",
    "Whitelist": "Whitelist",
    "Move completion popup together with text cursor": "Move completion popup together with text cursor",
    "Maximum results": "Maximum results",
    "Show all results": "Show all results",
    "How many results to load at once": "How many results to load at once",
    "Time in ms to wait before triggering completion again (Requires restart)": "Time in ms to wait before triggering completion again (Requires restart)",
    "Search for wildcards": "Search for wildcards",
    "Search for embeddings": "Search for embeddings",
    "Search for hypernetworks": "Search for hypernetworks",
    "Search for Loras": "Search for Loras",
    "Show '?' next to tags, linking to its Danbooru or e621 wiki page (Warning: This is an external site and very likely contains NSFW examples!)": "Show '?' next to tags, linking to its Danbooru or e621 wiki page (Warning: This is an external site and very likely contains NSFW examples!)",
    "Replace underscores with spaces on insertion": "Replace underscores with spaces on insertion",
    "Escape parentheses on insertion": "Escape parentheses on insertion",
    "Append comma on tag autocompletion": "Append comma on tag autocompletion",
    "Search by alias": "Search by alias",
    "Only show alias": "Only show alias",
    "Translation filename": "Translation filename",
    "Translation file uses old 3-column translation format instead of the new 2-column one": "Translation file uses old 3-column translation format instead of the new 2-column one",
    "Search by translation": "Search by translation",
    "Extra filename (for small sets of custom tags)": "Extra filename (for small sets of custom tags)",
    "Mode to add the extra tags to the main tag list": "Mode to add the extra tags to the main tag list",
    "Insert before": "Insert before",
    "Insert after": "Insert after",
    "a1111-sd-webui-tagcomplete": "a1111-sd-webui-tagcomplete",
    "https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git": "https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git",
    "Smart Preprocess": "Smart Preprocess",
    "sd_smartprocess": "sd_smartprocess",
    "Rename images": "Rename images",
    "Cropping": "Cropping",
    "Output Size": "Output Size",
    "Pad Images": "Pad Images",
    "Crop Images": "Crop Images",
    "Captions": "Captions",
    "Generate Captions": "Generate Captions",
    "Max Caption Length (0=unlimited)": "Max Caption Length (0=unlimited)",
    "Existing Caption Action": "Existing Caption Action",
    "Add CLIP results to Caption": "Add CLIP results to Caption",
    "Number of CLIP beams": "Number of CLIP beams",
    "CLIP Minimum length": "CLIP Minimum length",
    "CLIP Maximum length": "CLIP Maximum length",
    "Use v2 CLIP Model": "Use v2 CLIP Model",
    "Append Flavor tags from CLIP": "Append Flavor tags from CLIP",
    "Max flavors to append.": "Max flavors to append.",
    "Append Medium tags from CLIP": "Append Medium tags from CLIP",
    "Append Movement tags from CLIP": "Append Movement tags from CLIP",
    "Append Artist tags from CLIP": "Append Artist tags from CLIP",
    "Append Trending tags from CLIP": "Append Trending tags from CLIP",
    "Add WD14 Tags to Caption": "Add WD14 Tags to Caption",
    "Minimum Score for WD14 Tags": "Minimum Score for WD14 Tags",
    "Minimum Score for DeepDanbooru Tags": "Minimum Score for DeepDanbooru Tags",
    "Tags To Ignore": "Tags To Ignore",
    "Replace Class with Subject in Caption": "Replace Class with Subject in Caption",
    "Subject Class": "Subject Class",
    "Subject class to crop (leave blank to auto-detect)": "Subject class to crop (leave blank to auto-detect)",
    "Subject Name": "Subject Name",
    "Subject Name to replace class with in captions": "Subject Name to replace class with in captions",
    "Post-Processing": "Post-Processing",
    "Face Restore Model": "Face Restore Model",
    "Upscale and Resize": "Upscale and Resize",
    "https://github.com/d8ahazard/sd_smartprocess.git": "https://github.com/d8ahazard/sd_smartprocess.git",
    "CLIP_test": "CLIP_test",
    "Create Beta hypernetwork": "Create Beta hypernetwork",
    "Train_Gamma": "Train_Gamma",
    "Train_Tuning": "Train_Tuning",
    "Show advanced options": "Show advanced options",
    "Weight initialization seed, set -1 for default": "Weight initialization seed, set -1 for default",
    "Standard Deviation for Normal weight initialization": "Standard Deviation for Normal weight initialization",
    "Use dropout. Might improve training when dataset is small / limited.": "Use dropout. Might improve training when dataset is small / limited.",
    "Use skip-connection. Won't work without extension!": "Use skip-connection. Won't work without extension!",
    "Optional information about Hypernetwork": "Optional information about Hypernetwork",
    "Setting file name": "Setting file name",
    "Save hypernetwork setting to file": "Save hypernetwork setting to file",
    "Train an embedding or Hypernetwork; you must specify a directory": "Train an embedding or Hypernetwork; you must specify a directory",
    "Show advanced learn rate scheduler options": "Show advanced learn rate scheduler options",
    "Show advanced adamW parameter options)": "Show advanced adamW parameter options)",
    "Show Gradient Clipping Options(for both)": "Show Gradient Clipping Options(for both)",
    "Show Noise Scheduler Options(for both)": "Show Noise Scheduler Options(for both)",
    "Uses D-Adaptation(LR Free) AdamW. Recommended LR is 1.0 at base": "Uses D-Adaptation(LR Free) AdamW. Recommended LR is 1.0 at base",
    "AdamW weight decay parameter": "AdamW weight decay parameter",
    "AdamW beta1 parameter": "AdamW beta1 parameter",
    "AdamW beta2 parameter": "AdamW beta2 parameter",
    "AdamW epsilon parameter": "AdamW epsilon parameter",
    "Growth factor limiting, use value like 1.02 or leave it as -1": "Growth factor limiting, use value like 1.02 or leave it as -1",
    "Use CosineAnnealingWarmupRestarts Scheduler": "Use CosineAnnealingWarmupRestarts Scheduler",
    "Steps for cycle": "Steps for cycle",
    "Step multiplier per cycle": "Step multiplier per cycle",
    "Warmup step per cycle": "Warmup step per cycle",
    "Minimum learning rate": "Minimum learning rate",
    "Decays learning rate every cycle": "Decays learning rate every cycle",
    "Saves when every cycle finishes": "Saves when every cycle finishes",
    "Generates image when every cycle finishes": "Generates image when every cycle finishes",
    "Gradient Clipping Options": "Gradient Clipping Options",
    "limit": "limit",
    "Limiting value": "Limiting value",
    "Norm type": "Norm type",
    "Use Noise training scheduler(test)": "Use Noise training scheduler(test)",
    "Restarts noise scheduler, or linear": "Restarts noise scheduler, or linear",
    "Restarts noise scheduler every nth epoch": "Restarts noise scheduler every nth epoch",
    "Unload Optimizer when generating preview(hypernetwork)": "Unload Optimizer when generating preview(hypernetwork)",
    "Standard deviation for sampling": "Standard deviation for sampling",
    "loss type": "loss type",
    "loss": "loss",
    "loss_simple": "loss_simple",
    "loss_vlb": "loss_vlb",
    "Save training setting": "Save training setting",
    "File name to save setting as": "File name to save setting as",
    "Load training option from saved json file. This will override settings above": "Load training option from saved json file. This will override settings above",
    "Train Hypernetwork; you must specify a directory": "Train Hypernetwork; you must specify a directory",
    "Hypernetwork name to create, leave it empty to use selected": "Hypernetwork name to create, leave it empty to use selected",
    "Load Hypernetwork creation option from saved json file": "Load Hypernetwork creation option from saved json file",
    "Load training option(s) from saved json file": "Load training option(s) from saved json file",
    "Save a copy of model to log directory every N steps, 0 to disable": "Save a copy of model to log directory every N steps, 0 to disable",
    "Manual dataset seed": "Manual dataset seed",
    "CLIP-test": "CLIP-test",
    "CLIP Text models. Set to empty to not change.": "CLIP Text models. Set to empty to not change.",
    "Enable clip model change. This will be triggered from next model changes.": "Enable clip model change. This will be triggered from next model changes.",
    "Detach grad from conditioning models": "Detach grad from conditioning models",
    "Hypernetwork-MonkeyPatch-Extension": "Hypernetwork-MonkeyPatch-Extension",
    "must be positive float": "must be positive float",
    "Training information, dateset, etc": "Training information, dateset, etc",
    "default = 0.01": "default = 0.01",
    "default = 0.9": "default = 0.9",
    "default = 0.99": "default = 0.99",
    "default = 1e-8": "default = 1e-8",
    "Cycles every nth Step": "Cycles every nth Step",
    "Step length multiplier every cycle": "Step length multiplier every cycle",
    "CosineAnnealing lr increase step": "CosineAnnealing lr increase step",
    "restricts decay value, but does not restrict gamma rate decay": "restricts decay value, but does not restrict gamma rate decay",
    "Value should be in (0-1]": "Value should be in (0-1]",
    ". filename cannot have ',' inside, and files should be splitted by ','.": ". filename cannot have ',' inside, and files should be splitted by ','.",
    "Conditioning Highres": "Conditioning Highres",
    "Conditioning Highres.fix strength (for sd-v1-5-inpainting)": "Conditioning Highres.fix strength (for sd-v1-5-inpainting)",
    "Cond.fix: Disabled (none)": "Cond.fix: Disabled (none)",
    "Cond.fix: Empty": "Cond.fix: Empty",
    "Cond.fix: Lowest": "Cond.fix: Lowest",
    "Cond.fix: Low": "Cond.fix: Low",
    "Cond.fix: Medium": "Cond.fix: Medium",
    "Cond.fix: High (recommended)": "Cond.fix: High (recommended)",
    "Cond.fix: Highest": "Cond.fix: Highest",
    "Cond.fix: Full": "Cond.fix: Full",
    "stable-diffusion-webui-conditioning-highres-fix": "stable-diffusion-webui-conditioning-highres-fix",
    "https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git": "https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git",
    "img2img folder": "img2img folder",
    "Image folder 🡢 folder": "Image folder 🡢 folder",
    "String to include before the filename 🡢 pre": "String to include before the filename 🡢 pre",
    "String to include after the filename 🡢 post": "String to include after the filename 🡢 post",
    "##": "##",
    "#": "#",
    "after": "after",
    "antonyms": "antonyms",
    "array": "array",
    "article": "article",
    "autocorrect": "autocorrect",
    "case": "case",
    "casing": "casing",
    "chance": "chance",
    "choose": "choose",
    "config": "config",
    "conjugate": "conjugate",
    "do": "do",
    "elif": "elif",
    "else": "else",
    "eval": "eval",
    "file": "file",
    "filelist": "filelist",
    "get": "get",
    "hypernyms": "hypernyms",
    "hyponyms": "hyponyms",
    "if": "if",
    "info": "info",
    "Return the sentence count 🡢 sentence_count": "Return the sentence count 🡢 sentence_count",
    "Return the filename 🡢 filename": "Return the filename 🡢 filename",
    "length": "length",
    "max": "max",
    "min": "min",
    "override": "override",
    "pluralize": "pluralize",
    "repeat": "repeat",
    "replace": "replace",
    "set": "set",
    "sets": "sets",
    "singularize": "singularize",
    "switch": "switch",
    "synonyms": "synonyms",
    "unset": "unset",
    "while": "while",
    "controlnet": "controlnet",
    "enable_multi_images": "enable_multi_images",
    "file2mask": "file2mask",
    "img2img_autosize": "img2img_autosize",
    "img2pez": "img2pez",
    "init_image": "init_image",
    "instance2mask": "instance2mask",
    "invert_mask": "invert_mask",
    "pix2pix_zero": "pix2pix_zero",
    "txt2mask": "txt2mask",
    "zoom_enhance": "zoom_enhance",
    "zoom_enhance: Upscales a selected portion of the image. ENHANCE!": "zoom_enhance: Upscales a selected portion of the image. ENHANCE!",
    "Final image not showing up? Try using this workaround 🡢 use_workaround": "Final image not showing up? Try using this workaround 🡢 use_workaround",
    "Mask to find 🡢 mask": "Mask to find 🡢 mask",
    "Replacement 🡢 replacement": "Replacement 🡢 replacement",
    "Negative replacement 🡢 negative_replacement": "Negative replacement 🡢 negative_replacement",
    "Mask sorting method 🡢 mask_sort_method": "Mask sorting method 🡢 mask_sort_method",
    "left-to-right": "left-to-right",
    "right-to-left": "right-to-left",
    "top-to-bottom": "top-to-bottom",
    "bottom-to-top": "bottom-to-top",
    "big-to-small": "big-to-small",
    "small-to-big": "small-to-big",
    "unsorted": "unsorted",
    "Blur edges size 🡢 blur_size": "Blur edges size 🡢 blur_size",
    "Minimum CFG scale 🡢 cfg_scale_min": "Minimum CFG scale 🡢 cfg_scale_min",
    "Maximum denoising strength 🡢 denoising_max": "Maximum denoising strength 🡢 denoising_max",
    "Maximum mask size (if a bigger mask is found, it will bypass the shortcode) 🡢 mask_size_max": "Maximum mask size (if a bigger mask is found, it will bypass the shortcode) 🡢 mask_size_max",
    "Force denoising strength to this value 🡢 denoising_strength": "Force denoising strength to this value 🡢 denoising_strength",
    "Force CFG scale to this value 🡢 cfg_scale": "Force CFG scale to this value 🡢 cfg_scale",
    "Mask minimum number of pixels 🡢 min_area": "Mask minimum number of pixels 🡢 min_area",
    "Contour padding in pixels 🡢 contour_padding": "Contour padding in pixels 🡢 contour_padding",
    "Upscale width 🡢 upscale_width": "Upscale width 🡢 upscale_width",
    "Upscale height 🡢 upscale_height": "Upscale height 🡢 upscale_height",
    "Include original image in output window 🡢 include_original": "Include original image in output window 🡢 include_original",
    "Save debug images to WebUI folder 🡢 save": "Save debug images to WebUI folder 🡢 save",
    "https://github.com/ThereforeGames/unprompted.git": "https://github.com/ThereforeGames/unprompted.git",
    "https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git": "https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git",
    "Wildcards Manager": "Wildcards Manager",
    "Dynamic Prompts enabled": "Dynamic Prompts enabled",
    "Combinatorial generation": "Combinatorial generation",
    "Max generations (0 = all combinations - the batch count value is ignored)": "Max generations (0 = all combinations - the batch count value is ignored)",
    "Combinatorial batches": "Combinatorial batches",
    "Prompt Magic": "Prompt Magic",
    "Magic prompt": "Magic prompt",
    "Max magic prompt length": "Max magic prompt length",
    "Magic prompt creativity": "Magic prompt creativity",
    "Magic prompt model": "Magic prompt model",
    "Magic prompt blocklist regex": "Magic prompt blocklist regex",
    "I'm feeling lucky": "I'm feeling lucky",
    "Attention grabber": "Attention grabber",
    "Minimum attention": "Minimum attention",
    "Maximum attention": "Maximum attention",
    "Don't apply to negative prompts": "Don't apply to negative prompts",
    "Need help?": "Need help?",
    "Syntax cheatsheet": "Syntax cheatsheet",
    "Tutorial": "Tutorial",
    "Discussions": "Discussions",
    "Report a bug": "Report a bug",
    "Combinations": "Combinations",
    "Choose a number of terms from a list, in this case we choose two artists:": "Choose a number of terms from a list, in this case we choose two artists:",
    "{2$$artist1|artist2|artist3}": "{2$$artist1|artist2|artist3}",
    "If $$ is not provided, then 1$$ is assumed.": "If $$ is not provided, then 1$$ is assumed.",
    "If the chosen number of terms is greater than the available terms, then some terms will be duplicated, otherwise chosen terms will be unique. This is useful in the case of wildcards, e.g.": "If the chosen number of terms is greater than the available terms, then some terms will be duplicated, otherwise chosen terms will be unique. This is useful in the case of wildcards, e.g.",
    "{2$$__artist__}": "{2$$__artist__}",
    "is equivalent to": "is equivalent to",
    "{2$$__artist__|__artist__}": "{2$$__artist__|__artist__}",
    "A range can be provided:": "A range can be provided:",
    "{1-3$$artist1|artist2|artist3}": "{1-3$$artist1|artist2|artist3}",
    "In this case, a random number of artists between 1 and 3 is chosen.": "In this case, a random number of artists between 1 and 3 is chosen.",
    "Options can be given weights:": "Options can be given weights:",
    "{2::artist1|artist2}": "{2::artist1|artist2}",
    "In this case, artist1 will be chosen twice as often as artist2.": "In this case, artist1 will be chosen twice as often as artist2.",
    "Wildcards can be used and the joiner can also be specified:": "Wildcards can be used and the joiner can also be specified:",
    "{{1-$$and$$__adjective__}}": "{{1-$$and$$__adjective__}}",
    "Here, a random number between 1 and 3 words from adjective.txt will be chosen and joined together with the word 'and' instead of the default comma.": "Here, a random number between 1 and 3 words from adjective.txt will be chosen and joined together with the word 'and' instead of the default comma.",
    "Find and manage wildcards in the Wildcards Manager tab.": "Find and manage wildcards in the Wildcards Manager tab.",
    "You can add more wildcards by creating a text file with one term per line and name is mywildcards.txt. Place it in D:\\StableDiffusion\\clean install\\webui\\extensions\\sd-dynamic-prompts\\wildcards.": "You can add more wildcards by creating a text file with one term per line and name is mywildcards.txt. Place it in D:\\StableDiffusion\\clean install\\webui\\extensions\\sd-dynamic-prompts\\wildcards.",
    "__<folder>/mywildcards__": "__<folder>/mywildcards__",
    "will then become available.": "will then become available.",
    "Find more settings on the": "Find more settings on the",
    "tab": "tab",
    "You are using": "You are using",
    "version 2.7.2 of the WebUI extension": "version 2.7.2 of the WebUI extension",
    ", and the underlying": ", and the underlying",
    "dynamicprompts library is version 0.7.1": "dynamicprompts library is version 0.7.1",
    "Jinja2 templates": "Jinja2 templates",
    "Enable Jinja2 templates": "Enable Jinja2 templates",
    "Help for Jinja2 templates": "Help for Jinja2 templates",
    "Jinja2 templates is an experimental feature for advanced template generation. It is not recommended for general use unless you are comfortable with writing scripts.": "Jinja2 templates is an experimental feature for advanced template generation. It is not recommended for general use unless you are comfortable with writing scripts.",
    "Literals": "Literals",
    "I love red roses": "I love red roses",
    "Random choices": "Random choices",
    "I love {{ choice('red', 'blue', 'green') }} roses": "I love {{ choice('red', 'blue', 'green') }} roses",
    "This will randomly choose one of the three colors.": "This will randomly choose one of the three colors.",
    "Iterations": "Iterations",
    "{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}": "{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",
    "This will produce three prompts, one for each color. The prompt tag is used to mark the text that will be used as the prompt. If no prompt tag is present then only one prompt is assumed": "This will produce three prompts, one for each color. The prompt tag is used to mark the text that will be used as the prompt. If no prompt tag is present then only one prompt is assumed",
    "{% for colour in wildcard(\"__colours__\") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}": "{% for colour in wildcard(\"__colours__\") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",
    "This will produce one prompt for each colour in the wildcard.txt file.": "This will produce one prompt for each colour in the wildcard.txt file.",
    "Conditionals": "Conditionals",
    "{% for colour in [\"red\", \"blue\", \"green\"] %}\n        {% if colour == \"red\"}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}": "{% for colour in [\"red\", \"blue\", \"green\"] %}\n        {% if colour == \"red\"}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}",
    "This will produce the following prompts:": "This will produce the following prompts:",
    "I hate blue roses": "I hate blue roses",
    "I hate green roses": "I hate green roses",
    "Jinja2 templates are based on the Jinja2 template engine. For more information see the": "Jinja2 templates are based on the Jinja2 template engine. For more information see the",
    "Jinja2 documentation.": "Jinja2 documentation.",
    "If you are using these templates, please let me know if they are useful.": "If you are using these templates, please let me know if they are useful.",
    "Advanced options": "Advanced options",
    "Some settings have been moved to the settings tab. Find them in the Dynamic Prompts section.": "Some settings have been moved to the settings tab. Find them in the Dynamic Prompts section.",
    "Unlink seed from prompt": "Unlink seed from prompt",
    "Fixed seed": "Fixed seed",
    "Write raw prompt to image": "Write raw prompt to image",
    "Don't generate images": "Don't generate images",
    "Write prompts to file": "Write prompts to file",
    "Manage wildcards for Dynamic Prompts": "Manage wildcards for Dynamic Prompts",
    "1. Create your wildcard library by copying a collection using the dropdown below.": "1. Create your wildcard library by copying a collection using the dropdown below.",
    "2. Click on any of the files that appear in the tree to edit them.": "2. Click on any of the files that appear in the tree to edit them.",
    "3. Use the wildcard in your script by typing the name of the file or copying the text from the Wildcards file text box": "3. Use the wildcard in your script by typing the name of the file or copying the text from the Wildcards file text box",
    "4. Optional - add your own wildcards files to the D:\\StableDiffusion\\clean install\\webui\\extensions\\sd-dynamic-prompts\\wildcards folder": "4. Optional - add your own wildcards files to the D:\\StableDiffusion\\clean install\\webui\\extensions\\sd-dynamic-prompts\\wildcards folder",
    "Select a collection": "Select a collection",
    "Copy collection": "Copy collection",
    "Overwrite existing": "Overwrite existing",
    "Refresh wildcards": "Refresh wildcards",
    "Delete all wildcards": "Delete all wildcards",
    "Wildcards file": "Wildcards file",
    "File editor": "File editor",
    "Save wildcards": "Save wildcards",
    "Action": "Action",
    "Ignore whitespace in prompts: All newlines, tabs, and multiple spaces are replaced by a single space": "Ignore whitespace in prompts: All newlines, tabs, and multiple spaces are replaced by a single space",
    "Save template to metadata: Write prompt template into the PNG metadata": "Save template to metadata: Write prompt template into the PNG metadata",
    "Write prompts to file: Create a new .txt file for every batch containing the prompt template as well as the generated prompts.": "Write prompts to file: Create a new .txt file for every batch containing the prompt template as well as the generated prompts.",
    "String to use as left bracket for parser variants, .e.g {variant1|variant2|variant3}": "String to use as left bracket for parser variants, .e.g {variant1|variant2|variant3}",
    "String to use as right bracket for parser variants, .e.g {variant1|variant2|variant3}": "String to use as right bracket for parser variants, .e.g {variant1|variant2|variant3}",
    "sd-dynamic-prompts": "sd-dynamic-prompts",
    "Disable dynamic prompts by unchecking this box.": "Disable dynamic prompts by unchecking this box.",
    "Instead of generating random prompts from a template, combinatorial generation produces every possible prompt from the given string.\nThe prompt 'I {love|hate} {New York|Chicago} in {June|July|August}' will produce 12 variants in total.\n\nThe value of the 'Seed' field is only used for the first image. To change this, look for 'Fixed seed' in the 'Advanced options' section.": "Instead of generating random prompts from a template, combinatorial generation produces every possible prompt from the given string.\nThe prompt 'I {love|hate} {New York|Chicago} in {June|July|August}' will produce 12 variants in total.\n\nThe value of the 'Seed' field is only used for the first image. To change this, look for 'Fixed seed' in the 'Advanced options' section.",
    "Limit the maximum number of prompts generated. 0 (default) will generate all images. Useful to prevent an unexpected combinatorial explosion.": "Limit the maximum number of prompts generated. 0 (default) will generate all images. Useful to prevent an unexpected combinatorial explosion.",
    "Re-run your combinatorial batch this many times with a different seed each time.": "Re-run your combinatorial batch this many times with a different seed each time.",
    "Magic Prompt adds interesting modifiers to your prompt for a little bit of extra spice.\nThe first time you use it, the MagicPrompt model is downloaded so be patient.\nIf you're running low on VRAM, you might get a CUDA error.": "Magic Prompt adds interesting modifiers to your prompt for a little bit of extra spice.\nThe first time you use it, the MagicPrompt model is downloaded so be patient.\nIf you're running low on VRAM, you might get a CUDA error.",
    "Controls the maximum length in tokens of the generated prompt.": "Controls the maximum length in tokens of the generated prompt.",
    "Adjusts the generated prompt. You will need to experiment with this setting.": "Adjusts the generated prompt. You will need to experiment with this setting.",
    "Regular expression pattern for blocking terms out of the generated prompt. Applied case-insensitively. For instance, to block both \"purple\" and \"interdimensional\", you could use the pattern \"purple|interdimensional\".": "Regular expression pattern for blocking terms out of the generated prompt. Applied case-insensitively. For instance, to block both \"purple\" and \"interdimensional\", you could use the pattern \"purple|interdimensional\".",
    "Uses the lexica.art API to create random prompts.\nThe prompt in the main prompt box is used as a search string.\nLeaving the prompt box blank returns a list of completely randomly chosen prompts.\nTry it out, it can be quite fun.": "Uses the lexica.art API to create random prompts.\nThe prompt in the main prompt box is used as a search string.\nLeaving the prompt box blank returns a list of completely randomly chosen prompts.\nTry it out, it can be quite fun.",
    "Randomly selects a keyword from the prompt and adds emphasis to it. Try this with Fixed Seed enabled.": "Randomly selects a keyword from the prompt and adds emphasis to it. Try this with Fixed Seed enabled.",
    "Don't use prompt magic on negative prompts.": "Don't use prompt magic on negative prompts.",
    "Jinja2 templates are an expressive alternative to the standard syntax. See the Help section below for instructions.": "Jinja2 templates are an expressive alternative to the standard syntax. See the Help section below for instructions.",
    "Check this if you want to generate random prompts, even if your seed is fixed": "Check this if you want to generate random prompts, even if your seed is fixed",
    "Select this if you want to use the same seed for every generated image.\nThis is useful if you want to test prompt variations while using the same seed.\nIf there are no wildcards then all the images will be identical.": "Select this if you want to use the same seed for every generated image.\nThis is useful if you want to test prompt variations while using the same seed.\nIf there are no wildcards then all the images will be identical.",
    "Write the prompt template into the image metadata": "Write the prompt template into the image metadata",
    "Be sure to check the 'Write prompts to file' checkbox if you don't want to lose the generated prompts. Note, one image is still generated.": "Be sure to check the 'Write prompts to file' checkbox if you don't want to lose the generated prompts. Note, one image is still generated.",
    "The generated file is a slugified version of the prompt and can be found in the same directory as the generated images.\nE.g. in ./outputs/txt2img-images/.": "The generated file is a slugified version of the prompt and can be found in the same directory as the generated images.\nE.g. in ./outputs/txt2img-images/.",
    "Complete documentation is available at https://github.com/adieyal/sd-dynamic-prompts. Please report any issues on GitHub.": "Complete documentation is available at https://github.com/adieyal/sd-dynamic-prompts. Please report any issues on GitHub.",
    "Generate all possible prompt combinations.": "Generate all possible prompt combinations.",
    "Automatically update your prompt with interesting modifiers. (Runs slowly the first time)": "Automatically update your prompt with interesting modifiers. (Runs slowly the first time)",
    "Generate random prompts from lexica.art (your prompt is used as a search query).": "Generate random prompts from lexica.art (your prompt is used as a search query).",
    "Use the same seed for all prompts in this batch": "Use the same seed for all prompts in this batch",
    "Write all generated prompts to a file": "Write all generated prompts to a file",
    "If this is set, then random prompts are generated, even if the seed is the same.": "If this is set, then random prompts are generated, even if the seed is the same.",
    "Disable image generation. Useful if you only want to generate text prompts. (1 image will still be generated to keep Auto1111 happy.).": "Disable image generation. Useful if you only want to generate text prompts. (1 image will still be generated to keep Auto1111 happy.).",
    "Add emphasis to a randomly selected keyword in the prompt.": "Add emphasis to a randomly selected keyword in the prompt.",
    "Write template into image metadata.": "Write template into image metadata.",
    "Note: Each model will download between 300mb and 1.4gb of data on first use.": "Note: Each model will download between 300mb and 1.4gb of data on first use.",
    "https://github.com/adieyal/sd-dynamic-prompts.git": "https://github.com/adieyal/sd-dynamic-prompts.git",
    "Info, Links and Help": "Info, Links and Help",
    "Made by": "Made by",
    "deforum.github.io": "deforum.github.io",
    ", port for AUTOMATIC1111's webui maintained by": ", port for AUTOMATIC1111's webui maintained by",
    "kabachuha": "kabachuha",
    "FOR HELP CLICK HERE": "FOR HELP CLICK HERE",
    "The code for this extension:": "The code for this extension:",
    "here": "here",
    "Join the": "Join the",
    "official Deforum Discord": "official Deforum Discord",
    "to share your creations and suggestions.": "to share your creations and suggestions.",
    "Official Deforum Wiki:": "Official Deforum Wiki:",
    "Anime-inclined great guide (by FizzleDorf) with lots of examples:": "Anime-inclined great guide (by FizzleDorf) with lots of examples:",
    "For advanced keyframing with Math functions, see": "For advanced keyframing with Math functions, see",
    "Alternatively, use": "Alternatively, use",
    "sd-parseq": "sd-parseq",
    "as a UI to define your animation schedules (see the Parseq section in the Keyframes tab).": "as a UI to define your animation schedules (see the Parseq section in the Keyframes tab).",
    "framesync.xyz": "framesync.xyz",
    "is also a good option, it makes compact math formulae for Deforum keyframes by selecting various waveforms.": "is also a good option, it makes compact math formulae for Deforum keyframes by selecting various waveforms.",
    "The other site allows for making keyframes using": "The other site allows for making keyframes using",
    "interactive splines and Bezier curves": "interactive splines and Bezier curves",
    "(select Disco output format).": "(select Disco output format).",
    "If you want to use Width/Height which are not multiples of 64, please change noise_type to 'Uniform', in Keyframes --> Noise.": "If you want to use Width/Height which are not multiples of 64, please change noise_type to 'Uniform', in Keyframes --> Noise.",
    "If you liked this extension, please": "If you liked this extension, please",
    "give it a star on GitHub": "give it a star on GitHub",
    "Keyframes": "Keyframes",
    "Init": "Init",
    "ControlNet": "ControlNet",
    "Hybrid Video": "Hybrid Video",
    "Batch name": "Batch name",
    "Restore Faces, Tiling & more": "Restore Faces, Tiling & more",
    "Restore Faces": "Restore Faces",
    "DDIM Eta": "DDIM Eta",
    "Pix2Pix img CFG schedule": "Pix2Pix img CFG schedule",
    "Resume & Run from file": "Resume & Run from file",
    "Run from Settings file": "Run from Settings file",
    "Resume Animation": "Resume Animation",
    "Override settings": "Override settings",
    "Custom settings file": "Custom settings file",
    "Resume from timestring": "Resume from timestring",
    "Resume timestring": "Resume timestring",
    "Animation mode": "Animation mode",
    "2D": "2D",
    "3D": "3D",
    "Interpolation": "Interpolation",
    "Video Input": "Video Input",
    "Border": "Border",
    "replicate": "replicate",
    "wrap": "wrap",
    "Cadence": "Cadence",
    "Max frames": "Max frames",
    "Guided Images": "Guided Images",
    "*READ ME before you use this mode!*": "*READ ME before you use this mode!*",
    "You can use this as a guided image tool or as a looper depending on your settings in the keyframe images field. \n                               Set the keyframes and the images that you want to show up. \n                               Note: the number of frames between each keyframe should be greater than the tweening frames.": "You can use this as a guided image tool or as a looper depending on your settings in the keyframe images field. \n                               Set the keyframes and the images that you want to show up. \n                               Note: the number of frames between each keyframe should be greater than the tweening frames.",
    "Prerequisites and Important Info:": "Prerequisites and Important Info:",
    "This mode works ONLY with 2D/3D animation modes. Interpolation and Video Input modes aren't supported.": "This mode works ONLY with 2D/3D animation modes. Interpolation and Video Input modes aren't supported.",
    "Set Init tab's strength slider greater than 0. Recommended value (.65 - .80).": "Set Init tab's strength slider greater than 0. Recommended value (.65 - .80).",
    "Set 'seed_behavior' to 'schedule' under the Seed Scheduling section below.": "Set 'seed_behavior' to 'schedule' under the Seed Scheduling section below.",
    "Looping recommendations:": "Looping recommendations:",
    "seed_schedule should start and end on the same seed.": "seed_schedule should start and end on the same seed.",
    "Example: seed_schedule could use 0:(5), 1:(-1), 219:(-1), 220:(5)": "Example: seed_schedule could use 0:(5), 1:(-1), 219:(-1), 220:(5)",
    "The 1st and last keyframe images should match.": "The 1st and last keyframe images should match.",
    "Set your total number of keyframes to be 21 more than the last inserted keyframe image.": "Set your total number of keyframes to be 21 more than the last inserted keyframe image.",
    "Example: Default args should use 221 as total keyframes.": "Example: Default args should use 221 as total keyframes.",
    "Prompts are stored in JSON format. If you've got an error, check it in validator,": "Prompts are stored in JSON format. If you've got an error, check it in validator,",
    "like here": "like here",
    "Enable guided images mode": "Enable guided images mode",
    "Images to use for keyframe guidance": "Images to use for keyframe guidance",
    "Guided images schedules": "Guided images schedules",
    "Image strength schedule": "Image strength schedule",
    "Blend factor max": "Blend factor max",
    "Blend factor slope": "Blend factor slope",
    "Tweening frames schedule": "Tweening frames schedule",
    "Color correction factor": "Color correction factor",
    "Strength": "Strength",
    "CFG": "CFG",
    "SubSeed": "SubSeed",
    "Step": "Step",
    "Checkpoint": "Checkpoint",
    "CLIP Skip": "CLIP Skip",
    "Strength schedule": "Strength schedule",
    "CFG scale schedule": "CFG scale schedule",
    "Seed behavior": "Seed behavior",
    "iter": "iter",
    "fixed": "fixed",
    "ladder": "ladder",
    "alternate": "alternate",
    "schedule": "schedule",
    "Seed iter N": "Seed iter N",
    "Seed schedule": "Seed schedule",
    "Enable Subseed scheduling": "Enable Subseed scheduling",
    "Subseed schedule": "Subseed schedule",
    "Subseed strength schedule": "Subseed strength schedule",
    "Enable steps scheduling": "Enable steps scheduling",
    "Steps schedule": "Steps schedule",
    "Enable sampler scheduling": "Enable sampler scheduling",
    "Sampler schedule": "Sampler schedule",
    "Enable checkpoint scheduling": "Enable checkpoint scheduling",
    "Checkpoint schedule": "Checkpoint schedule",
    "Enable CLIP skip scheduling": "Enable CLIP skip scheduling",
    "CLIP skip schedule": "CLIP skip schedule",
    "Motion": "Motion",
    "Noise": "Noise",
    "Coherence": "Coherence",
    "Anti Blur": "Anti Blur",
    "Angle": "Angle",
    "Zoom": "Zoom",
    "Translation X": "Translation X",
    "Translation Y": "Translation Y",
    "Translation Z": "Translation Z",
    "Rotation 3D X": "Rotation 3D X",
    "Rotation 3D Y": "Rotation 3D Y",
    "Rotation 3D Z": "Rotation 3D Z",
    "Depth Warping & FOV": "Depth Warping & FOV",
    "Depth Warping": "Depth Warping",
    "Field Of View": "Field Of View",
    "Use depth warping": "Use depth warping",
    "MiDaS weight": "MiDaS weight",
    "Padding mode": "Padding mode",
    "border": "border",
    "reflection": "reflection",
    "zeros": "zeros",
    "Sampling mode": "Sampling mode",
    "bicubic": "bicubic",
    "bilinear": "bilinear",
    "nearest": "nearest",
    "FOV schedule": "FOV schedule",
    "Near schedule": "Near schedule",
    "Far schedule": "Far schedule",
    "Perspective Flip": "Perspective Flip",
    "Enable perspective flip": "Enable perspective flip",
    "Perspective flip theta": "Perspective flip theta",
    "Perspective flip phi": "Perspective flip phi",
    "Perspective flip gamma": "Perspective flip gamma",
    "Perspective flip fv": "Perspective flip fv",
    "Noise type": "Noise type",
    "perlin": "perlin",
    "Noise schedule": "Noise schedule",
    "Perlin octaves": "Perlin octaves",
    "Perlin persistence": "Perlin persistence",
    "Color coherence": "Color coherence",
    "Match Frame 0 HSV": "Match Frame 0 HSV",
    "Match Frame 0 LAB": "Match Frame 0 LAB",
    "Match Frame 0 RGB": "Match Frame 0 RGB",
    "Color force Grayscale": "Color force Grayscale",
    "Color coherence video every N frames": "Color coherence video every N frames",
    "Contrast schedule": "Contrast schedule",
    "Reroll blank frames": "Reroll blank frames",
    "reroll": "reroll",
    "interrupt": "interrupt",
    "Kernel schedule": "Kernel schedule",
    "Sigma schedule": "Sigma schedule",
    "Amount schedule": "Amount schedule",
    "Threshold schedule": "Threshold schedule",
    "*Important* notes on Prompts": "*Important* notes on Prompts",
    "Please always keep values in math functions above 0.": "Please always keep values in math functions above 0.",
    "There is *no* Batch mode like in vanilla deforum. Please Use the txt2img tab for that.": "There is *no* Batch mode like in vanilla deforum. Please Use the txt2img tab for that.",
    "For negative prompts, please write your positive prompt, then --neg ugly, text, assymetric, or any other negative tokens of your choice. OR:": "For negative prompts, please write your positive prompt, then --neg ugly, text, assymetric, or any other negative tokens of your choice. OR:",
    "Use the negative_prompts field to automatically append all words as a negative prompt. *Don't* add --neg in the negative_prompts field!": "Use the negative_prompts field to automatically append all words as a negative prompt. *Don't* add --neg in the negative_prompts field!",
    "Prompts are stored in JSON format. If you've got an error, check it in a": "Prompts are stored in JSON format. If you've got an error, check it in a",
    "JSON Validator": "JSON Validator",
    "Prompts positive": "Prompts positive",
    "Prompts negative": "Prompts negative",
    "Composable Mask scheduling": "Composable Mask scheduling",
    "To enable, check use_mask in the Init tab": "To enable, check use_mask in the Init tab",
    "Supports boolean operations: (! - negation, & - and, | - or, ^ - xor, \\ - difference, () - nested operations)": "Supports boolean operations: (! - negation, & - and, | - or, ^ - xor, \\ - difference, () - nested operations)",
    "default variables: in \\{\\}, like \\{init_mask\\}, \\{video_mask\\}, \\{everywhere\\}": "default variables: in \\{\\}, like \\{init_mask\\}, \\{video_mask\\}, \\{everywhere\\}",
    "masks from files: in [], like [mask1.png]": "masks from files: in [], like [mask1.png]",
    "description-based:": "description-based:",
    "word masks": "word masks",
    "in <>, like <apple>, <hair>": "in <>, like <apple>, <hair>",
    "Mask schedule": "Mask schedule",
    "Use noise mask": "Use noise mask",
    "Noise mask schedule": "Noise mask schedule",
    "Image Init": "Image Init",
    "Video Init": "Video Init",
    "Mask Init": "Mask Init",
    "Use init": "Use init",
    "Strength 0 no init": "Strength 0 no init",
    "Init image": "Init image",
    "Video init path": "Video init path",
    "Extract from frame": "Extract from frame",
    "Extract to frame": "Extract to frame",
    "Extract nth frame": "Extract nth frame",
    "Overwrite extracted frames": "Overwrite extracted frames",
    "Use mask video": "Use mask video",
    "Video mask path": "Video mask path",
    "Use mask": "Use mask",
    "Use alpha as mask": "Use alpha as mask",
    "Invert mask": "Invert mask",
    "Overlay mask": "Overlay mask",
    "Mask file": "Mask file",
    "Mask overlay blur": "Mask overlay blur",
    "Mask fill": "Mask fill",
    "Full res mask": "Full res mask",
    "Full res mask padding": "Full res mask padding",
    "Parseq": "Parseq",
    "Use an": "Use an",
    "sd-parseq manifest": "sd-parseq manifest",
    "for your animation (leave blank to ignore).": "for your animation (leave blank to ignore).",
    "Note that parseq overrides:": "Note that parseq overrides:",
    "Run: seed, subseed, subseed strength.": "Run: seed, subseed, subseed strength.",
    "Keyframes: generation settings (noise, strength, contrast, scale).": "Keyframes: generation settings (noise, strength, contrast, scale).",
    "Keyframes: motion parameters for 2D and 3D (angle, zoom, translation, rotation, perspective flip).": "Keyframes: motion parameters for 2D and 3D (angle, zoom, translation, rotation, perspective flip).",
    "Parseq does": "Parseq does",
    "not": "not",
    "override:": "override:",
    "Run: Sampler, Width, Height, tiling, resize seed.": "Run: Sampler, Width, Height, tiling, resize seed.",
    "Keyframes: animation settings (animation mode, max frames, border)": "Keyframes: animation settings (animation mode, max frames, border)",
    "Keyframes: coherence (color coherence & cadence)": "Keyframes: coherence (color coherence & cadence)",
    "Keyframes: depth warping": "Keyframes: depth warping",
    "Output settings: all settings (including fps and max frames)": "Output settings: all settings (including fps and max frames)",
    "Parseq Manifest (JSON or URL)": "Parseq Manifest (JSON or URL)",
    "Use delta values for movement parameters": "Use delta values for movement parameters",
    "Requires the": "Requires the",
    "extension to be installed.": "extension to be installed.",
    "Due to ControlNet base extension's inner works it needs its models to be located at 'extensions/deforum-for-automatic1111-webui/models'. So copy, symlink or move them there until a more elegant solution is found. And, as of now, it requires use_init checked for the first run. The ControlNet extension version used in the dev process is a24089a62e70a7fae44b7bf35b51fd584dd55e25, if even with all the other options above used it still breaks, upgrade/downgrade your CN version to this one.": "Due to ControlNet base extension's inner works it needs its models to be located at 'extensions/deforum-for-automatic1111-webui/models'. So copy, symlink or move them there until a more elegant solution is found. And, as of now, it requires use_init checked for the first run. The ControlNet extension version used in the dev process is a24089a62e70a7fae44b7bf35b51fd584dd55e25, if even with all the other options above used it still breaks, upgrade/downgrade your CN version to this one.",
    "ControlNet not found. Please install it :)": "ControlNet not found. Please install it :)",
    "Please, change animation mode to 2D or 3D to enable Hybrid Mode": "Please, change animation mode to 2D or 3D to enable Hybrid Mode",
    "Info & Help": "Info & Help",
    "Hybrid Video Compositing in 2D/3D Mode": "Hybrid Video Compositing in 2D/3D Mode",
    "by": "by",
    "reallybigname": "reallybigname",
    "Composite video with previous frame init image in": "Composite video with previous frame init image in",
    "2D or 3D animation_mode": "2D or 3D animation_mode",
    "(not for Video Input mode)": "(not for Video Input mode)",
    "Uses your": "Uses your",
    "settings for": "settings for",
    "video_init_path, extract_nth_frame, overwrite_extracted_frames": "video_init_path, extract_nth_frame, overwrite_extracted_frames",
    "In Keyframes tab, you can also set": "In Keyframes tab, you can also set",
    "color_coherence": "color_coherence",
    "= '": "= '",
    "'": "'",
    "color_coherence_video_every_N_frames": "color_coherence_video_every_N_frames",
    "lets you only match every N frames": "lets you only match every N frames",
    "Color coherence may be used with hybrid composite off, to just use video color.": "Color coherence may be used with hybrid composite off, to just use video color.",
    "Hybrid motion may be used with hybrid composite off, to just use video motion.": "Hybrid motion may be used with hybrid composite off, to just use video motion.",
    "Hybrid Video Schedules": "Hybrid Video Schedules",
    "The alpha schedule controls overall alpha for video mix, whether using a composite mask or not.": "The alpha schedule controls overall alpha for video mix, whether using a composite mask or not.",
    "hybrid_comp_mask_blend_alpha_schedule": "hybrid_comp_mask_blend_alpha_schedule",
    "only affects the 'Blend'": "only affects the 'Blend'",
    "hybrid_comp_mask_type": "hybrid_comp_mask_type",
    "Mask contrast schedule is from 0-255. Normal is 1. Affects all masks.": "Mask contrast schedule is from 0-255. Normal is 1. Affects all masks.",
    "Autocontrast low/high cutoff schedules 0-100. Low 0 High 100 is full range.": "Autocontrast low/high cutoff schedules 0-100. Low 0 High 100 is full range.",
    "(": "(",
    "hybrid_comp_mask_auto_contrast": "hybrid_comp_mask_auto_contrast",
    "must be enabled": "must be enabled",
    ")": ")",
    "Click Here": "Click Here",
    "for more info/ a Guide.": "for more info/ a Guide.",
    "Hybrid Settings": "Hybrid Settings",
    "Generate inputframes": "Generate inputframes",
    "Hybrid composite": "Hybrid composite",
    "First frame as init image": "First frame as init image",
    "Motion use prev img": "Motion use prev img",
    "Hybrid motion": "Hybrid motion",
    "Optical Flow": "Optical Flow",
    "Perspective": "Perspective",
    "Affine": "Affine",
    "Flow method": "Flow method",
    "DIS Medium": "DIS Medium",
    "Farneback": "Farneback",
    "Comp mask type": "Comp mask type",
    "Depth": "Depth",
    "Video Depth": "Video Depth",
    "Blend": "Blend",
    "Difference": "Difference",
    "Comp mask equalize": "Comp mask equalize",
    "Before": "Before",
    "After": "After",
    "Both": "Both",
    "Comp mask auto contrast": "Comp mask auto contrast",
    "Comp mask inverse": "Comp mask inverse",
    "Comp save extra frames": "Comp save extra frames",
    "Hybrid Schedules": "Hybrid Schedules",
    "Comp alpha schedule": "Comp alpha schedule",
    "Comp mask blend alpha schedule": "Comp mask blend alpha schedule",
    "Comp mask contrast schedule": "Comp mask contrast schedule",
    "Comp mask auto contrast cutoff high schedule": "Comp mask auto contrast cutoff high schedule",
    "Comp mask auto contrast cutoff low schedule": "Comp mask auto contrast cutoff low schedule",
    "Humans Masking": "Humans Masking",
    "Generate human masks": "Generate human masks",
    "PNGs": "PNGs",
    "Video": "Video",
    "Video Output Settings": "Video Output Settings",
    "FPS": "FPS",
    "Output format": "Output format",
    "FFMPEG mp4": "FFMPEG mp4",
    "Add soundtrack": "Add soundtrack",
    "Init Video": "Init Video",
    "Soundtrack path": "Soundtrack path",
    "Skip video for run all": "Skip video for run all",
    "Store frames in ram": "Store frames in ram",
    "Save depth maps": "Save depth maps",
    "Make GIF": "Make GIF",
    "Upscale": "Upscale",
    "Upscale model": "Upscale model",
    "realesr-animevideov3": "realesr-animevideov3",
    "realesrgan-x4plus": "realesrgan-x4plus",
    "realesrgan-x4plus-anime": "realesrgan-x4plus-anime",
    "Upscale factor": "Upscale factor",
    "x2": "x2",
    "x3": "x3",
    "x4": "x4",
    "Keep Imgs": "Keep Imgs",
    "FFmpeg settings": "FFmpeg settings",
    "CRF": "CRF",
    "Preset": "Preset",
    "veryslow": "veryslow",
    "slower": "slower",
    "slow": "slow",
    "medium": "medium",
    "fast": "fast",
    "faster": "faster",
    "veryfast": "veryfast",
    "superfast": "superfast",
    "ultrafast": "ultrafast",
    "Location": "Location",
    "Frame Interoplation": "Frame Interoplation",
    "Video Upscaling": "Video Upscaling",
    "Frames to Video": "Frames to Video",
    "Important notes and Help": "Important notes and Help",
    "Use": "Use",
    "RIFE": "RIFE",
    "FILM": "FILM",
    "Frame Interpolation to smooth out, slow-mo (or both) any video.": "Frame Interpolation to smooth out, slow-mo (or both) any video.",
    "Supported engines:": "Supported engines:",
    "RIFE v4.6 and FILM.": "RIFE v4.6 and FILM.",
    "Important notes:": "Important notes:",
    "Frame Interpolation will *not* run if any of the following are enabled: 'Store frames in ram' / 'Skip video for run all'.": "Frame Interpolation will *not* run if any of the following are enabled: 'Store frames in ram' / 'Skip video for run all'.",
    "Audio (if provided) will *not* be transferred to the interpolated video if Slow-Mo is enabled.": "Audio (if provided) will *not* be transferred to the interpolated video if Slow-Mo is enabled.",
    "'add_soundtrack' and 'soundtrack_path' aren't being honoured in \"Interpolate an existing video\" mode. Original vid audio will be used instead with the same slow-mo rules above.": "'add_soundtrack' and 'soundtrack_path' aren't being honoured in \"Interpolate an existing video\" mode. Original vid audio will be used instead with the same slow-mo rules above.",
    "Engine": "Engine",
    "RIFE v4.6": "RIFE v4.6",
    "Slow Mo": "Slow Mo",
    "Interp X": "Interp X",
    "Slow-Mo X": "Slow-Mo X",
    "Interpolate an existing video": "Interpolate an existing video",
    "Video to Interpolate": "Video to Interpolate",
    "In Frame Count": "In Frame Count",
    "In FPS": "In FPS",
    "Interpolated Vid FPS": "Interpolated Vid FPS",
    "*Interpolate uploaded video*": "*Interpolate uploaded video*",
    "* check your CLI for outputs": "* check your CLI for outputs",
    "Video to Upscale": "Video to Upscale",
    "Upscale V2": "Upscale V2",
    "Upscale V1": "Upscale V1",
    "In Res": "In Res",
    "Out Res": "Out Res",
    "*Upscale uploaded video*": "*Upscale uploaded video*",
    "Path name modifier": "Path name modifier",
    "x0_pred": "x0_pred",
    "x": "x",
    "Important Notes:": "Important Notes:",
    "Enter relative to webui folder or Full-Absolute path, and make sure it ends with something like this: '20230124234916_%05d.png', just replace 20230124234916 with your batch ID. The %05d is important, don't forget it!": "Enter relative to webui folder or Full-Absolute path, and make sure it ends with something like this: '20230124234916_%05d.png', just replace 20230124234916 with your batch ID. The %05d is important, don't forget it!",
    "MP4 path": "MP4 path",
    "Render steps": "Render steps",
    "*Stitch frames to video*": "*Stitch frames to video*",
    "INVISIBLE": "INVISIBLE",
    "Mask contrast adjust": "Mask contrast adjust",
    "Mask brightness adjust": "Mask brightness adjust",
    "from_img2img_instead_of_link": "from_img2img_instead_of_link",
    "Perlin W": "Perlin W",
    "Perlin H": "Perlin H",
    "Filename format": "Filename format",
    "save_settings": "save_settings",
    "save_samples": "save_samples",
    "display_samples": "display_samples",
    "Subseed controls & More": "Subseed controls & More",
    "Enable subseed controls": "Enable subseed controls",
    "N Batch": "N Batch",
    "Save sample per step": "Save sample per step",
    "Show sample per step": "Show sample per step",
    "Click here after the generation to show the video": "Click here after the generation to show the video",
    "Close the video": "Close the video",
    "Deforum extension for auto1111 — version 2.2b": "Deforum extension for auto1111 — version 2.2b",
    "* Paths can be relative to webui folder OR full - absolute": "* Paths can be relative to webui folder OR full - absolute",
    "General Settings File": "General Settings File",
    "Video Settings File": "Video Settings File",
    "Save Video Settings": "Save Video Settings",
    "Load Video Settings": "Load Video Settings",
    "deforum-for-automatic1111-webui": "deforum-for-automatic1111-webui",
    "Create aesthetic embedding": "Create aesthetic embedding",
    "Open for Clip Aesthetic!": "Open for Clip Aesthetic!",
    "Aesthetic weight": "Aesthetic weight",
    "Aesthetic steps": "Aesthetic steps",
    "Aesthetic learning rate": "Aesthetic learning rate",
    "Slerp interpolation": "Slerp interpolation",
    "Aesthetic imgs embedding": "Aesthetic imgs embedding",
    "Aesthetic text for imgs": "Aesthetic text for imgs",
    "Slerp angle": "Slerp angle",
    "Is negative text": "Is negative text",
    "Create an aesthetic embedding out of any number of images": "Create an aesthetic embedding out of any number of images",
    "Create images embedding": "Create images embedding",
    "stable-diffusion-webui-aesthetic-gradients": "stable-diffusion-webui-aesthetic-gradients",
    "This text is used to rotate the feature space of the imgs embs": "This text is used to rotate the feature space of the imgs embs",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git": "https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git",
    "https://github.com/fkunn1326/openpose-editor.git": "https://github.com/fkunn1326/openpose-editor.git",
    "Latent Mirror mode": "Latent Mirror mode",
    "Alternate Steps": "Alternate Steps",
    "Blend Average": "Blend Average",
    "Latent Mirror style": "Latent Mirror style",
    "Vertical Mirroring": "Vertical Mirroring",
    "Horizontal Mirroring": "Horizontal Mirroring",
    "Horizontal+Vertical Mirroring": "Horizontal+Vertical Mirroring",
    "90 Degree Rotation": "90 Degree Rotation",
    "180 Degree Rotation": "180 Degree Rotation",
    "Roll Channels": "Roll Channels",
    "X panning": "X panning",
    "Y panning": "Y panning",
    "Maximum steps fraction to mirror at": "Maximum steps fraction to mirror at",
    "SD-latent-mirroring": "SD-latent-mirroring",
    "Additional Networks": "Additional Networks",
    "Separate UNet/Text Encoder weights": "Separate UNet/Text Encoder weights",
    "Network module 1": "Network module 1",
    "LoRA": "LoRA",
    "Model 1": "モデル 1",
    "Weight 1": "重み 1",
    "UNet Weight 1": "UNetの重み 1",
    "TEnc Weight 1": "TEncの重み1",
    "Network module 2": "Network module 2",
    "Model 2": "モデル 2",
    "Weight 2": "重み 2",
    "UNet Weight 2": "UNetの重み 2",
    "TEnc Weight 2": "TEncの重み2",
    "Network module 3": "Network module 3",
    "Model 3": "モデル 3",
    "Weight 3": "重み 3",
    "UNet Weight 3": "UNetの重み 3",
    "TEnc Weight 3": "TEncの重み3",
    "Network module 4": "Network module 4",
    "Model 4": "モデル 4",
    "Weight 4": "重み 4",
    "UNet Weight 4": "UNetの重み 4",
    "TEnc Weight 4": "TEncの重み4",
    "Network module 5": "Network module 5",
    "Model 5": "モデル 5",
    "Weight 5": "重み 5",
    "UNet Weight 5": "UNetの重み 5",
    "TEnc Weight 5": "TEncの重み5",
    "Extra args": "そのほかの引数",
    "mask image:": "mask image:",
    "Refresh models": "モデルを更新",
    "AddNet Model 1": "モデル 1(AddNet)",
    "AddNet Weight 1": "重み 1(AddNet)",
    "AddNet UNet Weight 1": "UNetの重み 1(AddNet)",
    "AddNet TEnc Weight 1": "AddNetNetの重み 1",
    "AddNet Model 2": "モデル 2(AddNet)",
    "AddNet Weight 2": "重み 2(AddNet)",
    "AddNet UNet Weight 2": "UNetの重み 2(AddNet)",
    "AddNet TEnc Weight 2": "TEncの重み 2(AddNet)",
    "AddNet Model 3": "モデル 3(AddNet)",
    "AddNet Weight 3": "重み 3(AddNet)",
    "AddNet UNet Weight 3": "UNetの重み 3(AddNet)",
    "AddNet TEnc Weight 3": "TEncの重み 3(AddNet)",
    "AddNet Model 4": "モデル 4(AddNet)",
    "AddNet Weight 4": "重み 4(AddNet)",
    "AddNet UNet Weight 4": "UNetの重み 4(AddNet)",
    "AddNet TEnc Weight 4": "TEncの重み 4(AddNet)",
    "AddNet Model 5": "モデル 5(AddNet)",
    "AddNet Weight 5": "重み 5(AddNet)",
    "AddNet UNet Weight 5": "UNetの重み 5(AddNet)",
    "AddNet TEnc Weight 5": "TEncの重み 5(AddNet)",
    "Model path filter": "Model path filter",
    "Filter models by path name": "Filter models by path name",
    "Network module": "Network module",
    "Model hash": "モデルのHash値",
    "Legacy hash": "Legacy hash",
    "Model path": "モデルのパス",
    "Send to txt2img:": "Txt2imgに転送:",
    "Send to img2img:": "Img2Imgに転送:",
    "Copy metadata to other models in directory": "Copy metadata to other models in directory",
    "Containing directory": "Containing directory",
    "All models in this directory will receive the selected model's metadata": "All models in this directory will receive the selected model's metadata",
    "Only copy to models with same session ID": "Only copy to models with same session ID",
    "Only copy to models with no metadata": "Only copy to models with no metadata",
    "Copy Metadata": "メタデータをコピー",
    "Display name for this model": "表示名",
    "Author": "作成者",
    "Author of this model": "モデルの作成者",
    "Keywords": "キーワード",
    "Activation keywords, comma-separated": "Activation keywords, comma-separated",
    "Model description/readme/notes/instructions": "Model description/readme/notes/instructions",
    "Source URL where this model could be found": "Source URL where this model could be found",
    "Rating": "評価",
    "Tags": "タグ",
    "Comma-separated list of tags (\"artist, style, character, 2d, 3d...\")": "Comma-separated list of tags (\"artist, style, character, 2d, 3d...\")",
    "Editing Enabled": "Editing Enabled",
    "Save Metadata": "メタデータを保存",
    "Cover image": "カバー画像",
    "Image Parameters": "Image Parameters",
    "Training info": "Training info",
    "Most frequent tags in captions": "Most frequent tags in captions",
    "Dataset folder structure": "Dataset folder structure",
    "Image Count": "Image Count",
    "Repeats": "Repeats",
    "Total Images": "Total Images",
    "Training parameters": "Training parameters",
    "copy to clipboard": "クリップボードにコピー",
    "Extra paths to scan for LoRA models, comma-separated. Paths containing commas must be enclosed in double quotes. In the path, \" (one quote) must be replaced by \"\" (two quotes).": "Extra paths to scan for LoRA models, comma-separated. Paths containing commas must be enclosed in double quotes. In the path, \" (one quote) must be replaced by \"\" (two quotes).",
    "Sort LoRA models by": "LoRAの並び替え",
    "name": "名前",
    "rating": "評価",
    "has user metadata": "has user metadata",
    "Reverse model sort order": "Reverse model sort order",
    "LoRA model name filter": "LoRA model name filter",
    "Metadata to show in XY-Grid label for Model axes, comma-separated (example: \"ss_learning_rate, ss_num_epochs\")": "Metadata to show in XY-Grid label for Model axes, comma-separated (example: \"ss_learning_rate, ss_num_epochs\")",
    "# of threads to use for hash calculation (increase if using an SSD)": "# of threads to use for hash calculation (increase if using an SSD)",
    "Make a backup copy of the model being edited when saving its metadata.": "Make a backup copy of the model being edited when saving its metadata.",
    "Only show .safetensors format models": "Only show .safetensors format models",
    "Only show models that have/don't have user-added metadata": "Only show models that have/don't have user-added metadata",
    "has metadata": "has metadata",
    "missing metadata": "メタデータがありません",
    "Max number of top tags to show": "Max number of top tags to show",
    "Max number of dataset folders to show": "Max number of dataset folders to show",
    "sd-webui-additional-networks": "sd-webui-additional-networks",
    "https://github.com/kohya-ss/sd-webui-additional-networks.git": "https://github.com/kohya-ss/sd-webui-additional-networks.git",
    "Model Pre​views": "Model Pre​views",
    "Embeddings": "Embeddings",
    "Filter": "Filter",
    "Notes": "Notes",
    "Model Preview XD": "Model Preview XD",
    "Name matching rule for preview files": "Name matching rule for preview files",
    "Loose": "Loose",
    "Strict": "Strict",
    "Folder": "Folder",
    "Index": "Index",
    "Limit the height of preivews to the height of the browser window (.html preview files are always limited regardless of this setting)": "Limit the height of preivews to the height of the browser window (.html preview files are always limited regardless of this setting)",
    "sd-model-preview-xd": "sd-model-preview-xd",
    "No Preview Found": "No Preview Found",
    "https://github.com/deforum-art/deforum-for-automatic1111-webui.git": "https://github.com/deforum-art/deforum-for-automatic1111-webui.git",
    "openOutpaint": "openOutpaint",
    "Send to openOutpaint": "Send to openOutpaint",
    "openOutpaint-webUI-extension": "openOutpaint-webUI-extension",
    "Refresh openOutpaint": "Refresh openOutpaint",
    "HakuImg": "HakuImg",
    "Send to Blend": "Send to Blend",
    "Send to Layer5": "Send to Layer5",
    "Send to Layer4": "Send to Layer4",
    "Send to Layer3": "Send to Layer3",
    "Send to Layer2": "Send to Layer2",
    "Send to Layer1": "Send to Layer1",
    "Send to Effect": "Send to Effect",
    "Effect": "Effect",
    "Other": "Other",
    "Image preview height": "Image preview height",
    "Layer5": "Layer5",
    "Layer4": "Layer4",
    "Layer3": "Layer3",
    "Layer2": "Layer2",
    "Layer1": "Layer1",
    "Layer5 opacity": "Layer5 opacity",
    "Layer5 mask blur": "Layer5 mask blur",
    "Layer5 mask strength": "Layer5 mask strength",
    "Blend mode": "Blend mode",
    "normal": "normal",
    "darken": "darken",
    "multiply": "multiply",
    "color_burn": "color_burn",
    "linear_burn": "linear_burn",
    "lighten": "lighten",
    "screen": "screen",
    "color_dodge": "color_dodge",
    "linear_dodge": "linear_dodge",
    "overlay": "overlay",
    "soft_light": "soft_light",
    "hard_light": "hard_light",
    "vivid_light": "vivid_light",
    "linear_light": "linear_light",
    "pin_light": "pin_light",
    "difference": "difference",
    "exclusion": "exclusion",
    "Layer4 opacity": "Layer4 opacity",
    "Layer4 mask blur": "Layer4 mask blur",
    "Layer4 mask strength": "Layer4 mask strength",
    "Layer3 opacity": "Layer3 opacity",
    "Layer3 mask blur": "Layer3 mask blur",
    "Layer3 mask strength": "Layer3 mask strength",
    "Layer2 opacity": "Layer2 opacity",
    "Layer2 mask blur": "Layer2 mask blur",
    "Layer2 mask strength": "Layer2 mask strength",
    "Layer1 opacity": "Layer1 opacity",
    "Layer1 mask blur": "Layer1 mask blur",
    "Layer1 mask strength": "Layer1 mask strength",
    "background color": "background color",
    "refresh": "refresh",
    "img": "img",
    "Color": "Color",
    "Tone Curve": "Tone Curve",
    "Blur": "Blur",
    "Pixelize": "Pixelize",
    "Glow": "Glow",
    "temparature": "temparature",
    "hue": "hue",
    "brightness": "brightness",
    "contrast": "contrast",
    "saturation": "saturation",
    "Gamma": "Gamma",
    "reset": "reset",
    "R": "R",
    "G": "G",
    "point1 x": "point1 x",
    "point1 y": "point1 y",
    "point2 x": "point2 x",
    "point2 y": "point2 y",
    "point3 x": "point3 x",
    "point3 y": "point3 y",
    "blur": "blur",
    "kernel size": "kernel size",
    "sigma": "sigma",
    "k_sigma": "k_sigma",
    "epsilon": "epsilon",
    "phi": "phi",
    "gamma": "gamma",
    "color mode": "color mode",
    "gray": "gray",
    "rgb": "rgb",
    "use scale": "use scale",
    "colors": "colors",
    "dot size": "dot size",
    "outline inflating": "outline inflating",
    "Smoothing": "Smoothing",
    "Color reduce algo": "Color reduce algo",
    "kmeans": "kmeans",
    "dithering": "dithering",
    "kmeans with dithering": "kmeans with dithering",
    "Glow mode": "Glow mode",
    "BS": "BS",
    "BMBL": "BMBL",
    "range": "range",
    "strength": "strength",
    "InOutPaint": "InOutPaint",
    "fill up": "fill up",
    "fill down": "fill down",
    "fill left": "fill left",
    "fill right": "fill right",
    "Resolution": "Resolution",
    "haku_output": "haku_output",
    "Send to inpaint upload": "Send to inpaint upload",
    "Total num of layers (reload required)": "Total num of layers (reload required)",
    "Total num of point for curve (reload required)": "Total num of point for curve (reload required)",
    "a1111-sd-webui-haku-img": "a1111-sd-webui-haku-img",
    "https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git": "https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git",
    "Target": "Target",
    "Light": "Light",
    "Position/Rotate X": "Position/Rotate X",
    "Position/Rotate Y": "Position/Rotate Y",
    "Position/Rotate Z": "Position/Rotate Z",
    "Show Ground": "Show Ground",
    "Show Grid": "Show Grid",
    "Show Axis": "Show Axis",
    "Background Color": "Background Color",
    "Ground Color": "Ground Color",
    "Light Color": "Light Color",
    "Model Scale": "Model Scale",
    "Load Model": "Load Model",
    "Play/Pause": "Play/Pause",
    "Stop": "Stop",
    "3D Model": "3D Model",
    "Canvas Background Color": "Canvas Background Color",
    "Canvas Ground Color": "Canvas Ground Color",
    "Canvas Width": "Canvas Width",
    "Canvas Height": "Canvas Height",
    "sd-3dmodel-loader": "sd-3dmodel-loader",
    "https://github.com/jtydhr88/sd-3dmodel-loader.git": "https://github.com/jtydhr88/sd-3dmodel-loader.git",
    "stable-diffusion-webui-prompt-travel": "stable-diffusion-webui-prompt-travel",
    "Shift attention": "Shift attention",
    "https://github.com/yownas/shift-attention.git": "https://github.com/yownas/shift-attention.git",
    "Plot": "Plot",
    "Max Image Size": "Max Image Size",
    "Max Batch Count": "Max Batch Count",
    "Run benchmark": "Run benchmark",
    "Load results": "Load results",
    "a1111-stable-diffusion-webui-vram-estimator": "a1111-stable-diffusion-webui-vram-estimator",
    "https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git": "https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git",
    "https://github.com/dfaker/SD-latent-mirroring.git": "https://github.com/dfaker/SD-latent-mirroring.git",
    "hidden_idx_next": "hidden_idx_next",
    "hidden_idx_prev": "hidden_idx_prev",
    "hidden_s_or_n": "hidden_s_or_n",
    "Dataset Filter": "Dataset Filter",
    "Filter Apply": "Filter Apply",
    "This extension works well with text captions in comma-separated style (such as the tags generated by DeepBooru interrogator).": "This extension works well with text captions in comma-separated style (such as the tags generated by DeepBooru interrogator).",
    "Save all changes": "Save all changes",
    "Backup original text file (original file will be renamed like filename.000, .001, .002, ...)": "Backup original text file (original file will be renamed like filename.000, .001, .002, ...)",
    "Note:": "Note:",
    "New text file will be created if you are using filename as captions.": "New text file will be created if you are using filename as captions.",
    "Save kohya-ss's finetuning metadata json": "Save kohya-ss's finetuning metadata json",
    "json output path": "json output path",
    "json input path (Optional)": "json input path (Optional)",
    "Overwrite if output file exists": "Overwrite if output file exists",
    "Save metadata as caption": "Save metadata as caption",
    "Save metadata image key as fullpath": "Save metadata image key as fullpath",
    "Results": "Results",
    "Reload/Save Settings (config.json)": "Reload/Save Settings (config.json)",
    "Reload settings": "Reload settings",
    "Save current settings": "Save current settings",
    "Restore settings to default": "Restore settings to default",
    "Caption File Ext": "Caption File Ext",
    "Load": "Load",
    "Dataset Load Settings": "Dataset Load Settings",
    "Load from subdirectories": "Load from subdirectories",
    "Load caption from filename if no text file exists": "Load caption from filename if no text file exists",
    "Use Interrogator Caption": "Use Interrogator Caption",
    "If Empty": "If Empty",
    "Overwrite": "Overwrite",
    "Prepend": "Prepend",
    "Append": "Append",
    "Interrogators": "Interrogators",
    "Interrogator Settings": "Interrogator Settings",
    "Use Custom Threshold (Booru)": "Use Custom Threshold (Booru)",
    "Booru Score Threshold": "Booru Score Threshold",
    "Use Custom Threshold (WDv1.4 Tagger)": "Use Custom Threshold (WDv1.4 Tagger)",
    "WDv1.4 Tagger Score Threshold": "WDv1.4 Tagger Score Threshold",
    "Dataset Images": "Dataset Images",
    "Displayed Images : 0 / 0 total": "Displayed Images : 0 / 0 total",
    "Current Tag Filter :": "Current Tag Filter :",
    "Current Selection Filter : 0 images": "Current Selection Filter : 0 images",
    "Selected Image :": "Selected Image :",
    "Filter by Tags": "Filter by Tags",
    "Filter by Selection": "Filter by Selection",
    "Batch Edit Captions": "Batch Edit Captions",
    "Edit Caption of Selected Image": "Edit Caption of Selected Image",
    "Move or Delete Files": "Move or Delete Files",
    "Clear tag filters": "Clear tag filters",
    "Clear ALL filters": "Clear ALL filters",
    "Positive Filter": "Positive Filter",
    "Negative Filter": "Negative Filter",
    "Search tags / Filter images by tags": "Search tags / Filter images by tags",
    "(INCLUSIVE)": "(INCLUSIVE)",
    "Search Tags": "Search Tags",
    "Prefix": "Prefix",
    "Suffix": "Suffix",
    "Use regex": "Use regex",
    "Alphabetical Order": "Alphabetical Order",
    "Frequency": "Frequency",
    "Length": "Length",
    "Sort Order": "Sort Order",
    "Ascending": "Ascending",
    "Descending": "Descending",
    "Filter Logic": "Filter Logic",
    "AND": "AND",
    "OR": "OR",
    "Filter Images by Tags": "Filter Images by Tags",
    "(EXCLUSIVE)": "(EXCLUSIVE)",
    "Select images from the left gallery.": "Select images from the left gallery.",
    "Add selection [Enter]": "Add selection [Enter]",
    "Add ALL Displayed": "Add ALL Displayed",
    "Filter Images": "Filter Images",
    "Remove selection [Delete]": "Remove selection [Delete]",
    "Invert selection": "Invert selection",
    "Clear selection": "Clear selection",
    "Apply selection filter": "Apply selection filter",
    "Search and Replace": "Search and Replace",
    "Remove": "Remove",
    "Edit common tags.": "Edit common tags.",
    "Show only the tags selected in the Positive Filter": "Show only the tags selected in the Positive Filter",
    "Common Tags": "Common Tags",
    "Edit Tags": "Edit Tags",
    "Prepend additional tags": "Prepend additional tags",
    "Apply changes to filtered images": "Apply changes to filtered images",
    "Show description of how to edit tags": "Show description of how to edit tags",
    "1. The tags common to all displayed images are shown in comma separated style.": "1. The tags common to all displayed images are shown in comma separated style.",
    "2. When changes are applied, all tags in each displayed images are replaced.": "2. When changes are applied, all tags in each displayed images are replaced.",
    "3. If you change some tags into blank, they will be erased.": "3. If you change some tags into blank, they will be erased.",
    "4. If you add some tags to the end, they will be added to the end/beginning of the text file.": "4. If you add some tags to the end, they will be added to the end/beginning of the text file.",
    "5. Changes are not applied to the text files until the \"Save all changes\" button is pressed.": "5. Changes are not applied to the text files until the \"Save all changes\" button is pressed.",
    "ex A.": "ex A.",
    "Original Text = \"A, A, B, C\" Common Tags = \"B, A\" Edit Tags = \"X, Y\"": "Original Text = \"A, A, B, C\" Common Tags = \"B, A\" Edit Tags = \"X, Y\"",
    "Result = \"Y, Y, X, C\" (B->X, A->Y)": "Result = \"Y, Y, X, C\" (B->X, A->Y)",
    "ex B.": "ex B.",
    "Original Text = \"A, B, C\" Common Tags = \"(nothing)\" Edit Tags = \"X, Y\"": "Original Text = \"A, B, C\" Common Tags = \"(nothing)\" Edit Tags = \"X, Y\"",
    "Result = \"A, B, C, X, Y\" (add X and Y to the end (default))": "Result = \"A, B, C, X, Y\" (add X and Y to the end (default))",
    "Result = \"X, Y, A, B, C\" (add X and Y to the beginning (\"Prepend additional tags\" checked))": "Result = \"X, Y, A, B, C\" (add X and Y to the beginning (\"Prepend additional tags\" checked))",
    "ex C.": "ex C.",
    "Original Text = \"A, B, C, D, E\" Common Tags = \"A, B, D\" Edit Tags = \", X, \"": "Original Text = \"A, B, C, D, E\" Common Tags = \"A, B, D\" Edit Tags = \", X, \"",
    "Result = \"X, C, E\" (A->\"\", B->X, D->\"\")": "Result = \"X, C, E\" (A->\"\", B->X, D->\"\")",
    "Search and Replace for all images displayed.": "Search and Replace for all images displayed.",
    "Search Text": "Search Text",
    "Replace Text": "Replace Text",
    "Search and Replace in": "Search and Replace in",
    "Only Selected Tags": "Only Selected Tags",
    "Each Tags": "Each Tags",
    "Entire Caption": "Entire Caption",
    "Selected Tags": "Selected Tags",
    "duplicate": "duplicate",
    "tags from the images displayed.": "tags from the images displayed.",
    "Remove duplicate tags": "Remove duplicate tags",
    "selected": "selected",
    "Remove selected tags": "Remove selected tags",
    "Select visible tags": "Select visible tags",
    "Deselect visible tags": "Deselect visible tags",
    "Select Tags": "Select Tags",
    "Read Caption from Selected Image": "Read Caption from Selected Image",
    "Interrogate Selected Image": "Interrogate Selected Image",
    "Caption of Selected Image": "Caption of Selected Image",
    "Copy and Overwrite": "Copy and Overwrite",
    "Interrogator": "Interrogator",
    "BLIP": "BLIP",
    "DeepDanbooru": "DeepDanbooru",
    "wd-v1-4-vit-tagger": "wd-v1-4-vit-tagger",
    "wd-v1-4-convnext-tagger": "wd-v1-4-convnext-tagger",
    "wd-v1-4-vit-tagger-v2": "wd-v1-4-vit-tagger-v2",
    "wd-v1-4-convnext-tagger-v2": "wd-v1-4-convnext-tagger-v2",
    "wd-v1-4-swinv2-tagger-v2": "wd-v1-4-swinv2-tagger-v2",
    "Interrogate": "Interrogate",
    "Interrogate Result": "Interrogate Result",
    "Copy caption from selected images automatically": "Copy caption from selected images automatically",
    "Warn if changes in caption is not saved": "Warn if changes in caption is not saved",
    "Edit Caption": "Edit Caption",
    "Apply changes to selected image": "Apply changes to selected image",
    "Changes are not applied to the text files until the \"Save all changes\" button is pressed.": "Changes are not applied to the text files until the \"Save all changes\" button is pressed.",
    "Moved or deleted images will be unloaded.": "Moved or deleted images will be unloaded.",
    "Move or Delete": "Move or Delete",
    "Selected One": "Selected One",
    "All Displayed Ones": "All Displayed Ones",
    "Image File": "Image File",
    "Caption Text File": "Caption Text File",
    "Caption Backup File": "Caption Backup File",
    "Target dataset num: 0": "Target dataset num: 0",
    "Destination Directory": "Destination Directory",
    "Move File(s)": "Move File(s)",
    "DELETE cannot be undone. The files will be deleted completely.": "DELETE cannot be undone. The files will be deleted completely.",
    "DELETE File(s)": "DELETE File(s)",
    "Number of columns on image gallery": "Number of columns on image gallery",
    "stable-diffusion-webui-dataset-tag-editor": "stable-diffusion-webui-dataset-tag-editor",
    ".txt (on Load and Save)": ".txt (on Load and Save)",
    "Reconstruct prompt from existing image and put it into the prompt field.": "Reconstruct prompt from existing image and put it into the prompt field.",
    "txt": "txt",
    "https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor.git": "https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor.git",
    "Annotator result": "Annotatorの結果",
    "Invert colors if your image has white background.": "Invert colors if your image has white background.",
    "Change your brush width to make it thinner if you want to draw something.": "Change your brush width to make it thinner if you want to draw something.",
    "Invert Input Color": "Invert Input Color",
    "RGB to BGR": "RGB to BGR",
    "Low VRAM": "Low VRAM",
    "Guess Mode": "Guess Mode",
    "Preprocessor": "プリプロセッサ",
    "none": "none",
    "canny": "canny",
    "depth": "depth",
    "depth_leres": "depth_leres",
    "hed": "hed",
    "mlsd": "mlsd",
    "normal_map": "normal_map",
    "openpose": "openpose",
    "pidinet": "pidinet",
    "scribble": "scribble",
    "fake_scribble": "fake_scribble",
    "segmentation": "segmentation",
    "Guidance strength (T)": "Guidance strength (T)",
    "Annotator resolution": "Annotatorの解像度",
    "Threshold A": "Threshold A",
    "Threshold B": "Threshold B",
    "Resize Mode": "Resize Mode",
    "Envelope (Outer Fit)": "Envelope (Outer Fit)",
    "Scale to Fit (Inner Fit)": "Scale to Fit (Inner Fit)",
    "Just Resize": "Just Resize",
    "Create blank canvas": "Create blank canvas",
    "Preview annotator result": "Preview annotator result",
    "Hide annotator result": "Hide annotator result",
    "[ControlNet] Model": "[ControlNet] モデル",
    "[ControlNet] Weight": "[ControlNet] 重み",
    "[ControlNet] Guidance Strength": "[ControlNet] Guidance Strength",
    "[ControlNet] Resize Mode": "[ControlNet] Resize Mode",
    "[ControlNet] Preprocessor": "[ControlNet] プリプロセッサ",
    "[ControlNet] Pre Resolution": "[ControlNet] Pre Resolution",
    "[ControlNet] Pre Threshold A": "[ControlNet] Pre Threshold A",
    "[ControlNet] Pre Threshold B": "[ControlNet] Pre Threshold B",
    "Config file for Control Net models": "ControlNetモデルの設定ファイル",
    "Config file for Adapter models": "Config file for Adapter models",
    "Directory for detected maps auto saving": "Directory for detected maps auto saving",
    "Extra path to scan for ControlNet models (e.g. training output directory)": "Extra path to scan for ControlNet models (e.g. training output directory)",
    "Multi ControlNet: Max models amount (requires restart)": "Multi ControlNet: Max models amount (requires restart)",
    "Model cache size (requires restart)": "Model cache size (requires restart)",
    "Apply transfer control when loading models": "Apply transfer control when loading models",
    "Do not append detectmap to output": "Do not append detectmap to output",
    "Allow detectmap auto saving": "Allow detectmap auto saving",
    "Use mid-control on highres pass (second pass)": "Use mid-control on highres pass (second pass)",
    "Allow other script to control this extension": "Allow other script to control this extension",
    "Skip img2img processing when using img2img initial image": "Skip img2img processing when using img2img initial image",
    "Enable optimized monocular depth estimation": "Enable optimized monocular depth estimation",
    "Only use mid-control when inference": "Only use mid-control when inference",
    "Enable CFG-Based guidance": "Enable CFG-Based guidance",
    "https://github.com/Mikubill/sd-webui-controlnet.git": "https://github.com/Mikubill/sd-webui-controlnet.git",
    "stable-diffusion-webui-depthmap-script": "stable-diffusion-webui-depthmap-script",
    "Compute on": "Compute on",
    "GPU": "GPU",
    "CPU": "CPU",
    "Match input size (size is ignored when using boost)": "Match input size (size is ignored when using boost)",
    "BOOST (multi-resolution merging)": "BOOST (multi-resolution merging)",
    "Invert DepthMap (black=near, white=far)": "Invert DepthMap (black=near, white=far)",
    "Clip and renormalize": "Clip and renormalize",
    "Far clip": "Far clip",
    "Near clip": "Near clip",
    "Combine into one image.": "Combine into one image.",
    "Combine axis": "Combine axis",
    "Vertical": "Vertical",
    "Horizontal": "Horizontal",
    "Save DepthMap": "Save DepthMap",
    "Show DepthMap": "Show DepthMap",
    "Show HeatMap": "Show HeatMap",
    "Generate Stereo side-by-side image": "Generate Stereo side-by-side image",
    "Generate Stereo anaglyph image (red/cyan)": "Generate Stereo anaglyph image (red/cyan)",
    "Divergence (3D effect)": "Divergence (3D effect)",
    "Gap fill technique": "Gap fill technique",
    "Balance between eyes": "Balance between eyes",
    "Generate 3D inpainted mesh. (Sloooow)": "Generate 3D inpainted mesh. (Sloooow)",
    "Generate 4 demo videos with 3D inpainted mesh.": "Generate 4 demo videos with 3D inpainted mesh.",
    "Remove background": "Remove background",
    "Save the foreground masks": "Save the foreground masks",
    "pre-depth background removal": "pre-depth background removal",
    "Rembg Model": "Rembg Model",
    "Information, comment and share @": "Information, comment and share @",
    "Input Mesh (.ply)": "Input Mesh (.ply)",
    "Generate video from inpainted mesh.": "Generate video from inpainted mesh.",
    "A file on the same machine where the server is running.": "A file on the same machine where the server is running.",
    "Number of frames": "Number of frames",
    "Framerate": "Framerate",
    "Format": "Format",
    "Trajectory": "Trajectory",
    "Translate: x, y, z": "Translate: x, y, z",
    "Crop: top, left, bottom, right": "Crop: top, left, bottom, right",
    "Dolly": "Dolly",
    "Generate Video": "Generate Video",
    "https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git": "https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git",
    "https://github.com/zero01101/openOutpaint-webUI-extension.git": "https://github.com/zero01101/openOutpaint-webUI-extension.git",
    "https://github.com/thygate/stable-diffusion-webui-depthmap-script.git": "https://github.com/thygate/stable-diffusion-webui-depthmap-script.git",
    "https://github.com/CurtisDS/sd-model-preview-xd.git": "https://github.com/CurtisDS/sd-model-preview-xd.git",
    "https://github.com/yownas/seed_travel.git": "https://github.com/yownas/seed_travel.git"
}